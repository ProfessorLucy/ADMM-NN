I0822 19:29:56.003432 31324 caffe.cpp:224] Using GPUs 0
I0822 19:29:56.069322 31324 caffe.cpp:229] GPU 0: GeForce GTX 1080 Ti
I0822 19:29:56.475576 31324 solver.cpp:45] Initializing solver from parameters: 
test_iter: 1000
test_interval: 1000
base_lr: 0.01
display: 20
max_iter: 450000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 100000
snapshot: 10000
snapshot_prefix: "/data/kaiqi/24_prune_quantization01/caffe_alexnet_1st_retrain"
solver_mode: GPU
device_id: 0
net: "models/bvlc_alexnet/train_val_admm.prototxt"
train_state {
  level: 0
  stage: ""
}
weights: "/data/kaiqi/24_prune_quantization01/caffe_alexnet_train_admm_iter_2400000.caffemodel"
clustering_phase: "retrain"
I0822 19:29:56.475728 31324 solver.cpp:102] Creating training net from net file: models/bvlc_alexnet/train_val_admm.prototxt
I0822 19:29:56.476023 31324 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0822 19:29:56.476042 31324 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0822 19:29:56.476047 31324 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy5
I0822 19:29:56.476198 31324 net.cpp:51] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "/home/kaiqi/imagenet/imagenet_mean.binaryproto"
  }
  data_param {
    source: "/home/kaiqi/imagenet/ilsvrc12_train_lmdb"
    batch_size: 256
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
    rho: 0.0015
    clustering_num: 128
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
    rho: 0.0015
    clustering_num: 64
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
    rho: 0.0015
    clustering_num: 64
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
    rho: 0.0015
    clustering_num: 64
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
    rho: 0.0015
    clustering_num: 64
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
    rho: 0.0015
    clustering_num: 8
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
    rho: 0.0015
    clustering_num: 4
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
    rho: 0.0015
    clustering_num: 128
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0822 19:29:56.476289 31324 layer_factory.hpp:77] Creating layer data
I0822 19:29:56.476814 31324 db_lmdb.cpp:35] Opened lmdb /home/kaiqi/imagenet/ilsvrc12_train_lmdb
I0822 19:29:56.477677 31324 net.cpp:84] Creating Layer data
I0822 19:29:56.477705 31324 net.cpp:380] data -> data
I0822 19:29:56.477766 31324 net.cpp:380] data -> label
I0822 19:29:56.477799 31324 data_transformer.cpp:25] Loading mean file from: /home/kaiqi/imagenet/imagenet_mean.binaryproto
I0822 19:29:56.499824 31324 data_layer.cpp:45] output data size: 256,3,227,227
I0822 19:29:56.839301 31324 net.cpp:122] Setting up data
I0822 19:29:56.839335 31324 net.cpp:129] Top shape: 256 3 227 227 (39574272)
I0822 19:29:56.839342 31324 net.cpp:129] Top shape: 256 (256)
I0822 19:29:56.839346 31324 net.cpp:137] Memory required for data: 158298112
I0822 19:29:56.839355 31324 layer_factory.hpp:77] Creating layer conv1
I0822 19:29:56.839377 31324 net.cpp:84] Creating Layer conv1
I0822 19:29:56.839385 31324 net.cpp:406] conv1 <- data
I0822 19:29:56.839399 31324 net.cpp:380] conv1 -> conv1
I0822 19:29:58.669670 31324 net.cpp:122] Setting up conv1
I0822 19:29:58.669730 31324 net.cpp:129] Top shape: 256 96 55 55 (74342400)
I0822 19:29:58.669742 31324 net.cpp:137] Memory required for data: 455667712
I0822 19:29:58.669793 31324 layer_factory.hpp:77] Creating layer relu1
I0822 19:29:58.669816 31324 net.cpp:84] Creating Layer relu1
I0822 19:29:58.669826 31324 net.cpp:406] relu1 <- conv1
I0822 19:29:58.669845 31324 net.cpp:367] relu1 -> conv1 (in-place)
I0822 19:29:58.670696 31324 net.cpp:122] Setting up relu1
I0822 19:29:58.670722 31324 net.cpp:129] Top shape: 256 96 55 55 (74342400)
I0822 19:29:58.670740 31324 net.cpp:137] Memory required for data: 753037312
I0822 19:29:58.670765 31324 layer_factory.hpp:77] Creating layer norm1
I0822 19:29:58.670783 31324 net.cpp:84] Creating Layer norm1
I0822 19:29:58.670797 31324 net.cpp:406] norm1 <- conv1
I0822 19:29:58.670809 31324 net.cpp:380] norm1 -> norm1
I0822 19:29:58.672116 31324 net.cpp:122] Setting up norm1
I0822 19:29:58.672145 31324 net.cpp:129] Top shape: 256 96 55 55 (74342400)
I0822 19:29:58.672154 31324 net.cpp:137] Memory required for data: 1050406912
I0822 19:29:58.672163 31324 layer_factory.hpp:77] Creating layer pool1
I0822 19:29:58.672183 31324 net.cpp:84] Creating Layer pool1
I0822 19:29:58.672191 31324 net.cpp:406] pool1 <- norm1
I0822 19:29:58.672204 31324 net.cpp:380] pool1 -> pool1
I0822 19:29:58.672292 31324 net.cpp:122] Setting up pool1
I0822 19:29:58.672312 31324 net.cpp:129] Top shape: 256 96 27 27 (17915904)
I0822 19:29:58.672319 31324 net.cpp:137] Memory required for data: 1122070528
I0822 19:29:58.672327 31324 layer_factory.hpp:77] Creating layer conv2
I0822 19:29:58.672353 31324 net.cpp:84] Creating Layer conv2
I0822 19:29:58.672364 31324 net.cpp:406] conv2 <- pool1
I0822 19:29:58.672380 31324 net.cpp:380] conv2 -> conv2
I0822 19:29:58.685381 31324 net.cpp:122] Setting up conv2
I0822 19:29:58.685413 31324 net.cpp:129] Top shape: 256 256 27 27 (47775744)
I0822 19:29:58.685423 31324 net.cpp:137] Memory required for data: 1313173504
I0822 19:29:58.685441 31324 layer_factory.hpp:77] Creating layer relu2
I0822 19:29:58.685454 31324 net.cpp:84] Creating Layer relu2
I0822 19:29:58.685467 31324 net.cpp:406] relu2 <- conv2
I0822 19:29:58.685478 31324 net.cpp:367] relu2 -> conv2 (in-place)
I0822 19:29:58.686833 31324 net.cpp:122] Setting up relu2
I0822 19:29:58.686864 31324 net.cpp:129] Top shape: 256 256 27 27 (47775744)
I0822 19:29:58.686872 31324 net.cpp:137] Memory required for data: 1504276480
I0822 19:29:58.686882 31324 layer_factory.hpp:77] Creating layer norm2
I0822 19:29:58.686897 31324 net.cpp:84] Creating Layer norm2
I0822 19:29:58.686905 31324 net.cpp:406] norm2 <- conv2
I0822 19:29:58.686918 31324 net.cpp:380] norm2 -> norm2
I0822 19:29:58.687927 31324 net.cpp:122] Setting up norm2
I0822 19:29:58.687949 31324 net.cpp:129] Top shape: 256 256 27 27 (47775744)
I0822 19:29:58.687958 31324 net.cpp:137] Memory required for data: 1695379456
I0822 19:29:58.687964 31324 layer_factory.hpp:77] Creating layer pool2
I0822 19:29:58.687983 31324 net.cpp:84] Creating Layer pool2
I0822 19:29:58.687990 31324 net.cpp:406] pool2 <- norm2
I0822 19:29:58.688004 31324 net.cpp:380] pool2 -> pool2
I0822 19:29:58.688071 31324 net.cpp:122] Setting up pool2
I0822 19:29:58.688089 31324 net.cpp:129] Top shape: 256 256 13 13 (11075584)
I0822 19:29:58.688097 31324 net.cpp:137] Memory required for data: 1739681792
I0822 19:29:58.688103 31324 layer_factory.hpp:77] Creating layer conv3
I0822 19:29:58.688123 31324 net.cpp:84] Creating Layer conv3
I0822 19:29:58.688135 31324 net.cpp:406] conv3 <- pool2
I0822 19:29:58.688150 31324 net.cpp:380] conv3 -> conv3
I0822 19:29:58.706284 31324 net.cpp:122] Setting up conv3
I0822 19:29:58.706315 31324 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0822 19:29:58.706324 31324 net.cpp:137] Memory required for data: 1806135296
I0822 19:29:58.706344 31324 layer_factory.hpp:77] Creating layer relu3
I0822 19:29:58.706357 31324 net.cpp:84] Creating Layer relu3
I0822 19:29:58.706365 31324 net.cpp:406] relu3 <- conv3
I0822 19:29:58.706377 31324 net.cpp:367] relu3 -> conv3 (in-place)
I0822 19:29:58.707262 31324 net.cpp:122] Setting up relu3
I0822 19:29:58.707283 31324 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0822 19:29:58.707290 31324 net.cpp:137] Memory required for data: 1872588800
I0822 19:29:58.707298 31324 layer_factory.hpp:77] Creating layer conv4
I0822 19:29:58.707316 31324 net.cpp:84] Creating Layer conv4
I0822 19:29:58.707324 31324 net.cpp:406] conv4 <- conv3
I0822 19:29:58.707339 31324 net.cpp:380] conv4 -> conv4
I0822 19:29:58.724027 31324 net.cpp:122] Setting up conv4
I0822 19:29:58.724059 31324 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0822 19:29:58.724086 31324 net.cpp:137] Memory required for data: 1939042304
I0822 19:29:58.724099 31324 layer_factory.hpp:77] Creating layer relu4
I0822 19:29:58.724113 31324 net.cpp:84] Creating Layer relu4
I0822 19:29:58.724120 31324 net.cpp:406] relu4 <- conv4
I0822 19:29:58.724129 31324 net.cpp:367] relu4 -> conv4 (in-place)
I0822 19:29:58.725004 31324 net.cpp:122] Setting up relu4
I0822 19:29:58.725029 31324 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0822 19:29:58.725036 31324 net.cpp:137] Memory required for data: 2005495808
I0822 19:29:58.725042 31324 layer_factory.hpp:77] Creating layer conv5
I0822 19:29:58.725059 31324 net.cpp:84] Creating Layer conv5
I0822 19:29:58.725067 31324 net.cpp:406] conv5 <- conv4
I0822 19:29:58.725080 31324 net.cpp:380] conv5 -> conv5
I0822 19:29:58.737993 31324 net.cpp:122] Setting up conv5
I0822 19:29:58.738021 31324 net.cpp:129] Top shape: 256 256 13 13 (11075584)
I0822 19:29:58.738029 31324 net.cpp:137] Memory required for data: 2049798144
I0822 19:29:58.738049 31324 layer_factory.hpp:77] Creating layer relu5
I0822 19:29:58.738060 31324 net.cpp:84] Creating Layer relu5
I0822 19:29:58.738068 31324 net.cpp:406] relu5 <- conv5
I0822 19:29:58.738081 31324 net.cpp:367] relu5 -> conv5 (in-place)
I0822 19:29:58.738884 31324 net.cpp:122] Setting up relu5
I0822 19:29:58.738909 31324 net.cpp:129] Top shape: 256 256 13 13 (11075584)
I0822 19:29:58.738914 31324 net.cpp:137] Memory required for data: 2094100480
I0822 19:29:58.738922 31324 layer_factory.hpp:77] Creating layer pool5
I0822 19:29:58.738932 31324 net.cpp:84] Creating Layer pool5
I0822 19:29:58.738939 31324 net.cpp:406] pool5 <- conv5
I0822 19:29:58.738950 31324 net.cpp:380] pool5 -> pool5
I0822 19:29:58.739018 31324 net.cpp:122] Setting up pool5
I0822 19:29:58.739032 31324 net.cpp:129] Top shape: 256 256 6 6 (2359296)
I0822 19:29:58.739037 31324 net.cpp:137] Memory required for data: 2103537664
I0822 19:29:58.739043 31324 layer_factory.hpp:77] Creating layer fc6
I0822 19:29:58.739063 31324 net.cpp:84] Creating Layer fc6
I0822 19:29:58.739073 31324 net.cpp:406] fc6 <- pool5
I0822 19:29:58.739081 31324 net.cpp:380] fc6 -> fc6
I0822 19:29:59.081684 31324 net.cpp:122] Setting up fc6
I0822 19:29:59.081722 31324 net.cpp:129] Top shape: 256 4096 (1048576)
I0822 19:29:59.081727 31324 net.cpp:137] Memory required for data: 2107731968
I0822 19:29:59.081738 31324 layer_factory.hpp:77] Creating layer relu6
I0822 19:29:59.081755 31324 net.cpp:84] Creating Layer relu6
I0822 19:29:59.081763 31324 net.cpp:406] relu6 <- fc6
I0822 19:29:59.081769 31324 net.cpp:367] relu6 -> fc6 (in-place)
I0822 19:29:59.082352 31324 net.cpp:122] Setting up relu6
I0822 19:29:59.082365 31324 net.cpp:129] Top shape: 256 4096 (1048576)
I0822 19:29:59.082370 31324 net.cpp:137] Memory required for data: 2111926272
I0822 19:29:59.082375 31324 layer_factory.hpp:77] Creating layer drop6
I0822 19:29:59.082383 31324 net.cpp:84] Creating Layer drop6
I0822 19:29:59.082387 31324 net.cpp:406] drop6 <- fc6
I0822 19:29:59.082394 31324 net.cpp:367] drop6 -> fc6 (in-place)
I0822 19:29:59.082428 31324 net.cpp:122] Setting up drop6
I0822 19:29:59.082437 31324 net.cpp:129] Top shape: 256 4096 (1048576)
I0822 19:29:59.082442 31324 net.cpp:137] Memory required for data: 2116120576
I0822 19:29:59.082448 31324 layer_factory.hpp:77] Creating layer fc7
I0822 19:29:59.082456 31324 net.cpp:84] Creating Layer fc7
I0822 19:29:59.082460 31324 net.cpp:406] fc7 <- fc6
I0822 19:29:59.082468 31324 net.cpp:380] fc7 -> fc7
I0822 19:29:59.221560 31324 net.cpp:122] Setting up fc7
I0822 19:29:59.221597 31324 net.cpp:129] Top shape: 256 4096 (1048576)
I0822 19:29:59.221602 31324 net.cpp:137] Memory required for data: 2120314880
I0822 19:29:59.221612 31324 layer_factory.hpp:77] Creating layer relu7
I0822 19:29:59.221626 31324 net.cpp:84] Creating Layer relu7
I0822 19:29:59.221630 31324 net.cpp:406] relu7 <- fc7
I0822 19:29:59.221638 31324 net.cpp:367] relu7 -> fc7 (in-place)
I0822 19:29:59.222601 31324 net.cpp:122] Setting up relu7
I0822 19:29:59.222618 31324 net.cpp:129] Top shape: 256 4096 (1048576)
I0822 19:29:59.222638 31324 net.cpp:137] Memory required for data: 2124509184
I0822 19:29:59.222643 31324 layer_factory.hpp:77] Creating layer drop7
I0822 19:29:59.222652 31324 net.cpp:84] Creating Layer drop7
I0822 19:29:59.222657 31324 net.cpp:406] drop7 <- fc7
I0822 19:29:59.222666 31324 net.cpp:367] drop7 -> fc7 (in-place)
I0822 19:29:59.222695 31324 net.cpp:122] Setting up drop7
I0822 19:29:59.222704 31324 net.cpp:129] Top shape: 256 4096 (1048576)
I0822 19:29:59.222709 31324 net.cpp:137] Memory required for data: 2128703488
I0822 19:29:59.222714 31324 layer_factory.hpp:77] Creating layer fc8
I0822 19:29:59.222724 31324 net.cpp:84] Creating Layer fc8
I0822 19:29:59.222729 31324 net.cpp:406] fc8 <- fc7
I0822 19:29:59.222738 31324 net.cpp:380] fc8 -> fc8
I0822 19:29:59.256786 31324 net.cpp:122] Setting up fc8
I0822 19:29:59.256821 31324 net.cpp:129] Top shape: 256 1000 (256000)
I0822 19:29:59.256826 31324 net.cpp:137] Memory required for data: 2129727488
I0822 19:29:59.256837 31324 layer_factory.hpp:77] Creating layer loss
I0822 19:29:59.256850 31324 net.cpp:84] Creating Layer loss
I0822 19:29:59.256856 31324 net.cpp:406] loss <- fc8
I0822 19:29:59.256863 31324 net.cpp:406] loss <- label
I0822 19:29:59.256871 31324 net.cpp:380] loss -> loss
I0822 19:29:59.256886 31324 layer_factory.hpp:77] Creating layer loss
I0822 19:29:59.258491 31324 net.cpp:122] Setting up loss
I0822 19:29:59.258507 31324 net.cpp:129] Top shape: (1)
I0822 19:29:59.258512 31324 net.cpp:132]     with loss weight 1
I0822 19:29:59.258529 31324 net.cpp:137] Memory required for data: 2129727492
I0822 19:29:59.258534 31324 net.cpp:198] loss needs backward computation.
I0822 19:29:59.258543 31324 net.cpp:198] fc8 needs backward computation.
I0822 19:29:59.258548 31324 net.cpp:198] drop7 needs backward computation.
I0822 19:29:59.258553 31324 net.cpp:198] relu7 needs backward computation.
I0822 19:29:59.258558 31324 net.cpp:198] fc7 needs backward computation.
I0822 19:29:59.258561 31324 net.cpp:198] drop6 needs backward computation.
I0822 19:29:59.258566 31324 net.cpp:198] relu6 needs backward computation.
I0822 19:29:59.258570 31324 net.cpp:198] fc6 needs backward computation.
I0822 19:29:59.258575 31324 net.cpp:198] pool5 needs backward computation.
I0822 19:29:59.258579 31324 net.cpp:198] relu5 needs backward computation.
I0822 19:29:59.258584 31324 net.cpp:198] conv5 needs backward computation.
I0822 19:29:59.258589 31324 net.cpp:198] relu4 needs backward computation.
I0822 19:29:59.258594 31324 net.cpp:198] conv4 needs backward computation.
I0822 19:29:59.258599 31324 net.cpp:198] relu3 needs backward computation.
I0822 19:29:59.258604 31324 net.cpp:198] conv3 needs backward computation.
I0822 19:29:59.258608 31324 net.cpp:198] pool2 needs backward computation.
I0822 19:29:59.258613 31324 net.cpp:198] norm2 needs backward computation.
I0822 19:29:59.258617 31324 net.cpp:198] relu2 needs backward computation.
I0822 19:29:59.258622 31324 net.cpp:198] conv2 needs backward computation.
I0822 19:29:59.258627 31324 net.cpp:198] pool1 needs backward computation.
I0822 19:29:59.258632 31324 net.cpp:198] norm1 needs backward computation.
I0822 19:29:59.258636 31324 net.cpp:198] relu1 needs backward computation.
I0822 19:29:59.258642 31324 net.cpp:198] conv1 needs backward computation.
I0822 19:29:59.258647 31324 net.cpp:200] data does not need backward computation.
I0822 19:29:59.258651 31324 net.cpp:242] This network produces output loss
I0822 19:29:59.258666 31324 net.cpp:255] Network initialization done.
I0822 19:29:59.258743 31324 solver.cpp:72] Finetuning from /data/kaiqi/24_prune_quantization01/caffe_alexnet_train_admm_iter_2400000.caffemodel
I0822 19:30:01.164191 31324 solver.cpp:190] Creating test net (#0) specified by net file: models/bvlc_alexnet/train_val_admm.prototxt
I0822 19:30:01.164288 31324 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0822 19:30:01.164590 31324 net.cpp:51] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_file: "/home/kaiqi/imagenet/imagenet_mean.binaryproto"
  }
  data_param {
    source: "/home/kaiqi/imagenet/ilsvrc12_val_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
    rho: 0.0015
    clustering_num: 128
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
    rho: 0.0015
    clustering_num: 64
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
    rho: 0.0015
    clustering_num: 64
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
    rho: 0.0015
    clustering_num: 64
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
    rho: 0.0015
    clustering_num: 64
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
    rho: 0.0015
    clustering_num: 8
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
    rho: 0.0015
    clustering_num: 4
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
    rho: 0.0015
    clustering_num: 128
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 1
  }
}
layer {
  name: "accuracy5"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0822 19:30:01.164772 31324 layer_factory.hpp:77] Creating layer data
I0822 19:30:01.164887 31324 db_lmdb.cpp:35] Opened lmdb /home/kaiqi/imagenet/ilsvrc12_val_lmdb
I0822 19:30:01.164919 31324 net.cpp:84] Creating Layer data
I0822 19:30:01.164932 31324 net.cpp:380] data -> data
I0822 19:30:01.164949 31324 net.cpp:380] data -> label
I0822 19:30:01.164965 31324 data_transformer.cpp:25] Loading mean file from: /home/kaiqi/imagenet/imagenet_mean.binaryproto
I0822 19:30:01.166802 31324 data_layer.cpp:45] output data size: 50,3,227,227
I0822 19:30:01.238143 31324 net.cpp:122] Setting up data
I0822 19:30:01.238189 31324 net.cpp:129] Top shape: 50 3 227 227 (7729350)
I0822 19:30:01.238198 31324 net.cpp:129] Top shape: 50 (50)
I0822 19:30:01.238203 31324 net.cpp:137] Memory required for data: 30917600
I0822 19:30:01.238211 31324 layer_factory.hpp:77] Creating layer label_data_1_split
I0822 19:30:01.238229 31324 net.cpp:84] Creating Layer label_data_1_split
I0822 19:30:01.238235 31324 net.cpp:406] label_data_1_split <- label
I0822 19:30:01.238245 31324 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0822 19:30:01.238262 31324 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0822 19:30:01.238272 31324 net.cpp:380] label_data_1_split -> label_data_1_split_2
I0822 19:30:01.238356 31324 net.cpp:122] Setting up label_data_1_split
I0822 19:30:01.238368 31324 net.cpp:129] Top shape: 50 (50)
I0822 19:30:01.238374 31324 net.cpp:129] Top shape: 50 (50)
I0822 19:30:01.238382 31324 net.cpp:129] Top shape: 50 (50)
I0822 19:30:01.238387 31324 net.cpp:137] Memory required for data: 30918200
I0822 19:30:01.238392 31324 layer_factory.hpp:77] Creating layer conv1
I0822 19:30:01.238409 31324 net.cpp:84] Creating Layer conv1
I0822 19:30:01.238417 31324 net.cpp:406] conv1 <- data
I0822 19:30:01.238426 31324 net.cpp:380] conv1 -> conv1
I0822 19:30:01.241410 31324 net.cpp:122] Setting up conv1
I0822 19:30:01.241430 31324 net.cpp:129] Top shape: 50 96 55 55 (14520000)
I0822 19:30:01.241436 31324 net.cpp:137] Memory required for data: 88998200
I0822 19:30:01.241451 31324 layer_factory.hpp:77] Creating layer relu1
I0822 19:30:01.241461 31324 net.cpp:84] Creating Layer relu1
I0822 19:30:01.241466 31324 net.cpp:406] relu1 <- conv1
I0822 19:30:01.241474 31324 net.cpp:367] relu1 -> conv1 (in-place)
I0822 19:30:01.245002 31324 net.cpp:122] Setting up relu1
I0822 19:30:01.245023 31324 net.cpp:129] Top shape: 50 96 55 55 (14520000)
I0822 19:30:01.245029 31324 net.cpp:137] Memory required for data: 147078200
I0822 19:30:01.245035 31324 layer_factory.hpp:77] Creating layer norm1
I0822 19:30:01.245046 31324 net.cpp:84] Creating Layer norm1
I0822 19:30:01.245061 31324 net.cpp:406] norm1 <- conv1
I0822 19:30:01.245080 31324 net.cpp:380] norm1 -> norm1
I0822 19:30:01.245715 31324 net.cpp:122] Setting up norm1
I0822 19:30:01.245729 31324 net.cpp:129] Top shape: 50 96 55 55 (14520000)
I0822 19:30:01.245734 31324 net.cpp:137] Memory required for data: 205158200
I0822 19:30:01.245740 31324 layer_factory.hpp:77] Creating layer pool1
I0822 19:30:01.245757 31324 net.cpp:84] Creating Layer pool1
I0822 19:30:01.245764 31324 net.cpp:406] pool1 <- norm1
I0822 19:30:01.245772 31324 net.cpp:380] pool1 -> pool1
I0822 19:30:01.245820 31324 net.cpp:122] Setting up pool1
I0822 19:30:01.245831 31324 net.cpp:129] Top shape: 50 96 27 27 (3499200)
I0822 19:30:01.245836 31324 net.cpp:137] Memory required for data: 219155000
I0822 19:30:01.245841 31324 layer_factory.hpp:77] Creating layer conv2
I0822 19:30:01.245852 31324 net.cpp:84] Creating Layer conv2
I0822 19:30:01.245859 31324 net.cpp:406] conv2 <- pool1
I0822 19:30:01.245867 31324 net.cpp:380] conv2 -> conv2
I0822 19:30:01.253968 31324 net.cpp:122] Setting up conv2
I0822 19:30:01.254015 31324 net.cpp:129] Top shape: 50 256 27 27 (9331200)
I0822 19:30:01.254022 31324 net.cpp:137] Memory required for data: 256479800
I0822 19:30:01.254036 31324 layer_factory.hpp:77] Creating layer relu2
I0822 19:30:01.254046 31324 net.cpp:84] Creating Layer relu2
I0822 19:30:01.254051 31324 net.cpp:406] relu2 <- conv2
I0822 19:30:01.254060 31324 net.cpp:367] relu2 -> conv2 (in-place)
I0822 19:30:01.254603 31324 net.cpp:122] Setting up relu2
I0822 19:30:01.254616 31324 net.cpp:129] Top shape: 50 256 27 27 (9331200)
I0822 19:30:01.254622 31324 net.cpp:137] Memory required for data: 293804600
I0822 19:30:01.254628 31324 layer_factory.hpp:77] Creating layer norm2
I0822 19:30:01.254639 31324 net.cpp:84] Creating Layer norm2
I0822 19:30:01.254645 31324 net.cpp:406] norm2 <- conv2
I0822 19:30:01.254652 31324 net.cpp:380] norm2 -> norm2
I0822 19:30:01.255501 31324 net.cpp:122] Setting up norm2
I0822 19:30:01.255517 31324 net.cpp:129] Top shape: 50 256 27 27 (9331200)
I0822 19:30:01.255523 31324 net.cpp:137] Memory required for data: 331129400
I0822 19:30:01.255528 31324 layer_factory.hpp:77] Creating layer pool2
I0822 19:30:01.255537 31324 net.cpp:84] Creating Layer pool2
I0822 19:30:01.255543 31324 net.cpp:406] pool2 <- norm2
I0822 19:30:01.255550 31324 net.cpp:380] pool2 -> pool2
I0822 19:30:01.255597 31324 net.cpp:122] Setting up pool2
I0822 19:30:01.255609 31324 net.cpp:129] Top shape: 50 256 13 13 (2163200)
I0822 19:30:01.255615 31324 net.cpp:137] Memory required for data: 339782200
I0822 19:30:01.255620 31324 layer_factory.hpp:77] Creating layer conv3
I0822 19:30:01.255632 31324 net.cpp:84] Creating Layer conv3
I0822 19:30:01.255640 31324 net.cpp:406] conv3 <- pool2
I0822 19:30:01.255648 31324 net.cpp:380] conv3 -> conv3
I0822 19:30:01.267720 31324 net.cpp:122] Setting up conv3
I0822 19:30:01.267753 31324 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0822 19:30:01.267760 31324 net.cpp:137] Memory required for data: 352761400
I0822 19:30:01.267776 31324 layer_factory.hpp:77] Creating layer relu3
I0822 19:30:01.267786 31324 net.cpp:84] Creating Layer relu3
I0822 19:30:01.267792 31324 net.cpp:406] relu3 <- conv3
I0822 19:30:01.267802 31324 net.cpp:367] relu3 -> conv3 (in-place)
I0822 19:30:01.268342 31324 net.cpp:122] Setting up relu3
I0822 19:30:01.268355 31324 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0822 19:30:01.268362 31324 net.cpp:137] Memory required for data: 365740600
I0822 19:30:01.268366 31324 layer_factory.hpp:77] Creating layer conv4
I0822 19:30:01.268379 31324 net.cpp:84] Creating Layer conv4
I0822 19:30:01.268384 31324 net.cpp:406] conv4 <- conv3
I0822 19:30:01.268393 31324 net.cpp:380] conv4 -> conv4
I0822 19:30:01.279938 31324 net.cpp:122] Setting up conv4
I0822 19:30:01.279973 31324 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0822 19:30:01.279978 31324 net.cpp:137] Memory required for data: 378719800
I0822 19:30:01.279989 31324 layer_factory.hpp:77] Creating layer relu4
I0822 19:30:01.280000 31324 net.cpp:84] Creating Layer relu4
I0822 19:30:01.280015 31324 net.cpp:406] relu4 <- conv4
I0822 19:30:01.280033 31324 net.cpp:367] relu4 -> conv4 (in-place)
I0822 19:30:01.280578 31324 net.cpp:122] Setting up relu4
I0822 19:30:01.280594 31324 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0822 19:30:01.280599 31324 net.cpp:137] Memory required for data: 391699000
I0822 19:30:01.280603 31324 layer_factory.hpp:77] Creating layer conv5
I0822 19:30:01.280616 31324 net.cpp:84] Creating Layer conv5
I0822 19:30:01.280623 31324 net.cpp:406] conv5 <- conv4
I0822 19:30:01.280632 31324 net.cpp:380] conv5 -> conv5
I0822 19:30:01.291108 31324 net.cpp:122] Setting up conv5
I0822 19:30:01.291134 31324 net.cpp:129] Top shape: 50 256 13 13 (2163200)
I0822 19:30:01.291141 31324 net.cpp:137] Memory required for data: 400351800
I0822 19:30:01.291155 31324 layer_factory.hpp:77] Creating layer relu5
I0822 19:30:01.291165 31324 net.cpp:84] Creating Layer relu5
I0822 19:30:01.291172 31324 net.cpp:406] relu5 <- conv5
I0822 19:30:01.291179 31324 net.cpp:367] relu5 -> conv5 (in-place)
I0822 19:30:01.291692 31324 net.cpp:122] Setting up relu5
I0822 19:30:01.291704 31324 net.cpp:129] Top shape: 50 256 13 13 (2163200)
I0822 19:30:01.291709 31324 net.cpp:137] Memory required for data: 409004600
I0822 19:30:01.291714 31324 layer_factory.hpp:77] Creating layer pool5
I0822 19:30:01.291725 31324 net.cpp:84] Creating Layer pool5
I0822 19:30:01.291731 31324 net.cpp:406] pool5 <- conv5
I0822 19:30:01.291738 31324 net.cpp:380] pool5 -> pool5
I0822 19:30:01.291791 31324 net.cpp:122] Setting up pool5
I0822 19:30:01.291801 31324 net.cpp:129] Top shape: 50 256 6 6 (460800)
I0822 19:30:01.291806 31324 net.cpp:137] Memory required for data: 410847800
I0822 19:30:01.291810 31324 layer_factory.hpp:77] Creating layer fc6
I0822 19:30:01.291821 31324 net.cpp:84] Creating Layer fc6
I0822 19:30:01.291826 31324 net.cpp:406] fc6 <- pool5
I0822 19:30:01.291832 31324 net.cpp:380] fc6 -> fc6
I0822 19:30:01.607568 31324 net.cpp:122] Setting up fc6
I0822 19:30:01.607609 31324 net.cpp:129] Top shape: 50 4096 (204800)
I0822 19:30:01.607614 31324 net.cpp:137] Memory required for data: 411667000
I0822 19:30:01.607623 31324 layer_factory.hpp:77] Creating layer relu6
I0822 19:30:01.607633 31324 net.cpp:84] Creating Layer relu6
I0822 19:30:01.607640 31324 net.cpp:406] relu6 <- fc6
I0822 19:30:01.607648 31324 net.cpp:367] relu6 -> fc6 (in-place)
I0822 19:30:01.608660 31324 net.cpp:122] Setting up relu6
I0822 19:30:01.608676 31324 net.cpp:129] Top shape: 50 4096 (204800)
I0822 19:30:01.608682 31324 net.cpp:137] Memory required for data: 412486200
I0822 19:30:01.608686 31324 layer_factory.hpp:77] Creating layer drop6
I0822 19:30:01.608695 31324 net.cpp:84] Creating Layer drop6
I0822 19:30:01.608700 31324 net.cpp:406] drop6 <- fc6
I0822 19:30:01.608705 31324 net.cpp:367] drop6 -> fc6 (in-place)
I0822 19:30:01.608738 31324 net.cpp:122] Setting up drop6
I0822 19:30:01.608747 31324 net.cpp:129] Top shape: 50 4096 (204800)
I0822 19:30:01.608752 31324 net.cpp:137] Memory required for data: 413305400
I0822 19:30:01.608757 31324 layer_factory.hpp:77] Creating layer fc7
I0822 19:30:01.608765 31324 net.cpp:84] Creating Layer fc7
I0822 19:30:01.608770 31324 net.cpp:406] fc7 <- fc6
I0822 19:30:01.608777 31324 net.cpp:380] fc7 -> fc7
I0822 19:30:01.748076 31324 net.cpp:122] Setting up fc7
I0822 19:30:01.748114 31324 net.cpp:129] Top shape: 50 4096 (204800)
I0822 19:30:01.748119 31324 net.cpp:137] Memory required for data: 414124600
I0822 19:30:01.748131 31324 layer_factory.hpp:77] Creating layer relu7
I0822 19:30:01.748142 31324 net.cpp:84] Creating Layer relu7
I0822 19:30:01.748148 31324 net.cpp:406] relu7 <- fc7
I0822 19:30:01.748157 31324 net.cpp:367] relu7 -> fc7 (in-place)
I0822 19:30:01.748711 31324 net.cpp:122] Setting up relu7
I0822 19:30:01.748725 31324 net.cpp:129] Top shape: 50 4096 (204800)
I0822 19:30:01.748729 31324 net.cpp:137] Memory required for data: 414943800
I0822 19:30:01.748734 31324 layer_factory.hpp:77] Creating layer drop7
I0822 19:30:01.748741 31324 net.cpp:84] Creating Layer drop7
I0822 19:30:01.748755 31324 net.cpp:406] drop7 <- fc7
I0822 19:30:01.748772 31324 net.cpp:367] drop7 -> fc7 (in-place)
I0822 19:30:01.748805 31324 net.cpp:122] Setting up drop7
I0822 19:30:01.748814 31324 net.cpp:129] Top shape: 50 4096 (204800)
I0822 19:30:01.748819 31324 net.cpp:137] Memory required for data: 415763000
I0822 19:30:01.748824 31324 layer_factory.hpp:77] Creating layer fc8
I0822 19:30:01.748832 31324 net.cpp:84] Creating Layer fc8
I0822 19:30:01.748837 31324 net.cpp:406] fc8 <- fc7
I0822 19:30:01.748844 31324 net.cpp:380] fc8 -> fc8
I0822 19:30:01.783187 31324 net.cpp:122] Setting up fc8
I0822 19:30:01.783219 31324 net.cpp:129] Top shape: 50 1000 (50000)
I0822 19:30:01.783224 31324 net.cpp:137] Memory required for data: 415963000
I0822 19:30:01.783236 31324 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0822 19:30:01.783244 31324 net.cpp:84] Creating Layer fc8_fc8_0_split
I0822 19:30:01.783251 31324 net.cpp:406] fc8_fc8_0_split <- fc8
I0822 19:30:01.783258 31324 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0822 19:30:01.783268 31324 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0822 19:30:01.783277 31324 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_2
I0822 19:30:01.783332 31324 net.cpp:122] Setting up fc8_fc8_0_split
I0822 19:30:01.783340 31324 net.cpp:129] Top shape: 50 1000 (50000)
I0822 19:30:01.783345 31324 net.cpp:129] Top shape: 50 1000 (50000)
I0822 19:30:01.783350 31324 net.cpp:129] Top shape: 50 1000 (50000)
I0822 19:30:01.783354 31324 net.cpp:137] Memory required for data: 416563000
I0822 19:30:01.783358 31324 layer_factory.hpp:77] Creating layer accuracy
I0822 19:30:01.783368 31324 net.cpp:84] Creating Layer accuracy
I0822 19:30:01.783373 31324 net.cpp:406] accuracy <- fc8_fc8_0_split_0
I0822 19:30:01.783380 31324 net.cpp:406] accuracy <- label_data_1_split_0
I0822 19:30:01.783396 31324 net.cpp:380] accuracy -> accuracy
I0822 19:30:01.783406 31324 net.cpp:122] Setting up accuracy
I0822 19:30:01.783411 31324 net.cpp:129] Top shape: (1)
I0822 19:30:01.783417 31324 net.cpp:137] Memory required for data: 416563004
I0822 19:30:01.783422 31324 layer_factory.hpp:77] Creating layer accuracy5
I0822 19:30:01.783428 31324 net.cpp:84] Creating Layer accuracy5
I0822 19:30:01.783433 31324 net.cpp:406] accuracy5 <- fc8_fc8_0_split_1
I0822 19:30:01.783438 31324 net.cpp:406] accuracy5 <- label_data_1_split_1
I0822 19:30:01.783445 31324 net.cpp:380] accuracy5 -> accuracy5
I0822 19:30:01.783453 31324 net.cpp:122] Setting up accuracy5
I0822 19:30:01.783458 31324 net.cpp:129] Top shape: (1)
I0822 19:30:01.783463 31324 net.cpp:137] Memory required for data: 416563008
I0822 19:30:01.783466 31324 layer_factory.hpp:77] Creating layer loss
I0822 19:30:01.783474 31324 net.cpp:84] Creating Layer loss
I0822 19:30:01.783481 31324 net.cpp:406] loss <- fc8_fc8_0_split_2
I0822 19:30:01.783486 31324 net.cpp:406] loss <- label_data_1_split_2
I0822 19:30:01.783491 31324 net.cpp:380] loss -> loss
I0822 19:30:01.783502 31324 layer_factory.hpp:77] Creating layer loss
I0822 19:30:01.784536 31324 net.cpp:122] Setting up loss
I0822 19:30:01.784551 31324 net.cpp:129] Top shape: (1)
I0822 19:30:01.784555 31324 net.cpp:132]     with loss weight 1
I0822 19:30:01.784567 31324 net.cpp:137] Memory required for data: 416563012
I0822 19:30:01.784571 31324 net.cpp:198] loss needs backward computation.
I0822 19:30:01.784579 31324 net.cpp:200] accuracy5 does not need backward computation.
I0822 19:30:01.784582 31324 net.cpp:200] accuracy does not need backward computation.
I0822 19:30:01.784588 31324 net.cpp:198] fc8_fc8_0_split needs backward computation.
I0822 19:30:01.784592 31324 net.cpp:198] fc8 needs backward computation.
I0822 19:30:01.784597 31324 net.cpp:198] drop7 needs backward computation.
I0822 19:30:01.784601 31324 net.cpp:198] relu7 needs backward computation.
I0822 19:30:01.784605 31324 net.cpp:198] fc7 needs backward computation.
I0822 19:30:01.784610 31324 net.cpp:198] drop6 needs backward computation.
I0822 19:30:01.784615 31324 net.cpp:198] relu6 needs backward computation.
I0822 19:30:01.784618 31324 net.cpp:198] fc6 needs backward computation.
I0822 19:30:01.784632 31324 net.cpp:198] pool5 needs backward computation.
I0822 19:30:01.784646 31324 net.cpp:198] relu5 needs backward computation.
I0822 19:30:01.784651 31324 net.cpp:198] conv5 needs backward computation.
I0822 19:30:01.784657 31324 net.cpp:198] relu4 needs backward computation.
I0822 19:30:01.784662 31324 net.cpp:198] conv4 needs backward computation.
I0822 19:30:01.784665 31324 net.cpp:198] relu3 needs backward computation.
I0822 19:30:01.784672 31324 net.cpp:198] conv3 needs backward computation.
I0822 19:30:01.784677 31324 net.cpp:198] pool2 needs backward computation.
I0822 19:30:01.784682 31324 net.cpp:198] norm2 needs backward computation.
I0822 19:30:01.784687 31324 net.cpp:198] relu2 needs backward computation.
I0822 19:30:01.784693 31324 net.cpp:198] conv2 needs backward computation.
I0822 19:30:01.784698 31324 net.cpp:198] pool1 needs backward computation.
I0822 19:30:01.784703 31324 net.cpp:198] norm1 needs backward computation.
I0822 19:30:01.784710 31324 net.cpp:198] relu1 needs backward computation.
I0822 19:30:01.784714 31324 net.cpp:198] conv1 needs backward computation.
I0822 19:30:01.784719 31324 net.cpp:200] label_data_1_split does not need backward computation.
I0822 19:30:01.784725 31324 net.cpp:200] data does not need backward computation.
I0822 19:30:01.784729 31324 net.cpp:242] This network produces output accuracy
I0822 19:30:01.784734 31324 net.cpp:242] This network produces output accuracy5
I0822 19:30:01.784739 31324 net.cpp:242] This network produces output loss
I0822 19:30:01.784757 31324 net.cpp:255] Network initialization done.
I0822 19:30:01.784832 31324 solver.cpp:72] Finetuning from /data/kaiqi/24_prune_quantization01/caffe_alexnet_train_admm_iter_2400000.caffemodel
I0822 19:30:01.986801 31324 solver.cpp:57] Solver scaffolding done.
0layer128
2layer64
4layer64
6layer64
8layer64
10layer8
12layer4
14layer128
I0822 19:30:01.988346 31324 caffe.cpp:265] Load centroids from /data/kaiqi/24_prune_quantization01/caffe_alexnet_train_admm_iter_2400000.solverstate.centroids
I0822 19:30:02.015357 31324 sgd_solver.cpp:1242] SGDSolver: restoring centroids
I0822 19:30:02.015729 31324 caffe.cpp:269] Load centroidranges from /data/kaiqi/24_prune_quantization01/caffe_alexnet_train_admm_iter_2400000.solverstate.centroidsrange
I0822 19:30:02.016091 31324 sgd_solver.cpp:1275] SGDSolver: restoring centroids_ranges_
I0822 19:30:02.016450 31324 caffe.cpp:273] Starting Optimization
I0822 19:30:02.016460 31324 solver.cpp:308] Solving AlexNet
I0822 19:30:02.016465 31324 solver.cpp:309] Learning Rate Policy: step
you going to keep pruned weight unchanged part
you going to retrain quantization start part 
before partial quantization
layer 0 number cluster 28223
layer0num zero6621
global centroids
-0.411235
-0.408023
-0.40481
-0.401597
-0.398384
-0.395172
-0.391959
-0.388746
-0.385533
-0.38232
-0.379108
-0.375895
-0.372682
-0.369469
-0.366257
-0.363044
-0.359831
-0.356618
-0.353405
-0.350193
-0.34698
-0.343767
-0.340554
-0.337342
-0.334129
-0.330916
-0.327703
-0.32449
-0.321278
-0.318065
-0.314852
-0.311639
-0.308427
-0.305214
-0.302001
-0.298788
-0.295575
-0.292363
-0.28915
-0.285937
-0.282724
-0.279512
-0.276299
-0.273086
-0.269873
-0.26666
-0.263448
-0.260235
-0.257022
-0.253809
-0.250597
-0.247384
-0.244171
-0.240958
-0.237745
-0.234533
-0.23132
-0.228107
-0.224894
-0.221682
-0.218469
-0.215256
-0.212043
-0.208831
-0.205618
-0.202405
-0.199192
-0.195979
-0.192767
-0.189554
-0.186341
-0.183128
-0.179916
-0.176703
-0.17349
-0.170277
-0.167064
-0.163852
-0.160639
-0.157426
-0.154213
-0.151001
-0.147788
-0.144575
-0.141362
-0.138149
-0.134937
-0.131724
-0.128511
-0.125298
-0.122086
-0.118873
-0.11566
-0.112447
-0.109234
-0.106022
-0.102809
-0.0995961
-0.0963833
-0.0931705
-0.0899578
-0.086745
-0.0835322
-0.0803194
-0.0771066
-0.0738939
-0.0706811
-0.0674683
-0.0642555
-0.0610428
-0.05783
-0.0546172
-0.0514044
-0.0481917
-0.0449789
-0.0417661
-0.0385533
-0.0353405
-0.0321278
-0.028915
-0.0257022
-0.0224894
-0.0192767
-0.0160639
-0.0128511
-0.00963833
-0.00642555
-0.00321278
0.00321278
0.00642555
0.00963833
0.0128511
0.0160639
0.0192767
0.0224894
0.0257022
0.028915
0.0321278
0.0353405
0.0385533
0.0417661
0.0449789
0.0481917
0.0514044
0.0546172
0.05783
0.0610428
0.0642555
0.0674683
0.0706811
0.0738939
0.0771066
0.0803194
0.0835322
0.086745
0.0899578
0.0931705
0.0963833
0.0995961
0.102809
0.106022
0.109234
0.112447
0.11566
0.118873
0.122086
0.125298
0.128511
0.131724
0.134937
0.138149
0.141362
0.144575
0.147788
0.151001
0.154213
0.157426
0.160639
0.163852
0.167064
0.170277
0.17349
0.176703
0.179916
0.183128
0.186341
0.189554
0.192767
0.195979
0.199192
0.202405
0.205618
0.208831
0.212043
0.215256
0.218469
0.221682
0.224894
0.228107
0.23132
0.234533
0.237745
0.240958
0.244171
0.247384
0.250597
0.253809
0.257022
0.260235
0.263448
0.26666
0.269873
0.273086
0.276299
0.279512
0.282724
0.285937
0.28915
0.292363
0.295575
0.298788
0.302001
0.305214
0.308427
0.311639
0.314852
0.318065
0.321278
0.32449
0.327703
0.330916
0.334129
0.337342
0.340554
0.343767
0.34698
0.350193
0.353405
0.356618
0.359831
0.363044
0.366257
0.369469
0.372682
0.375895
0.379108
0.38232
0.385533
0.388746
0.391959
0.395172
0.398384
0.401597
0.40481
0.408023
0.411235
num zero in mask
layer0num zero6621
start to project threshold
centroids_count: 256
centroids_ranges_count: 255
layer0quantized modify: 0
layer0threshold modify: 5738
after partial num zero in mask
layer0num zero12359
after partial num zero in weight
layer0num zero6621
after partial quantization
layer 0 number cluster 22700
before partial quantization
layer 2 number cluster 61404
layer2num zero245760
global centroids
-0.406104
-0.399759
-0.393413
-0.387068
-0.380723
-0.374377
-0.368032
-0.361687
-0.355341
-0.348996
-0.34265
-0.336305
-0.32996
-0.323614
-0.317269
-0.310924
-0.304578
-0.298233
-0.291887
-0.285542
-0.279197
-0.272851
-0.266506
-0.26016
-0.253815
-0.24747
-0.241124
-0.234779
-0.228434
-0.222088
-0.215743
-0.209397
-0.203052
-0.196707
-0.190361
-0.184016
-0.177671
-0.171325
-0.16498
-0.158634
-0.152289
-0.145944
-0.139598
-0.133253
-0.126908
-0.120562
-0.114217
-0.107871
-0.101526
-0.0951807
-0.0888353
-0.0824899
-0.0761445
-0.0697992
-0.0634538
-0.0571084
-0.050763
-0.0444176
-0.0380723
-0.0317269
-0.0253815
-0.0190361
-0.0126908
-0.00634538
0.00634538
0.0126908
0.0190361
0.0253815
0.0317269
0.0380723
0.0444176
0.050763
0.0571084
0.0634538
0.0697992
0.0761445
0.0824899
0.0888353
0.0951807
0.101526
0.107871
0.114217
0.120562
0.126908
0.133253
0.139598
0.145944
0.152289
0.158634
0.16498
0.171325
0.177671
0.184016
0.190361
0.196707
0.203052
0.209397
0.215743
0.222088
0.228434
0.234779
0.241124
0.24747
0.253815
0.26016
0.266506
0.272851
0.279197
0.285542
0.291887
0.298233
0.304578
0.310924
0.317269
0.323614
0.32996
0.336305
0.34265
0.348996
0.355341
0.361687
0.368032
0.374377
0.380723
0.387068
0.393413
0.399759
0.406104
num zero in mask
layer2num zero245760
start to project threshold
centroids_count: 128
centroids_ranges_count: 127
layer2quantized modify: 0
layer2threshold modify: 12335
after partial num zero in mask
layer2num zero258095
after partial num zero in weight
layer2num zero245760
after partial quantization
layer 2 number cluster 49175
before partial quantization
layer 4 number cluster 167729
layer4num zero716636
global centroids
-0.414245
-0.407773
-0.4013
-0.394828
-0.388355
-0.381882
-0.37541
-0.368937
-0.362465
-0.355992
-0.34952
-0.343047
-0.336574
-0.330102
-0.323629
-0.317157
-0.310684
-0.304211
-0.297739
-0.291266
-0.284794
-0.278321
-0.271849
-0.265376
-0.258903
-0.252431
-0.245958
-0.239486
-0.233013
-0.22654
-0.220068
-0.213595
-0.207123
-0.20065
-0.194178
-0.187705
-0.181232
-0.17476
-0.168287
-0.161815
-0.155342
-0.148869
-0.142397
-0.135924
-0.129452
-0.122979
-0.116507
-0.110034
-0.103561
-0.0970888
-0.0906162
-0.0841436
-0.077671
-0.0711984
-0.0647258
-0.0582533
-0.0517807
-0.0453081
-0.0388355
-0.0323629
-0.0258903
-0.0194178
-0.0129452
-0.00647258
0.00647258
0.0129452
0.0194178
0.0258903
0.0323629
0.0388355
0.0453081
0.0517807
0.0582533
0.0647258
0.0711984
0.077671
0.0841436
0.0906162
0.0970888
0.103561
0.110034
0.116507
0.122979
0.129452
0.135924
0.142397
0.148869
0.155342
0.161815
0.168287
0.17476
0.181232
0.187705
0.194178
0.20065
0.207123
0.213595
0.220068
0.22654
0.233013
0.239486
0.245958
0.252431
0.258903
0.265376
0.271849
0.278321
0.284794
0.291266
0.297739
0.304211
0.310684
0.317157
0.323629
0.330102
0.336574
0.343047
0.34952
0.355992
0.362465
0.368937
0.37541
0.381882
0.388355
0.394828
0.4013
0.407773
0.414245
num zero in mask
layer4num zero716636
start to project threshold
centroids_count: 128
centroids_ranges_count: 127
layer4quantized modify: 0
layer4threshold modify: 33656
after partial num zero in mask
layer4num zero750292
after partial num zero in weight
layer4num zero716636
after partial quantization
layer 4 number cluster 134251
before partial quantization
layer 6 number cluster 132453
layer6num zero530841
global centroids
-0.323898
-0.318837
-0.313776
-0.308715
-0.303655
-0.298594
-0.293533
-0.288472
-0.283411
-0.27835
-0.273289
-0.268228
-0.263167
-0.258106
-0.253045
-0.247985
-0.242924
-0.237863
-0.232802
-0.227741
-0.22268
-0.217619
-0.212558
-0.207497
-0.202436
-0.197375
-0.192315
-0.187254
-0.182193
-0.177132
-0.172071
-0.16701
-0.161949
-0.156888
-0.151827
-0.146766
-0.141705
-0.136645
-0.131584
-0.126523
-0.121462
-0.116401
-0.11134
-0.106279
-0.101218
-0.0961573
-0.0910964
-0.0860355
-0.0809745
-0.0759136
-0.0708527
-0.0657918
-0.0607309
-0.05567
-0.0506091
-0.0455482
-0.0404873
-0.0354264
-0.0303655
-0.0253045
-0.0202436
-0.0151827
-0.0101218
-0.00506091
0.00506091
0.0101218
0.0151827
0.0202436
0.0253045
0.0303655
0.0354264
0.0404873
0.0455482
0.0506091
0.05567
0.0607309
0.0657918
0.0708527
0.0759136
0.0809745
0.0860355
0.0910964
0.0961573
0.101218
0.106279
0.11134
0.116401
0.121462
0.126523
0.131584
0.136645
0.141705
0.146766
0.151827
0.156888
0.161949
0.16701
0.172071
0.177132
0.182193
0.187254
0.192315
0.197375
0.202436
0.207497
0.212558
0.217619
0.22268
0.227741
0.232802
0.237863
0.242924
0.247985
0.253045
0.258106
0.263167
0.268228
0.273289
0.27835
0.283411
0.288472
0.293533
0.298594
0.303655
0.308715
0.313776
0.318837
0.323898
num zero in mask
layer6num zero530841
start to project threshold
centroids_count: 128
centroids_ranges_count: 127
layer6quantized modify: 0
layer6threshold modify: 26584
after partial num zero in mask
layer6num zero557425
after partial num zero in weight
layer6num zero530841
after partial quantization
layer 6 number cluster 106022
before partial quantization
layer 8 number cluster 88376
layer8num zero353894
global centroids
-0.356374
-0.350806
-0.345237
-0.339669
-0.334101
-0.328532
-0.322964
-0.317396
-0.311827
-0.306259
-0.300691
-0.295122
-0.289554
-0.283985
-0.278417
-0.272849
-0.26728
-0.261712
-0.256144
-0.250575
-0.245007
-0.239439
-0.23387
-0.228302
-0.222734
-0.217165
-0.211597
-0.206029
-0.20046
-0.194892
-0.189324
-0.183755
-0.178187
-0.172619
-0.16705
-0.161482
-0.155914
-0.150345
-0.144777
-0.139209
-0.13364
-0.128072
-0.122504
-0.116935
-0.111367
-0.105799
-0.10023
-0.0946618
-0.0890935
-0.0835252
-0.0779568
-0.0723885
-0.0668201
-0.0612518
-0.0556834
-0.0501151
-0.0445467
-0.0389784
-0.0334101
-0.0278417
-0.0222734
-0.016705
-0.0111367
-0.00556834
0.00556834
0.0111367
0.016705
0.0222734
0.0278417
0.0334101
0.0389784
0.0445467
0.0501151
0.0556834
0.0612518
0.0668201
0.0723885
0.0779568
0.0835252
0.0890935
0.0946618
0.10023
0.105799
0.111367
0.116935
0.122504
0.128072
0.13364
0.139209
0.144777
0.150345
0.155914
0.161482
0.16705
0.172619
0.178187
0.183755
0.189324
0.194892
0.20046
0.206029
0.211597
0.217165
0.222734
0.228302
0.23387
0.239439
0.245007
0.250575
0.256144
0.261712
0.26728
0.272849
0.278417
0.283985
0.289554
0.295122
0.300691
0.306259
0.311827
0.317396
0.322964
0.328532
0.334101
0.339669
0.345237
0.350806
0.356374
num zero in mask
layer8num zero353894
start to project threshold
centroids_count: 128
centroids_ranges_count: 127
layer8quantized modify: 0
layer8threshold modify: 17732
after partial num zero in mask
layer8num zero371626
after partial num zero in weight
layer8num zero353894
after partial quantization
layer 8 number cluster 70764
before partial quantization
layer 10 number cluster 746290
layer10num zero36993760
global centroids
-0.0638484
-0.0558673
-0.0478863
-0.0399052
-0.0319242
-0.0239431
-0.0159621
-0.00798105
0.00798105
0.0159621
0.0239431
0.0319242
0.0399052
0.0478863
0.0558673
0.0638484
num zero in mask
layer10num zero36993760
start to project threshold
centroids_count: 16
centroids_ranges_count: 15
layer10quantized modify: 1
layer10threshold modify: 151001
after partial num zero in mask
layer10num zero37144762
after partial num zero in weight
layer10num zero36993760
after partial quantization
layer 10 number cluster 597505
before partial quantization
layer 12 number cluster 878485
layer12num zero15871246
global centroids
-0.0882365
-0.0661774
-0.0441183
-0.0220591
0.0220591
0.0441183
0.0661774
0.0882365
num zero in mask
layer12num zero15871246
start to project threshold
centroids_count: 8
centroids_ranges_count: 7
layer12quantized modify: 0
layer12threshold modify: 181197
after partial num zero in mask
layer12num zero16052443
after partial num zero in weight
layer12num zero15871246
after partial quantization
layer 12 number cluster 707484
before partial quantization
layer 14 number cluster 324826
layer14num zero3768320
global centroids
-0.0989526
-0.0981795
-0.0974064
-0.0966334
-0.0958603
-0.0950872
-0.0943142
-0.0935411
-0.092768
-0.091995
-0.0912219
-0.0904488
-0.0896758
-0.0889027
-0.0881296
-0.0873566
-0.0865835
-0.0858104
-0.0850374
-0.0842643
-0.0834912
-0.0827181
-0.0819451
-0.081172
-0.0803989
-0.0796259
-0.0788528
-0.0780798
-0.0773067
-0.0765336
-0.0757606
-0.0749875
-0.0742144
-0.0734413
-0.0726683
-0.0718952
-0.0711221
-0.0703491
-0.069576
-0.0688029
-0.0680299
-0.0672568
-0.0664838
-0.0657107
-0.0649376
-0.0641645
-0.0633915
-0.0626184
-0.0618453
-0.0610723
-0.0602992
-0.0595261
-0.0587531
-0.05798
-0.0572069
-0.0564339
-0.0556608
-0.0548877
-0.0541147
-0.0533416
-0.0525685
-0.0517955
-0.0510224
-0.0502493
-0.0494763
-0.0487032
-0.0479301
-0.0471571
-0.046384
-0.0456109
-0.0448379
-0.0440648
-0.0432917
-0.0425187
-0.0417456
-0.0409725
-0.0401995
-0.0394264
-0.0386533
-0.0378803
-0.0371072
-0.0363341
-0.0355611
-0.034788
-0.0340149
-0.0332419
-0.0324688
-0.0316957
-0.0309227
-0.0301496
-0.0293765
-0.0286035
-0.0278304
-0.0270573
-0.0262843
-0.0255112
-0.0247381
-0.0239651
-0.023192
-0.0224189
-0.0216459
-0.0208728
-0.0200997
-0.0193267
-0.0185536
-0.0177805
-0.0170075
-0.0162344
-0.0154613
-0.0146883
-0.0139152
-0.0131421
-0.0123691
-0.011596
-0.0108229
-0.0100499
-0.0092768
-0.00850374
-0.00773067
-0.0069576
-0.00618453
-0.00541147
-0.0046384
-0.00386533
-0.00309227
-0.0023192
-0.00154613
-0.000773067
0.000773067
0.00154613
0.0023192
0.00309227
0.00386533
0.0046384
0.00541147
0.00618453
0.0069576
0.00773067
0.00850374
0.0092768
0.0100499
0.0108229
0.011596
0.0123691
0.0131421
0.0139152
0.0146883
0.0154613
0.0162344
0.0170075
0.0177805
0.0185536
0.0193267
0.0200997
0.0208728
0.0216459
0.0224189
0.023192
0.0239651
0.0247381
0.0255112
0.0262843
0.0270573
0.0278304
0.0286035
0.0293765
0.0301496
0.0309227
0.0316957
0.0324688
0.0332419
0.0340149
0.034788
0.0355611
0.0363341
0.0371072
0.0378803
0.0386533
0.0394264
0.0401995
0.0409725
0.0417456
0.0425187
0.0432917
0.0440648
0.0448379
0.0456109
0.046384
0.0471571
0.0479301
0.0487032
0.0494763
0.0502493
0.0510224
0.0517955
0.0525685
0.0533416
0.0541147
0.0548877
0.0556608
0.0564339
0.0572069
0.05798
0.0587531
0.0595261
0.0602992
0.0610723
0.0618453
0.0626184
0.0633915
0.0641645
0.0649376
0.0657107
0.0664838
0.0672568
0.0680299
0.0688029
0.069576
0.0703491
0.0711221
0.0718952
0.0726683
0.0734413
0.0742144
0.0749875
0.0757606
0.0765336
0.0773067
0.0780798
0.0788528
0.0796259
0.0803989
0.081172
0.0819451
0.0827181
0.0834912
0.0842643
0.0850374
0.0858104
0.0865835
0.0873566
0.0881296
0.0889027
0.0896758
0.0904488
0.0912219
0.091995
0.092768
0.0935411
0.0943142
0.0950872
0.0958603
0.0966334
0.0974064
0.0981795
0.0989526
num zero in mask
layer14num zero3768320
start to project threshold
centroids_count: 256
centroids_ranges_count: 255
layer14quantized modify: 2
layer14threshold modify: 65629
after partial num zero in mask
layer14num zero3833951
after partial num zero in weight
layer14num zero3768320
after partial quantization
layer 14 number cluster 259954
I0822 19:30:14.752948 31324 solver.cpp:483] Snapshotting to binary proto file /data/kaiqi/24_prune_quantization01/caffe_alexnet_1st_retrain_iter_0.caffemodel
I0822 19:30:15.613082 31324 sgd_solver.cpp:1201] Snapshotting solver state to binary proto file /data/kaiqi/24_prune_quantization01/caffe_alexnet_1st_retrain_iter_0.solverstate
I0822 19:30:15.932170 31324 solver.cpp:366] Iteration 0, Testing net (#0)
I0822 19:30:16.030231 31324 blocking_queue.cpp:49] Waiting for data
I0822 19:30:38.988837 31336 data_layer.cpp:73] Restarting data prefetching from start.
I0822 19:30:39.004362 31324 solver.cpp:433]     Test net output #0: accuracy = 0.56278
I0822 19:30:39.004393 31324 solver.cpp:433]     Test net output #1: accuracy5 = 0.799281
I0822 19:30:39.004403 31324 solver.cpp:433]     Test net output #2: loss = 1.87656 (* 1 = 1.87656 loss)
I0822 19:30:39.169139 31324 solver.cpp:254] Iteration 0 (-nan iter/s, 23.2387s/20 iters), loss = 1.82229
I0822 19:30:39.171525 31324 solver.cpp:273]     Train net output #0: loss = 1.82229 (* 1 = 1.82229 loss)
I0822 19:30:39.171553 31324 sgd_solver.cpp:790] Iteration 0, lr = 0.01
I0822 19:30:40.683733 31324 blocking_queue.cpp:49] Waiting for data
I0822 19:30:43.423175 31324 solver.cpp:254] Iteration 20 (4.70409 iter/s, 4.25162s/20 iters), loss = 2.80358
I0822 19:30:43.423244 31324 solver.cpp:273]     Train net output #0: loss = 2.80358 (* 1 = 2.80358 loss)
I0822 19:30:43.423259 31324 sgd_solver.cpp:790] Iteration 20, lr = 0.01
I0822 19:30:47.384760 31324 solver.cpp:254] Iteration 40 (5.04862 iter/s, 3.96148s/20 iters), loss = 2.38868
I0822 19:30:47.384826 31324 solver.cpp:273]     Train net output #0: loss = 2.38868 (* 1 = 2.38868 loss)
I0822 19:30:47.384837 31324 sgd_solver.cpp:790] Iteration 40, lr = 0.01
I0822 19:30:51.405864 31324 solver.cpp:254] Iteration 60 (4.9739 iter/s, 4.02099s/20 iters), loss = 2.61822
I0822 19:30:51.405941 31324 solver.cpp:273]     Train net output #0: loss = 2.61822 (* 1 = 2.61822 loss)
I0822 19:30:51.405956 31324 sgd_solver.cpp:790] Iteration 60, lr = 0.01
I0822 19:30:55.760304 31324 solver.cpp:254] Iteration 80 (4.59314 iter/s, 4.35432s/20 iters), loss = 2.52427
I0822 19:30:55.760368 31324 solver.cpp:273]     Train net output #0: loss = 2.52427 (* 1 = 2.52427 loss)
I0822 19:30:55.760380 31324 sgd_solver.cpp:790] Iteration 80, lr = 0.01
I0822 19:30:59.843636 31324 solver.cpp:254] Iteration 100 (4.89809 iter/s, 4.08322s/20 iters), loss = 2.58748
I0822 19:30:59.843706 31324 solver.cpp:273]     Train net output #0: loss = 2.58748 (* 1 = 2.58748 loss)
I0822 19:30:59.843720 31324 sgd_solver.cpp:790] Iteration 100, lr = 0.01
I0822 19:31:04.141623 31324 solver.cpp:254] Iteration 120 (4.65347 iter/s, 4.29787s/20 iters), loss = 2.50687
I0822 19:31:04.141705 31324 solver.cpp:273]     Train net output #0: loss = 2.50687 (* 1 = 2.50687 loss)
I0822 19:31:04.141721 31324 sgd_solver.cpp:790] Iteration 120, lr = 0.01
I0822 19:31:08.153787 31324 solver.cpp:254] Iteration 140 (4.98501 iter/s, 4.01203s/20 iters), loss = 2.78596
I0822 19:31:08.153867 31324 solver.cpp:273]     Train net output #0: loss = 2.78596 (* 1 = 2.78596 loss)
I0822 19:31:08.153882 31324 sgd_solver.cpp:790] Iteration 140, lr = 0.01
I0822 19:31:12.099076 31324 solver.cpp:254] Iteration 160 (5.0695 iter/s, 3.94516s/20 iters), loss = 2.33678
I0822 19:31:12.099287 31324 solver.cpp:273]     Train net output #0: loss = 2.33678 (* 1 = 2.33678 loss)
I0822 19:31:12.099303 31324 sgd_solver.cpp:790] Iteration 160, lr = 0.01
I0822 19:31:15.952626 31324 solver.cpp:254] Iteration 180 (5.19036 iter/s, 3.8533s/20 iters), loss = 2.8433
I0822 19:31:15.952694 31324 solver.cpp:273]     Train net output #0: loss = 2.8433 (* 1 = 2.8433 loss)
I0822 19:31:15.952710 31324 sgd_solver.cpp:790] Iteration 180, lr = 0.01
I0822 19:31:20.176796 31324 solver.cpp:254] Iteration 200 (4.73479 iter/s, 4.22405s/20 iters), loss = 2.57457
I0822 19:31:20.176877 31324 solver.cpp:273]     Train net output #0: loss = 2.57457 (* 1 = 2.57457 loss)
I0822 19:31:20.176903 31324 sgd_solver.cpp:790] Iteration 200, lr = 0.01
I0822 19:31:24.116997 31324 solver.cpp:254] Iteration 220 (5.07604 iter/s, 3.94008s/20 iters), loss = 2.53776
I0822 19:31:24.129093 31324 solver.cpp:273]     Train net output #0: loss = 2.53776 (* 1 = 2.53776 loss)
I0822 19:31:24.129118 31324 sgd_solver.cpp:790] Iteration 220, lr = 0.01
I0822 19:31:27.889160 31324 solver.cpp:254] Iteration 240 (5.3191 iter/s, 3.76003s/20 iters), loss = 3.05085
I0822 19:31:27.889233 31324 solver.cpp:273]     Train net output #0: loss = 3.05085 (* 1 = 3.05085 loss)
I0822 19:31:27.889247 31324 sgd_solver.cpp:790] Iteration 240, lr = 0.01
I0822 19:31:31.673857 31324 solver.cpp:254] Iteration 260 (5.2846 iter/s, 3.78458s/20 iters), loss = 2.62216
I0822 19:31:31.673930 31324 solver.cpp:273]     Train net output #0: loss = 2.62216 (* 1 = 2.62216 loss)
I0822 19:31:31.673946 31324 sgd_solver.cpp:790] Iteration 260, lr = 0.01
I0822 19:31:35.463928 31324 solver.cpp:254] Iteration 280 (5.27711 iter/s, 3.78996s/20 iters), loss = 2.55983
I0822 19:31:35.463991 31324 solver.cpp:273]     Train net output #0: loss = 2.55983 (* 1 = 2.55983 loss)
I0822 19:31:35.464005 31324 sgd_solver.cpp:790] Iteration 280, lr = 0.01
I0822 19:31:39.289505 31324 solver.cpp:254] Iteration 300 (5.22813 iter/s, 3.82546s/20 iters), loss = 2.49505
I0822 19:31:39.289582 31324 solver.cpp:273]     Train net output #0: loss = 2.49505 (* 1 = 2.49505 loss)
I0822 19:31:39.289597 31324 sgd_solver.cpp:790] Iteration 300, lr = 0.01
I0822 19:31:43.075634 31324 solver.cpp:254] Iteration 320 (5.2826 iter/s, 3.78601s/20 iters), loss = 2.57112
I0822 19:31:43.087718 31324 solver.cpp:273]     Train net output #0: loss = 2.57112 (* 1 = 2.57112 loss)
I0822 19:31:43.087740 31324 sgd_solver.cpp:790] Iteration 320, lr = 0.01
I0822 19:31:46.854720 31324 solver.cpp:254] Iteration 340 (5.30931 iter/s, 3.76697s/20 iters), loss = 2.74364
I0822 19:31:46.854791 31324 solver.cpp:273]     Train net output #0: loss = 2.74364 (* 1 = 2.74364 loss)
I0822 19:31:46.854806 31324 sgd_solver.cpp:790] Iteration 340, lr = 0.01
I0822 19:31:50.762676 31324 solver.cpp:254] Iteration 360 (5.11792 iter/s, 3.90784s/20 iters), loss = 2.42158
I0822 19:31:50.762750 31324 solver.cpp:273]     Train net output #0: loss = 2.42158 (* 1 = 2.42158 loss)
I0822 19:31:50.762764 31324 sgd_solver.cpp:790] Iteration 360, lr = 0.01
I0822 19:31:54.986342 31324 solver.cpp:254] Iteration 380 (4.73536 iter/s, 4.22354s/20 iters), loss = 2.49501
I0822 19:31:54.986416 31324 solver.cpp:273]     Train net output #0: loss = 2.49501 (* 1 = 2.49501 loss)
I0822 19:31:54.986429 31324 sgd_solver.cpp:790] Iteration 380, lr = 0.01
I0822 19:31:58.955334 31324 solver.cpp:254] Iteration 400 (5.03921 iter/s, 3.96888s/20 iters), loss = 2.7528
I0822 19:31:58.955392 31324 solver.cpp:273]     Train net output #0: loss = 2.7528 (* 1 = 2.7528 loss)
I0822 19:31:58.955404 31324 sgd_solver.cpp:790] Iteration 400, lr = 0.01
I0822 19:32:03.329202 31324 solver.cpp:254] Iteration 420 (4.57273 iter/s, 4.37376s/20 iters), loss = 2.51662
I0822 19:32:03.329284 31324 solver.cpp:273]     Train net output #0: loss = 2.51662 (* 1 = 2.51662 loss)
I0822 19:32:03.329298 31324 sgd_solver.cpp:790] Iteration 420, lr = 0.01
I0822 19:32:07.472913 31324 solver.cpp:254] Iteration 440 (4.82673 iter/s, 4.14359s/20 iters), loss = 2.63337
I0822 19:32:07.472977 31324 solver.cpp:273]     Train net output #0: loss = 2.63337 (* 1 = 2.63337 loss)
I0822 19:32:07.472990 31324 sgd_solver.cpp:790] Iteration 440, lr = 0.01
I0822 19:32:11.440546 31324 solver.cpp:254] Iteration 460 (5.04093 iter/s, 3.96752s/20 iters), loss = 2.62562
I0822 19:32:11.440621 31324 solver.cpp:273]     Train net output #0: loss = 2.62562 (* 1 = 2.62562 loss)
I0822 19:32:11.440635 31324 sgd_solver.cpp:790] Iteration 460, lr = 0.01
I0822 19:32:15.308554 31324 solver.cpp:254] Iteration 480 (5.17078 iter/s, 3.86788s/20 iters), loss = 2.56189
I0822 19:32:15.320684 31324 solver.cpp:273]     Train net output #0: loss = 2.56189 (* 1 = 2.56189 loss)
I0822 19:32:15.320704 31324 sgd_solver.cpp:790] Iteration 480, lr = 0.01
I0822 19:32:19.145265 31324 solver.cpp:254] Iteration 500 (5.22939 iter/s, 3.82454s/20 iters), loss = 2.73329
I0822 19:32:19.145349 31324 solver.cpp:273]     Train net output #0: loss = 2.73329 (* 1 = 2.73329 loss)
I0822 19:32:19.145366 31324 sgd_solver.cpp:790] Iteration 500, lr = 0.01
I0822 19:32:23.020830 31324 solver.cpp:254] Iteration 520 (5.1607 iter/s, 3.87544s/20 iters), loss = 2.31371
I0822 19:32:23.032958 31324 solver.cpp:273]     Train net output #0: loss = 2.31371 (* 1 = 2.31371 loss)
I0822 19:32:23.032977 31324 sgd_solver.cpp:790] Iteration 520, lr = 0.01
I0822 19:32:26.877665 31324 solver.cpp:254] Iteration 540 (5.20201 iter/s, 3.84467s/20 iters), loss = 2.43129
I0822 19:32:26.877734 31324 solver.cpp:273]     Train net output #0: loss = 2.43129 (* 1 = 2.43129 loss)
I0822 19:32:26.877758 31324 sgd_solver.cpp:790] Iteration 540, lr = 0.01
I0822 19:32:30.837800 31324 solver.cpp:254] Iteration 560 (5.05049 iter/s, 3.96001s/20 iters), loss = 2.5848
I0822 19:32:30.837882 31324 solver.cpp:273]     Train net output #0: loss = 2.5848 (* 1 = 2.5848 loss)
I0822 19:32:30.837901 31324 sgd_solver.cpp:790] Iteration 560, lr = 0.01
I0822 19:32:34.726639 31324 solver.cpp:254] Iteration 580 (5.14309 iter/s, 3.88871s/20 iters), loss = 2.70593
I0822 19:32:34.738739 31324 solver.cpp:273]     Train net output #0: loss = 2.70593 (* 1 = 2.70593 loss)
I0822 19:32:34.738780 31324 sgd_solver.cpp:790] Iteration 580, lr = 0.01
I0822 19:32:38.750964 31324 solver.cpp:254] Iteration 600 (4.98481 iter/s, 4.01219s/20 iters), loss = 2.57389
I0822 19:32:38.751065 31324 solver.cpp:273]     Train net output #0: loss = 2.57389 (* 1 = 2.57389 loss)
I0822 19:32:38.751086 31324 sgd_solver.cpp:790] Iteration 600, lr = 0.01
I0822 19:32:42.846616 31324 solver.cpp:254] Iteration 620 (4.88339 iter/s, 4.09551s/20 iters), loss = 2.55062
I0822 19:32:42.846686 31324 solver.cpp:273]     Train net output #0: loss = 2.55062 (* 1 = 2.55062 loss)
I0822 19:32:42.846699 31324 sgd_solver.cpp:790] Iteration 620, lr = 0.01
I0822 19:32:46.743764 31324 solver.cpp:254] Iteration 640 (5.1321 iter/s, 3.89704s/20 iters), loss = 2.86004
I0822 19:32:46.755834 31324 solver.cpp:273]     Train net output #0: loss = 2.86004 (* 1 = 2.86004 loss)
I0822 19:32:46.755856 31324 sgd_solver.cpp:790] Iteration 640, lr = 0.01
I0822 19:32:50.684581 31324 solver.cpp:254] Iteration 660 (5.09072 iter/s, 3.92871s/20 iters), loss = 2.74433
I0822 19:32:50.684646 31324 solver.cpp:273]     Train net output #0: loss = 2.74433 (* 1 = 2.74433 loss)
I0822 19:32:50.684660 31324 sgd_solver.cpp:790] Iteration 660, lr = 0.01
I0822 19:32:54.577630 31324 solver.cpp:254] Iteration 680 (5.13751 iter/s, 3.89294s/20 iters), loss = 2.66131
I0822 19:32:54.577702 31324 solver.cpp:273]     Train net output #0: loss = 2.66131 (* 1 = 2.66131 loss)
I0822 19:32:54.577715 31324 sgd_solver.cpp:790] Iteration 680, lr = 0.01
I0822 19:32:58.618077 31324 solver.cpp:254] Iteration 700 (4.95009 iter/s, 4.04033s/20 iters), loss = 2.58688
I0822 19:32:58.630156 31324 solver.cpp:273]     Train net output #0: loss = 2.58688 (* 1 = 2.58688 loss)
I0822 19:32:58.630178 31324 sgd_solver.cpp:790] Iteration 700, lr = 0.01
I0822 19:33:02.432302 31324 solver.cpp:254] Iteration 720 (5.26023 iter/s, 3.80212s/20 iters), loss = 2.57304
I0822 19:33:02.444442 31324 solver.cpp:273]     Train net output #0: loss = 2.57304 (* 1 = 2.57304 loss)
I0822 19:33:02.444466 31324 sgd_solver.cpp:790] Iteration 720, lr = 0.01
I0822 19:33:06.456938 31324 solver.cpp:254] Iteration 740 (4.98447 iter/s, 4.01246s/20 iters), loss = 2.65629
I0822 19:33:06.457018 31324 solver.cpp:273]     Train net output #0: loss = 2.65629 (* 1 = 2.65629 loss)
I0822 19:33:06.457036 31324 sgd_solver.cpp:790] Iteration 740, lr = 0.01
I0822 19:33:10.570623 31324 solver.cpp:254] Iteration 760 (4.86196 iter/s, 4.11357s/20 iters), loss = 2.40271
I0822 19:33:10.570694 31324 solver.cpp:273]     Train net output #0: loss = 2.40271 (* 1 = 2.40271 loss)
I0822 19:33:10.570708 31324 sgd_solver.cpp:790] Iteration 760, lr = 0.01
I0822 19:33:14.468298 31324 solver.cpp:254] Iteration 780 (5.13142 iter/s, 3.89756s/20 iters), loss = 2.4665
I0822 19:33:14.468381 31324 solver.cpp:273]     Train net output #0: loss = 2.4665 (* 1 = 2.4665 loss)
I0822 19:33:14.468396 31324 sgd_solver.cpp:790] Iteration 780, lr = 0.01
I0822 19:33:18.321727 31324 solver.cpp:254] Iteration 800 (5.19036 iter/s, 3.8533s/20 iters), loss = 2.87282
I0822 19:33:18.321920 31324 solver.cpp:273]     Train net output #0: loss = 2.87282 (* 1 = 2.87282 loss)
I0822 19:33:18.321938 31324 sgd_solver.cpp:790] Iteration 800, lr = 0.01
I0822 19:33:22.866667 31324 solver.cpp:254] Iteration 820 (4.40073 iter/s, 4.5447s/20 iters), loss = 2.63042
I0822 19:33:22.866746 31324 solver.cpp:273]     Train net output #0: loss = 2.63042 (* 1 = 2.63042 loss)
I0822 19:33:22.866762 31324 sgd_solver.cpp:790] Iteration 820, lr = 0.01
I0822 19:33:26.934554 31324 solver.cpp:254] Iteration 840 (4.91669 iter/s, 4.06777s/20 iters), loss = 2.96216
I0822 19:33:26.946602 31324 solver.cpp:273]     Train net output #0: loss = 2.96216 (* 1 = 2.96216 loss)
I0822 19:33:26.946624 31324 sgd_solver.cpp:790] Iteration 840, lr = 0.01
I0822 19:33:30.573937 31324 solver.cpp:254] Iteration 860 (5.51374 iter/s, 3.6273s/20 iters), loss = 2.47192
I0822 19:33:30.585995 31324 solver.cpp:273]     Train net output #0: loss = 2.47192 (* 1 = 2.47192 loss)
I0822 19:33:30.586019 31324 sgd_solver.cpp:790] Iteration 860, lr = 0.01
I0822 19:33:34.214053 31324 solver.cpp:254] Iteration 880 (5.51264 iter/s, 3.62802s/20 iters), loss = 2.59061
I0822 19:33:34.214128 31324 solver.cpp:273]     Train net output #0: loss = 2.59061 (* 1 = 2.59061 loss)
I0822 19:33:34.214143 31324 sgd_solver.cpp:790] Iteration 880, lr = 0.01
I0822 19:33:38.016059 31324 solver.cpp:254] Iteration 900 (5.26054 iter/s, 3.80189s/20 iters), loss = 2.53701
I0822 19:33:38.028141 31324 solver.cpp:273]     Train net output #0: loss = 2.53701 (* 1 = 2.53701 loss)
I0822 19:33:38.028172 31324 sgd_solver.cpp:790] Iteration 900, lr = 0.01
I0822 19:33:43.481089 31324 solver.cpp:254] Iteration 920 (3.66776 iter/s, 5.45292s/20 iters), loss = 2.55752
I0822 19:33:43.481149 31324 solver.cpp:273]     Train net output #0: loss = 2.55752 (* 1 = 2.55752 loss)
I0822 19:33:43.481161 31324 sgd_solver.cpp:790] Iteration 920, lr = 0.01
I0822 19:33:51.599264 31324 solver.cpp:254] Iteration 940 (2.46365 iter/s, 8.11805s/20 iters), loss = 2.55366
I0822 19:33:51.599434 31324 solver.cpp:273]     Train net output #0: loss = 2.55366 (* 1 = 2.55366 loss)
I0822 19:33:51.599452 31324 sgd_solver.cpp:790] Iteration 940, lr = 0.01
I0822 19:33:59.550253 31324 solver.cpp:254] Iteration 960 (2.51548 iter/s, 7.95076s/20 iters), loss = 2.51125
I0822 19:33:59.550333 31324 solver.cpp:273]     Train net output #0: loss = 2.51125 (* 1 = 2.51125 loss)
I0822 19:33:59.550348 31324 sgd_solver.cpp:790] Iteration 960, lr = 0.01
I0822 19:34:07.581764 31324 solver.cpp:254] Iteration 980 (2.49024 iter/s, 8.03135s/20 iters), loss = 2.43956
I0822 19:34:07.581845 31324 solver.cpp:273]     Train net output #0: loss = 2.43956 (* 1 = 2.43956 loss)
I0822 19:34:07.581861 31324 sgd_solver.cpp:790] Iteration 980, lr = 0.01
I0822 19:34:15.111804 31324 solver.cpp:366] Iteration 1000, Testing net (#0)
I0822 19:34:15.759052 31324 blocking_queue.cpp:49] Waiting for data
I0822 19:34:38.323827 31336 data_layer.cpp:73] Restarting data prefetching from start.
I0822 19:34:38.340071 31324 solver.cpp:433]     Test net output #0: accuracy = 0.46518
I0822 19:34:38.340126 31324 solver.cpp:433]     Test net output #1: accuracy5 = 0.72538
I0822 19:34:38.340142 31324 solver.cpp:433]     Test net output #2: loss = 2.38318 (* 1 = 2.38318 loss)
I0822 19:34:38.506860 31324 solver.cpp:254] Iteration 1000 (0.64673 iter/s, 30.9248s/20 iters), loss = 2.662
I0822 19:34:38.509286 31324 solver.cpp:273]     Train net output #0: loss = 2.662 (* 1 = 2.662 loss)
I0822 19:34:38.509310 31324 sgd_solver.cpp:790] Iteration 1000, lr = 0.01
I0822 19:34:45.163339 31324 solver.cpp:254] Iteration 1020 (3.00571 iter/s, 6.65401s/20 iters), loss = 2.63923
I0822 19:34:45.163419 31324 solver.cpp:273]     Train net output #0: loss = 2.63923 (* 1 = 2.63923 loss)
I0822 19:34:45.163445 31324 sgd_solver.cpp:790] Iteration 1020, lr = 0.01
I0822 19:34:47.324899 31324 blocking_queue.cpp:49] Waiting for data
I0822 19:34:53.295084 31324 solver.cpp:254] Iteration 1040 (2.45954 iter/s, 8.13159s/20 iters), loss = 2.34879
I0822 19:34:53.295161 31324 solver.cpp:273]     Train net output #0: loss = 2.34879 (* 1 = 2.34879 loss)
I0822 19:34:53.295178 31324 sgd_solver.cpp:790] Iteration 1040, lr = 0.01
I0822 19:35:01.476622 31324 solver.cpp:254] Iteration 1060 (2.44457 iter/s, 8.18139s/20 iters), loss = 2.40954
I0822 19:35:01.476696 31324 solver.cpp:273]     Train net output #0: loss = 2.40954 (* 1 = 2.40954 loss)
I0822 19:35:01.476709 31324 sgd_solver.cpp:790] Iteration 1060, lr = 0.01
I0822 19:35:10.495182 31324 solver.cpp:254] Iteration 1080 (2.21768 iter/s, 9.01842s/20 iters), loss = 2.60652
I0822 19:35:10.495332 31324 solver.cpp:273]     Train net output #0: loss = 2.60652 (* 1 = 2.60652 loss)
I0822 19:35:10.495344 31324 sgd_solver.cpp:790] Iteration 1080, lr = 0.01
I0822 19:35:18.729480 31324 solver.cpp:254] Iteration 1100 (2.42893 iter/s, 8.23408s/20 iters), loss = 2.7297
I0822 19:35:18.729562 31324 solver.cpp:273]     Train net output #0: loss = 2.7297 (* 1 = 2.7297 loss)
I0822 19:35:18.729578 31324 sgd_solver.cpp:790] Iteration 1100, lr = 0.01
I0822 19:35:26.047049 31324 solver.cpp:254] Iteration 1120 (2.7332 iter/s, 7.31742s/20 iters), loss = 2.69672
I0822 19:35:26.047116 31324 solver.cpp:273]     Train net output #0: loss = 2.69672 (* 1 = 2.69672 loss)
I0822 19:35:26.047129 31324 sgd_solver.cpp:790] Iteration 1120, lr = 0.01
I0822 19:35:33.426643 31324 solver.cpp:254] Iteration 1140 (2.71022 iter/s, 7.37946s/20 iters), loss = 2.48172
I0822 19:35:33.426713 31324 solver.cpp:273]     Train net output #0: loss = 2.48172 (* 1 = 2.48172 loss)
I0822 19:35:33.426725 31324 sgd_solver.cpp:790] Iteration 1140, lr = 0.01
I0822 19:35:40.711135 31324 solver.cpp:254] Iteration 1160 (2.74561 iter/s, 7.28436s/20 iters), loss = 2.61434
I0822 19:35:40.711318 31324 solver.cpp:273]     Train net output #0: loss = 2.61434 (* 1 = 2.61434 loss)
I0822 19:35:40.711333 31324 sgd_solver.cpp:790] Iteration 1160, lr = 0.01
I0822 19:35:48.224107 31324 solver.cpp:254] Iteration 1180 (2.66215 iter/s, 7.51273s/20 iters), loss = 2.60614
I0822 19:35:48.224190 31324 solver.cpp:273]     Train net output #0: loss = 2.60614 (* 1 = 2.60614 loss)
I0822 19:35:48.224207 31324 sgd_solver.cpp:790] Iteration 1180, lr = 0.01
I0822 19:35:56.380333 31324 solver.cpp:254] Iteration 1200 (2.45216 iter/s, 8.15608s/20 iters), loss = 2.47447
I0822 19:35:56.380408 31324 solver.cpp:273]     Train net output #0: loss = 2.47447 (* 1 = 2.47447 loss)
I0822 19:35:56.380424 31324 sgd_solver.cpp:790] Iteration 1200, lr = 0.01
I0822 19:36:04.488029 31324 solver.cpp:254] Iteration 1220 (2.46683 iter/s, 8.10756s/20 iters), loss = 2.72372
I0822 19:36:04.488107 31324 solver.cpp:273]     Train net output #0: loss = 2.72372 (* 1 = 2.72372 loss)
I0822 19:36:04.488123 31324 sgd_solver.cpp:790] Iteration 1220, lr = 0.01
I0822 19:36:12.210513 31324 solver.cpp:254] Iteration 1240 (2.58989 iter/s, 7.72235s/20 iters), loss = 2.71748
I0822 19:36:12.210630 31324 solver.cpp:273]     Train net output #0: loss = 2.71748 (* 1 = 2.71748 loss)
I0822 19:36:12.210646 31324 sgd_solver.cpp:790] Iteration 1240, lr = 0.01
I0822 19:36:19.611918 31324 solver.cpp:254] Iteration 1260 (2.70225 iter/s, 7.40123s/20 iters), loss = 2.63413
I0822 19:36:19.611994 31324 solver.cpp:273]     Train net output #0: loss = 2.63413 (* 1 = 2.63413 loss)
I0822 19:36:19.612010 31324 sgd_solver.cpp:790] Iteration 1260, lr = 0.01
I0822 19:36:27.351140 31324 solver.cpp:254] Iteration 1280 (2.58429 iter/s, 7.73908s/20 iters), loss = 2.48915
I0822 19:36:27.351234 31324 solver.cpp:273]     Train net output #0: loss = 2.48915 (* 1 = 2.48915 loss)
I0822 19:36:27.351259 31324 sgd_solver.cpp:790] Iteration 1280, lr = 0.01
I0822 19:36:34.964073 31324 solver.cpp:254] Iteration 1300 (2.62716 iter/s, 7.61279s/20 iters), loss = 2.67758
I0822 19:36:34.964143 31324 solver.cpp:273]     Train net output #0: loss = 2.67758 (* 1 = 2.67758 loss)
I0822 19:36:34.964167 31324 sgd_solver.cpp:790] Iteration 1300, lr = 0.01
I0822 19:36:42.625032 31324 solver.cpp:254] Iteration 1320 (2.61068 iter/s, 7.66083s/20 iters), loss = 2.60917
I0822 19:36:42.625211 31324 solver.cpp:273]     Train net output #0: loss = 2.60917 (* 1 = 2.60917 loss)
I0822 19:36:42.625228 31324 sgd_solver.cpp:790] Iteration 1320, lr = 0.01
I0822 19:36:50.213565 31324 solver.cpp:254] Iteration 1340 (2.63564 iter/s, 7.5883s/20 iters), loss = 2.45731
I0822 19:36:50.213644 31324 solver.cpp:273]     Train net output #0: loss = 2.45731 (* 1 = 2.45731 loss)
I0822 19:36:50.213656 31324 sgd_solver.cpp:790] Iteration 1340, lr = 0.01
I0822 19:36:58.504443 31324 solver.cpp:254] Iteration 1360 (2.41233 iter/s, 8.29074s/20 iters), loss = 2.80636
I0822 19:36:58.504534 31324 solver.cpp:273]     Train net output #0: loss = 2.80636 (* 1 = 2.80636 loss)
I0822 19:36:58.504551 31324 sgd_solver.cpp:790] Iteration 1360, lr = 0.01
I0822 19:37:06.727149 31324 solver.cpp:254] Iteration 1380 (2.43234 iter/s, 8.22255s/20 iters), loss = 2.56417
I0822 19:37:06.727238 31324 solver.cpp:273]     Train net output #0: loss = 2.56417 (* 1 = 2.56417 loss)
I0822 19:37:06.727254 31324 sgd_solver.cpp:790] Iteration 1380, lr = 0.01
I0822 19:37:14.271139 31324 solver.cpp:254] Iteration 1400 (2.65117 iter/s, 7.54385s/20 iters), loss = 2.71887
I0822 19:37:14.271284 31324 solver.cpp:273]     Train net output #0: loss = 2.71887 (* 1 = 2.71887 loss)
I0822 19:37:14.271299 31324 sgd_solver.cpp:790] Iteration 1400, lr = 0.01
I0822 19:37:21.837384 31324 solver.cpp:254] Iteration 1420 (2.64339 iter/s, 7.56604s/20 iters), loss = 2.63366
I0822 19:37:21.837460 31324 solver.cpp:273]     Train net output #0: loss = 2.63366 (* 1 = 2.63366 loss)
I0822 19:37:21.837474 31324 sgd_solver.cpp:790] Iteration 1420, lr = 0.01
I0822 19:37:29.913177 31324 solver.cpp:254] Iteration 1440 (2.47658 iter/s, 8.07565s/20 iters), loss = 2.83164
I0822 19:37:29.913255 31324 solver.cpp:273]     Train net output #0: loss = 2.83164 (* 1 = 2.83164 loss)
I0822 19:37:29.913271 31324 sgd_solver.cpp:790] Iteration 1440, lr = 0.01
I0822 19:37:37.254923 31324 solver.cpp:254] Iteration 1460 (2.7242 iter/s, 7.34161s/20 iters), loss = 2.54476
I0822 19:37:37.255012 31324 solver.cpp:273]     Train net output #0: loss = 2.54476 (* 1 = 2.54476 loss)
I0822 19:37:37.255029 31324 sgd_solver.cpp:790] Iteration 1460, lr = 0.01
I0822 19:37:45.631587 31324 solver.cpp:254] Iteration 1480 (2.38763 iter/s, 8.37651s/20 iters), loss = 2.48385
I0822 19:37:45.631762 31324 solver.cpp:273]     Train net output #0: loss = 2.48385 (* 1 = 2.48385 loss)
I0822 19:37:45.631779 31324 sgd_solver.cpp:790] Iteration 1480, lr = 0.01
I0822 19:37:53.291224 31324 solver.cpp:254] Iteration 1500 (2.61117 iter/s, 7.65941s/20 iters), loss = 2.61283
I0822 19:37:53.291296 31324 solver.cpp:273]     Train net output #0: loss = 2.61283 (* 1 = 2.61283 loss)
I0822 19:37:53.291311 31324 sgd_solver.cpp:790] Iteration 1500, lr = 0.01
I0822 19:38:00.795497 31324 solver.cpp:254] Iteration 1520 (2.6652 iter/s, 7.50414s/20 iters), loss = 2.47127
I0822 19:38:00.795581 31324 solver.cpp:273]     Train net output #0: loss = 2.47127 (* 1 = 2.47127 loss)
I0822 19:38:00.795599 31324 sgd_solver.cpp:790] Iteration 1520, lr = 0.01
I0822 19:38:09.260677 31324 solver.cpp:254] Iteration 1540 (2.36266 iter/s, 8.46504s/20 iters), loss = 2.66977
I0822 19:38:09.260759 31324 solver.cpp:273]     Train net output #0: loss = 2.66977 (* 1 = 2.66977 loss)
I0822 19:38:09.260774 31324 sgd_solver.cpp:790] Iteration 1540, lr = 0.01
I0822 19:38:17.286147 31324 solver.cpp:254] Iteration 1560 (2.49211 iter/s, 8.02532s/20 iters), loss = 2.74227
I0822 19:38:17.286314 31324 solver.cpp:273]     Train net output #0: loss = 2.74227 (* 1 = 2.74227 loss)
I0822 19:38:17.286329 31324 sgd_solver.cpp:790] Iteration 1560, lr = 0.01
I0822 19:38:21.219228 31324 solver.cpp:254] Iteration 1580 (5.08533 iter/s, 3.93288s/20 iters), loss = 2.7578
I0822 19:38:21.219292 31324 solver.cpp:273]     Train net output #0: loss = 2.7578 (* 1 = 2.7578 loss)
I0822 19:38:21.219316 31324 sgd_solver.cpp:790] Iteration 1580, lr = 0.01
I0822 19:38:25.017487 31324 solver.cpp:254] Iteration 1600 (5.26571 iter/s, 3.79816s/20 iters), loss = 2.48105
I0822 19:38:25.017549 31324 solver.cpp:273]     Train net output #0: loss = 2.48105 (* 1 = 2.48105 loss)
I0822 19:38:25.017562 31324 sgd_solver.cpp:790] Iteration 1600, lr = 0.01
I0822 19:38:28.828356 31324 solver.cpp:254] Iteration 1620 (5.24828 iter/s, 3.81077s/20 iters), loss = 2.79505
I0822 19:38:28.828430 31324 solver.cpp:273]     Train net output #0: loss = 2.79505 (* 1 = 2.79505 loss)
I0822 19:38:28.828444 31324 sgd_solver.cpp:790] Iteration 1620, lr = 0.01
I0822 19:38:32.579334 31324 solver.cpp:254] Iteration 1640 (5.33209 iter/s, 3.75087s/20 iters), loss = 2.75402
I0822 19:38:32.591775 31324 solver.cpp:273]     Train net output #0: loss = 2.75402 (* 1 = 2.75402 loss)
I0822 19:38:32.591806 31324 sgd_solver.cpp:790] Iteration 1640, lr = 0.01
I0822 19:38:36.317520 31324 solver.cpp:254] Iteration 1660 (5.36808 iter/s, 3.72573s/20 iters), loss = 2.31476
I0822 19:38:36.329875 31324 solver.cpp:273]     Train net output #0: loss = 2.31476 (* 1 = 2.31476 loss)
I0822 19:38:36.329900 31324 sgd_solver.cpp:790] Iteration 1660, lr = 0.01
I0822 19:38:41.639020 31324 solver.cpp:254] Iteration 1680 (3.7671 iter/s, 5.30912s/20 iters), loss = 2.6189
I0822 19:38:41.662868 31324 solver.cpp:273]     Train net output #0: loss = 2.6189 (* 1 = 2.6189 loss)
I0822 19:38:41.662887 31324 sgd_solver.cpp:790] Iteration 1680, lr = 0.01
I0822 19:38:45.336892 31324 solver.cpp:254] Iteration 1700 (5.44366 iter/s, 3.674s/20 iters), loss = 2.90568
I0822 19:38:45.336947 31324 solver.cpp:273]     Train net output #0: loss = 2.90568 (* 1 = 2.90568 loss)
I0822 19:38:45.336958 31324 sgd_solver.cpp:790] Iteration 1700, lr = 0.01
I0822 19:38:49.088507 31324 solver.cpp:254] Iteration 1720 (5.33116 iter/s, 3.75153s/20 iters), loss = 2.65738
I0822 19:38:49.088609 31324 solver.cpp:273]     Train net output #0: loss = 2.65738 (* 1 = 2.65738 loss)
I0822 19:38:49.088620 31324 sgd_solver.cpp:790] Iteration 1720, lr = 0.01
I0822 19:38:52.806561 31324 solver.cpp:254] Iteration 1740 (5.37936 iter/s, 3.71792s/20 iters), loss = 2.74179
I0822 19:38:52.806620 31324 solver.cpp:273]     Train net output #0: loss = 2.74179 (* 1 = 2.74179 loss)
I0822 19:38:52.806632 31324 sgd_solver.cpp:790] Iteration 1740, lr = 0.01
I0822 19:38:59.580616 31324 solver.cpp:254] Iteration 1760 (2.95249 iter/s, 6.77395s/20 iters), loss = 2.51572
I0822 19:38:59.580689 31324 solver.cpp:273]     Train net output #0: loss = 2.51572 (* 1 = 2.51572 loss)
I0822 19:38:59.580706 31324 sgd_solver.cpp:790] Iteration 1760, lr = 0.01
I0822 19:39:07.531392 31324 solver.cpp:254] Iteration 1780 (2.51552 iter/s, 7.95065s/20 iters), loss = 2.76815
I0822 19:39:07.531477 31324 solver.cpp:273]     Train net output #0: loss = 2.76815 (* 1 = 2.76815 loss)
I0822 19:39:07.531492 31324 sgd_solver.cpp:790] Iteration 1780, lr = 0.01
I0822 19:39:15.911346 31324 solver.cpp:254] Iteration 1800 (2.38669 iter/s, 8.37982s/20 iters), loss = 2.48412
I0822 19:39:15.911412 31324 solver.cpp:273]     Train net output #0: loss = 2.48412 (* 1 = 2.48412 loss)
I0822 19:39:15.911423 31324 sgd_solver.cpp:790] Iteration 1800, lr = 0.01
I0822 19:39:23.411870 31324 solver.cpp:254] Iteration 1820 (2.66652 iter/s, 7.5004s/20 iters), loss = 2.50117
I0822 19:39:23.412940 31324 solver.cpp:273]     Train net output #0: loss = 2.50117 (* 1 = 2.50117 loss)
I0822 19:39:23.412958 31324 sgd_solver.cpp:790] Iteration 1820, lr = 0.01
I0822 19:39:31.237442 31324 solver.cpp:254] Iteration 1840 (2.55609 iter/s, 7.82444s/20 iters), loss = 2.84438
I0822 19:39:31.237550 31324 solver.cpp:273]     Train net output #0: loss = 2.84438 (* 1 = 2.84438 loss)
I0822 19:39:31.237570 31324 sgd_solver.cpp:790] Iteration 1840, lr = 0.01
I0822 19:39:38.907810 31324 solver.cpp:254] Iteration 1860 (2.60749 iter/s, 7.6702s/20 iters), loss = 2.83042
I0822 19:39:38.907896 31324 solver.cpp:273]     Train net output #0: loss = 2.83042 (* 1 = 2.83042 loss)
I0822 19:39:38.907922 31324 sgd_solver.cpp:790] Iteration 1860, lr = 0.01
I0822 19:39:46.323079 31324 solver.cpp:254] Iteration 1880 (2.69719 iter/s, 7.41513s/20 iters), loss = 2.7731
I0822 19:39:46.323158 31324 solver.cpp:273]     Train net output #0: loss = 2.7731 (* 1 = 2.7731 loss)
I0822 19:39:46.323173 31324 sgd_solver.cpp:790] Iteration 1880, lr = 0.01
I0822 19:39:54.258754 31324 solver.cpp:254] Iteration 1900 (2.52031 iter/s, 7.93553s/20 iters), loss = 2.56123
I0822 19:39:54.258930 31324 solver.cpp:273]     Train net output #0: loss = 2.56123 (* 1 = 2.56123 loss)
I0822 19:39:54.258946 31324 sgd_solver.cpp:790] Iteration 1900, lr = 0.01
I0822 19:40:01.678637 31324 solver.cpp:254] Iteration 1920 (2.69555 iter/s, 7.41964s/20 iters), loss = 2.77826
I0822 19:40:01.678715 31324 solver.cpp:273]     Train net output #0: loss = 2.77826 (* 1 = 2.77826 loss)
I0822 19:40:01.678732 31324 sgd_solver.cpp:790] Iteration 1920, lr = 0.01
I0822 19:40:09.823824 31324 solver.cpp:254] Iteration 1940 (2.45548 iter/s, 8.14504s/20 iters), loss = 2.6652
I0822 19:40:09.823902 31324 solver.cpp:273]     Train net output #0: loss = 2.6652 (* 1 = 2.6652 loss)
I0822 19:40:09.823916 31324 sgd_solver.cpp:790] Iteration 1940, lr = 0.01
I0822 19:40:17.367141 31324 solver.cpp:254] Iteration 1960 (2.6514 iter/s, 7.54318s/20 iters), loss = 2.78062
I0822 19:40:17.367204 31324 solver.cpp:273]     Train net output #0: loss = 2.78062 (* 1 = 2.78062 loss)
I0822 19:40:17.367216 31324 sgd_solver.cpp:790] Iteration 1960, lr = 0.01
I0822 19:40:22.397346 31324 solver.cpp:254] Iteration 1980 (3.97607 iter/s, 5.0301s/20 iters), loss = 2.44132
I0822 19:40:22.397405 31324 solver.cpp:273]     Train net output #0: loss = 2.44132 (* 1 = 2.44132 loss)
I0822 19:40:22.397416 31324 sgd_solver.cpp:790] Iteration 1980, lr = 0.01
I0822 19:40:26.001405 31324 solver.cpp:366] Iteration 2000, Testing net (#0)
I0822 19:40:26.993259 31324 blocking_queue.cpp:49] Waiting for data
I0822 19:40:49.990480 31336 data_layer.cpp:73] Restarting data prefetching from start.
I0822 19:40:50.010269 31324 solver.cpp:433]     Test net output #0: accuracy = 0.46298
I0822 19:40:50.010313 31324 solver.cpp:433]     Test net output #1: accuracy5 = 0.7231
I0822 19:40:50.010324 31324 solver.cpp:433]     Test net output #2: loss = 2.39029 (* 1 = 2.39029 loss)
I0822 19:40:50.189615 31324 solver.cpp:254] Iteration 2000 (0.71963 iter/s, 27.792s/20 iters), loss = 2.74286
I0822 19:40:50.191992 31324 solver.cpp:273]     Train net output #0: loss = 2.74286 (* 1 = 2.74286 loss)
I0822 19:40:50.192009 31324 sgd_solver.cpp:790] Iteration 2000, lr = 0.01
I0822 19:40:57.409557 31324 solver.cpp:254] Iteration 2020 (2.77104 iter/s, 7.21752s/20 iters), loss = 2.66595
I0822 19:40:57.409703 31324 solver.cpp:273]     Train net output #0: loss = 2.66595 (* 1 = 2.66595 loss)
I0822 19:40:57.409718 31324 sgd_solver.cpp:790] Iteration 2020, lr = 0.01
I0822 19:41:03.313179 31324 blocking_queue.cpp:49] Waiting for data
I0822 19:41:04.771324 31324 solver.cpp:254] Iteration 2040 (2.71681 iter/s, 7.36157s/20 iters), loss = 2.86107
I0822 19:41:04.771399 31324 solver.cpp:273]     Train net output #0: loss = 2.86107 (* 1 = 2.86107 loss)
I0822 19:41:04.771421 31324 sgd_solver.cpp:790] Iteration 2040, lr = 0.01
I0822 19:41:12.136993 31324 solver.cpp:254] Iteration 2060 (2.71535 iter/s, 7.36554s/20 iters), loss = 2.83607
I0822 19:41:12.137049 31324 solver.cpp:273]     Train net output #0: loss = 2.83607 (* 1 = 2.83607 loss)
I0822 19:41:12.137061 31324 sgd_solver.cpp:790] Iteration 2060, lr = 0.01
I0822 19:41:20.071643 31324 solver.cpp:254] Iteration 2080 (2.52063 iter/s, 7.93454s/20 iters), loss = 2.60589
I0822 19:41:20.071699 31324 solver.cpp:273]     Train net output #0: loss = 2.60589 (* 1 = 2.60589 loss)
I0822 19:41:20.071709 31324 sgd_solver.cpp:790] Iteration 2080, lr = 0.01
I0822 19:41:29.200398 31324 solver.cpp:254] Iteration 2100 (2.19091 iter/s, 9.12862s/20 iters), loss = 2.59148
I0822 19:41:29.200598 31324 solver.cpp:273]     Train net output #0: loss = 2.59148 (* 1 = 2.59148 loss)
I0822 19:41:29.200620 31324 sgd_solver.cpp:790] Iteration 2100, lr = 0.01
I0822 19:41:38.962543 31324 solver.cpp:254] Iteration 2120 (2.04878 iter/s, 9.76189s/20 iters), loss = 2.60694
I0822 19:41:38.962605 31324 solver.cpp:273]     Train net output #0: loss = 2.60694 (* 1 = 2.60694 loss)
I0822 19:41:38.962615 31324 sgd_solver.cpp:790] Iteration 2120, lr = 0.01
I0822 19:41:48.307947 31324 solver.cpp:254] Iteration 2140 (2.14012 iter/s, 9.34528s/20 iters), loss = 2.8221
I0822 19:41:48.308007 31324 solver.cpp:273]     Train net output #0: loss = 2.8221 (* 1 = 2.8221 loss)
I0822 19:41:48.308019 31324 sgd_solver.cpp:790] Iteration 2140, lr = 0.01
I0822 19:41:57.572685 31324 solver.cpp:254] Iteration 2160 (2.15875 iter/s, 9.26461s/20 iters), loss = 2.3305
I0822 19:41:57.572764 31324 solver.cpp:273]     Train net output #0: loss = 2.3305 (* 1 = 2.3305 loss)
I0822 19:41:57.572780 31324 sgd_solver.cpp:790] Iteration 2160, lr = 0.01
I0822 19:42:07.178408 31324 solver.cpp:254] Iteration 2180 (2.08212 iter/s, 9.60558s/20 iters), loss = 2.52491
I0822 19:42:07.178527 31324 solver.cpp:273]     Train net output #0: loss = 2.52491 (* 1 = 2.52491 loss)
I0822 19:42:07.178540 31324 sgd_solver.cpp:790] Iteration 2180, lr = 0.01
I0822 19:42:16.825505 31324 solver.cpp:254] Iteration 2200 (2.0732 iter/s, 9.64691s/20 iters), loss = 2.92836
I0822 19:42:16.825577 31324 solver.cpp:273]     Train net output #0: loss = 2.92836 (* 1 = 2.92836 loss)
I0822 19:42:16.825588 31324 sgd_solver.cpp:790] Iteration 2200, lr = 0.01
I0822 19:42:24.731990 31324 solver.cpp:254] Iteration 2220 (2.52961 iter/s, 7.90635s/20 iters), loss = 2.83489
I0822 19:42:24.744451 31324 solver.cpp:273]     Train net output #0: loss = 2.83489 (* 1 = 2.83489 loss)
I0822 19:42:24.744488 31324 sgd_solver.cpp:790] Iteration 2220, lr = 0.01
I0822 19:42:33.646133 31324 solver.cpp:254] Iteration 2240 (2.24678 iter/s, 8.90164s/20 iters), loss = 2.53651
I0822 19:42:33.646209 31324 solver.cpp:273]     Train net output #0: loss = 2.53651 (* 1 = 2.53651 loss)
I0822 19:42:33.646224 31324 sgd_solver.cpp:790] Iteration 2240, lr = 0.01
I0822 19:42:42.948981 31324 solver.cpp:254] Iteration 2260 (2.14991 iter/s, 9.30272s/20 iters), loss = 2.52721
I0822 19:42:42.949149 31324 solver.cpp:273]     Train net output #0: loss = 2.52721 (* 1 = 2.52721 loss)
I0822 19:42:42.949162 31324 sgd_solver.cpp:790] Iteration 2260, lr = 0.01
I0822 19:42:52.713718 31324 solver.cpp:254] Iteration 2280 (2.04823 iter/s, 9.76451s/20 iters), loss = 2.52071
I0822 19:42:52.713786 31324 solver.cpp:273]     Train net output #0: loss = 2.52071 (* 1 = 2.52071 loss)
I0822 19:42:52.713800 31324 sgd_solver.cpp:790] Iteration 2280, lr = 0.01
I0822 19:43:02.311854 31324 solver.cpp:254] Iteration 2300 (2.08377 iter/s, 9.59801s/20 iters), loss = 2.63931
I0822 19:43:02.311915 31324 solver.cpp:273]     Train net output #0: loss = 2.63931 (* 1 = 2.63931 loss)
I0822 19:43:02.311926 31324 sgd_solver.cpp:790] Iteration 2300, lr = 0.01
I0822 19:43:11.986335 31324 solver.cpp:254] Iteration 2320 (2.06732 iter/s, 9.67436s/20 iters), loss = 2.3562
I0822 19:43:11.986397 31324 solver.cpp:273]     Train net output #0: loss = 2.3562 (* 1 = 2.3562 loss)
I0822 19:43:11.986412 31324 sgd_solver.cpp:790] Iteration 2320, lr = 0.01
I0822 19:43:21.510156 31324 solver.cpp:254] Iteration 2340 (2.10003 iter/s, 9.52369s/20 iters), loss = 2.64848
I0822 19:43:21.510332 31324 solver.cpp:273]     Train net output #0: loss = 2.64848 (* 1 = 2.64848 loss)
I0822 19:43:21.510349 31324 sgd_solver.cpp:790] Iteration 2340, lr = 0.01
I0822 19:43:30.836119 31324 solver.cpp:254] Iteration 2360 (2.14461 iter/s, 9.32572s/20 iters), loss = 2.49355
I0822 19:43:30.836197 31324 solver.cpp:273]     Train net output #0: loss = 2.49355 (* 1 = 2.49355 loss)
I0822 19:43:30.836212 31324 sgd_solver.cpp:790] Iteration 2360, lr = 0.01
I0822 19:43:40.215972 31324 solver.cpp:254] Iteration 2380 (2.13226 iter/s, 9.37971s/20 iters), loss = 2.8836
I0822 19:43:40.216044 31324 solver.cpp:273]     Train net output #0: loss = 2.8836 (* 1 = 2.8836 loss)
I0822 19:43:40.216059 31324 sgd_solver.cpp:790] Iteration 2380, lr = 0.01
I0822 19:43:49.426204 31324 solver.cpp:254] Iteration 2400 (2.17153 iter/s, 9.21009s/20 iters), loss = 2.62399
I0822 19:43:49.426312 31324 solver.cpp:273]     Train net output #0: loss = 2.62399 (* 1 = 2.62399 loss)
I0822 19:43:49.426327 31324 sgd_solver.cpp:790] Iteration 2400, lr = 0.01
I0822 19:43:58.696126 31324 solver.cpp:254] Iteration 2420 (2.15755 iter/s, 9.26975s/20 iters), loss = 2.82499
I0822 19:43:58.696285 31324 solver.cpp:273]     Train net output #0: loss = 2.82499 (* 1 = 2.82499 loss)
I0822 19:43:58.696298 31324 sgd_solver.cpp:790] Iteration 2420, lr = 0.01
I0822 19:44:08.284245 31324 solver.cpp:254] Iteration 2440 (2.08596 iter/s, 9.58789s/20 iters), loss = 2.8417
I0822 19:44:08.284329 31324 solver.cpp:273]     Train net output #0: loss = 2.8417 (* 1 = 2.8417 loss)
I0822 19:44:08.284343 31324 sgd_solver.cpp:790] Iteration 2440, lr = 0.01
I0822 19:44:17.611733 31324 solver.cpp:254] Iteration 2460 (2.14423 iter/s, 9.32734s/20 iters), loss = 2.56693
I0822 19:44:17.611809 31324 solver.cpp:273]     Train net output #0: loss = 2.56693 (* 1 = 2.56693 loss)
I0822 19:44:17.611826 31324 sgd_solver.cpp:790] Iteration 2460, lr = 0.01
I0822 19:44:26.884681 31324 solver.cpp:254] Iteration 2480 (2.15684 iter/s, 9.27282s/20 iters), loss = 2.57193
I0822 19:44:26.884747 31324 solver.cpp:273]     Train net output #0: loss = 2.57193 (* 1 = 2.57193 loss)
I0822 19:44:26.884762 31324 sgd_solver.cpp:790] Iteration 2480, lr = 0.01
I0822 19:44:36.311933 31324 solver.cpp:254] Iteration 2500 (2.12154 iter/s, 9.42713s/20 iters), loss = 2.52546
I0822 19:44:36.312075 31324 solver.cpp:273]     Train net output #0: loss = 2.52546 (* 1 = 2.52546 loss)
I0822 19:44:36.312088 31324 sgd_solver.cpp:790] Iteration 2500, lr = 0.01
I0822 19:44:45.775029 31324 solver.cpp:254] Iteration 2520 (2.11352 iter/s, 9.46289s/20 iters), loss = 2.64497
I0822 19:44:45.775100 31324 solver.cpp:273]     Train net output #0: loss = 2.64497 (* 1 = 2.64497 loss)
I0822 19:44:45.775111 31324 sgd_solver.cpp:790] Iteration 2520, lr = 0.01
I0822 19:44:55.326553 31324 solver.cpp:254] Iteration 2540 (2.09394 iter/s, 9.55138s/20 iters), loss = 2.38115
I0822 19:44:55.326640 31324 solver.cpp:273]     Train net output #0: loss = 2.38115 (* 1 = 2.38115 loss)
I0822 19:44:55.326658 31324 sgd_solver.cpp:790] Iteration 2540, lr = 0.01
I0822 19:45:04.737943 31324 solver.cpp:254] Iteration 2560 (2.12512 iter/s, 9.41125s/20 iters), loss = 2.64355
I0822 19:45:04.738015 31324 solver.cpp:273]     Train net output #0: loss = 2.64355 (* 1 = 2.64355 loss)
I0822 19:45:04.738028 31324 sgd_solver.cpp:790] Iteration 2560, lr = 0.01
I0822 19:45:14.042690 31324 solver.cpp:254] Iteration 2580 (2.14947 iter/s, 9.30462s/20 iters), loss = 2.61246
I0822 19:45:14.042876 31324 solver.cpp:273]     Train net output #0: loss = 2.61246 (* 1 = 2.61246 loss)
I0822 19:45:14.042891 31324 sgd_solver.cpp:790] Iteration 2580, lr = 0.01
I0822 19:45:23.378976 31324 solver.cpp:254] Iteration 2600 (2.14223 iter/s, 9.33605s/20 iters), loss = 2.77955
I0822 19:45:23.379040 31324 solver.cpp:273]     Train net output #0: loss = 2.77955 (* 1 = 2.77955 loss)
I0822 19:45:23.379050 31324 sgd_solver.cpp:790] Iteration 2600, lr = 0.01
I0822 19:45:32.827350 31324 solver.cpp:254] Iteration 2620 (2.11679 iter/s, 9.44825s/20 iters), loss = 2.73962
I0822 19:45:32.827414 31324 solver.cpp:273]     Train net output #0: loss = 2.73962 (* 1 = 2.73962 loss)
I0822 19:45:32.827425 31324 sgd_solver.cpp:790] Iteration 2620, lr = 0.01
I0822 19:45:42.480844 31324 solver.cpp:254] Iteration 2640 (2.07182 iter/s, 9.65337s/20 iters), loss = 2.89397
I0822 19:45:42.480928 31324 solver.cpp:273]     Train net output #0: loss = 2.89397 (* 1 = 2.89397 loss)
I0822 19:45:42.480944 31324 sgd_solver.cpp:790] Iteration 2640, lr = 0.01
I0822 19:45:51.480201 31324 solver.cpp:254] Iteration 2660 (2.22242 iter/s, 8.99922s/20 iters), loss = 2.59565
I0822 19:45:51.481566 31324 solver.cpp:273]     Train net output #0: loss = 2.59565 (* 1 = 2.59565 loss)
I0822 19:45:51.481585 31324 sgd_solver.cpp:790] Iteration 2660, lr = 0.01
I0822 19:45:56.019284 31324 solver.cpp:254] Iteration 2680 (4.40753 iter/s, 4.53769s/20 iters), loss = 2.32088
I0822 19:45:56.031895 31324 solver.cpp:273]     Train net output #0: loss = 2.32088 (* 1 = 2.32088 loss)
I0822 19:45:56.031934 31324 sgd_solver.cpp:790] Iteration 2680, lr = 0.01
I0822 19:45:59.690706 31324 solver.cpp:254] Iteration 2700 (5.46627 iter/s, 3.6588s/20 iters), loss = 2.70775
I0822 19:45:59.702934 31324 solver.cpp:273]     Train net output #0: loss = 2.70775 (* 1 = 2.70775 loss)
I0822 19:45:59.702987 31324 sgd_solver.cpp:790] Iteration 2700, lr = 0.01
I0822 19:46:03.328835 31324 solver.cpp:254] Iteration 2720 (5.51586 iter/s, 3.62591s/20 iters), loss = 2.97696
I0822 19:46:03.340960 31324 solver.cpp:273]     Train net output #0: loss = 2.97696 (* 1 = 2.97696 loss)
I0822 19:46:03.340991 31324 sgd_solver.cpp:790] Iteration 2720, lr = 0.01
I0822 19:46:06.979429 31324 solver.cpp:254] Iteration 2740 (5.49685 iter/s, 3.63845s/20 iters), loss = 2.72397
I0822 19:46:06.991701 31324 solver.cpp:273]     Train net output #0: loss = 2.72397 (* 1 = 2.72397 loss)
I0822 19:46:06.991744 31324 sgd_solver.cpp:790] Iteration 2740, lr = 0.01
I0822 19:46:10.694134 31324 solver.cpp:254] Iteration 2760 (5.40187 iter/s, 3.70242s/20 iters), loss = 2.38936
I0822 19:46:10.706241 31324 solver.cpp:273]     Train net output #0: loss = 2.38936 (* 1 = 2.38936 loss)
I0822 19:46:10.706293 31324 sgd_solver.cpp:790] Iteration 2760, lr = 0.01
I0822 19:46:14.358088 31324 solver.cpp:254] Iteration 2780 (5.47669 iter/s, 3.65184s/20 iters), loss = 2.73996
I0822 19:46:14.370682 31324 solver.cpp:273]     Train net output #0: loss = 2.73996 (* 1 = 2.73996 loss)
I0822 19:46:14.370718 31324 sgd_solver.cpp:790] Iteration 2780, lr = 0.01
I0822 19:46:18.018800 31324 solver.cpp:254] Iteration 2800 (5.4823 iter/s, 3.6481s/20 iters), loss = 2.6018
I0822 19:46:18.040691 31324 solver.cpp:273]     Train net output #0: loss = 2.6018 (* 1 = 2.6018 loss)
I0822 19:46:18.040724 31324 sgd_solver.cpp:790] Iteration 2800, lr = 0.01
I0822 19:46:21.748430 31324 solver.cpp:254] Iteration 2820 (5.39414 iter/s, 3.70773s/20 iters), loss = 2.70992
I0822 19:46:21.751885 31324 solver.cpp:273]     Train net output #0: loss = 2.70992 (* 1 = 2.70992 loss)
I0822 19:46:21.751902 31324 sgd_solver.cpp:790] Iteration 2820, lr = 0.01
I0822 19:46:28.859369 31324 solver.cpp:254] Iteration 2840 (2.81395 iter/s, 7.10746s/20 iters), loss = 2.47752
I0822 19:46:28.859427 31324 solver.cpp:273]     Train net output #0: loss = 2.47752 (* 1 = 2.47752 loss)
I0822 19:46:28.859436 31324 sgd_solver.cpp:790] Iteration 2840, lr = 0.01
I0822 19:46:37.911900 31324 solver.cpp:254] Iteration 2860 (2.20935 iter/s, 9.05242s/20 iters), loss = 2.76516
I0822 19:46:37.911958 31324 solver.cpp:273]     Train net output #0: loss = 2.76516 (* 1 = 2.76516 loss)
I0822 19:46:37.911970 31324 sgd_solver.cpp:790] Iteration 2860, lr = 0.01
I0822 19:46:46.754882 31324 solver.cpp:254] Iteration 2880 (2.26171 iter/s, 8.84287s/20 iters), loss = 2.62744
I0822 19:46:46.754951 31324 solver.cpp:273]     Train net output #0: loss = 2.62744 (* 1 = 2.62744 loss)
I0822 19:46:46.754966 31324 sgd_solver.cpp:790] Iteration 2880, lr = 0.01
I0822 19:46:56.136835 31324 solver.cpp:254] Iteration 2900 (2.13178 iter/s, 9.38183s/20 iters), loss = 2.61729
I0822 19:46:56.136991 31324 solver.cpp:273]     Train net output #0: loss = 2.61729 (* 1 = 2.61729 loss)
I0822 19:46:56.137006 31324 sgd_solver.cpp:790] Iteration 2900, lr = 0.01
I0822 19:47:06.708003 31324 solver.cpp:254] Iteration 2920 (1.89198 iter/s, 10.5709s/20 iters), loss = 2.7191
I0822 19:47:06.708079 31324 solver.cpp:273]     Train net output #0: loss = 2.7191 (* 1 = 2.7191 loss)
I0822 19:47:06.708091 31324 sgd_solver.cpp:790] Iteration 2920, lr = 0.01
I0822 19:47:17.238827 31324 solver.cpp:254] Iteration 2940 (1.89922 iter/s, 10.5307s/20 iters), loss = 2.59392
I0822 19:47:17.238917 31324 solver.cpp:273]     Train net output #0: loss = 2.59392 (* 1 = 2.59392 loss)
I0822 19:47:17.238936 31324 sgd_solver.cpp:790] Iteration 2940, lr = 0.01
I0822 19:47:28.084462 31324 solver.cpp:254] Iteration 2960 (1.84409 iter/s, 10.8455s/20 iters), loss = 2.72302
I0822 19:47:28.084627 31324 solver.cpp:273]     Train net output #0: loss = 2.72302 (* 1 = 2.72302 loss)
I0822 19:47:28.084640 31324 sgd_solver.cpp:790] Iteration 2960, lr = 0.01
I0822 19:47:37.866288 31324 solver.cpp:254] Iteration 2980 (2.04466 iter/s, 9.78159s/20 iters), loss = 2.78195
I0822 19:47:37.866371 31324 solver.cpp:273]     Train net output #0: loss = 2.78195 (* 1 = 2.78195 loss)
I0822 19:47:37.866389 31324 sgd_solver.cpp:790] Iteration 2980, lr = 0.01
I0822 19:47:46.854219 31324 solver.cpp:366] Iteration 3000, Testing net (#0)
I0822 19:47:48.151681 31324 blocking_queue.cpp:49] Waiting for data
I0822 19:48:10.456665 31336 data_layer.cpp:73] Restarting data prefetching from start.
I0822 19:48:10.473249 31324 solver.cpp:433]     Test net output #0: accuracy = 0.46668
I0822 19:48:10.473301 31324 solver.cpp:433]     Test net output #1: accuracy5 = 0.72768
I0822 19:48:10.473316 31324 solver.cpp:433]     Test net output #2: loss = 2.37122 (* 1 = 2.37122 loss)
I0822 19:48:10.639684 31324 solver.cpp:254] Iteration 3000 (0.610256 iter/s, 32.7731s/20 iters), loss = 2.68259
I0822 19:48:10.642117 31324 solver.cpp:273]     Train net output #0: loss = 2.68259 (* 1 = 2.68259 loss)
I0822 19:48:10.642150 31324 sgd_solver.cpp:790] Iteration 3000, lr = 0.01
I0822 19:48:18.695448 31324 solver.cpp:254] Iteration 3020 (2.48345 iter/s, 8.0533s/20 iters), loss = 2.49539
I0822 19:48:18.695505 31324 solver.cpp:273]     Train net output #0: loss = 2.49539 (* 1 = 2.49539 loss)
I0822 19:48:18.695515 31324 sgd_solver.cpp:790] Iteration 3020, lr = 0.01
I0822 19:48:27.832796 31324 solver.cpp:254] Iteration 3040 (2.18885 iter/s, 9.13723s/20 iters), loss = 2.50232
I0822 19:48:27.832860 31324 solver.cpp:273]     Train net output #0: loss = 2.50232 (* 1 = 2.50232 loss)
I0822 19:48:27.832871 31324 sgd_solver.cpp:790] Iteration 3040, lr = 0.01
I0822 19:48:32.603667 31324 blocking_queue.cpp:49] Waiting for data
I0822 19:48:37.285953 31324 solver.cpp:254] Iteration 3060 (2.11572 iter/s, 9.45303s/20 iters), loss = 2.89678
I0822 19:48:37.286026 31324 solver.cpp:273]     Train net output #0: loss = 2.89678 (* 1 = 2.89678 loss)
I0822 19:48:37.286037 31324 sgd_solver.cpp:790] Iteration 3060, lr = 0.01
I0822 19:48:47.773406 31324 solver.cpp:254] Iteration 3080 (1.90707 iter/s, 10.4873s/20 iters), loss = 2.96326
I0822 19:48:47.773607 31324 solver.cpp:273]     Train net output #0: loss = 2.96326 (* 1 = 2.96326 loss)
I0822 19:48:47.773622 31324 sgd_solver.cpp:790] Iteration 3080, lr = 0.01
I0822 19:48:58.332154 31324 solver.cpp:254] Iteration 3100 (1.89421 iter/s, 10.5585s/20 iters), loss = 2.41953
I0822 19:48:58.332218 31324 solver.cpp:273]     Train net output #0: loss = 2.41953 (* 1 = 2.41953 loss)
I0822 19:48:58.332319 31324 sgd_solver.cpp:790] Iteration 3100, lr = 0.01
I0822 19:49:09.002015 31324 solver.cpp:254] Iteration 3120 (1.87446 iter/s, 10.6697s/20 iters), loss = 2.7709
I0822 19:49:09.002089 31324 solver.cpp:273]     Train net output #0: loss = 2.7709 (* 1 = 2.7709 loss)
I0822 19:49:09.002104 31324 sgd_solver.cpp:790] Iteration 3120, lr = 0.01
I0822 19:49:19.295078 31324 solver.cpp:254] Iteration 3140 (1.94308 iter/s, 10.2929s/20 iters), loss = 2.70857
I0822 19:49:19.295249 31324 solver.cpp:273]     Train net output #0: loss = 2.70857 (* 1 = 2.70857 loss)
I0822 19:49:19.295264 31324 sgd_solver.cpp:790] Iteration 3140, lr = 0.01
I0822 19:49:29.595834 31324 solver.cpp:254] Iteration 3160 (1.94165 iter/s, 10.3005s/20 iters), loss = 2.83894
I0822 19:49:29.595904 31324 solver.cpp:273]     Train net output #0: loss = 2.83894 (* 1 = 2.83894 loss)
I0822 19:49:29.595919 31324 sgd_solver.cpp:790] Iteration 3160, lr = 0.01
I0822 19:49:40.006429 31324 solver.cpp:254] Iteration 3180 (1.92115 iter/s, 10.4105s/20 iters), loss = 2.51126
I0822 19:49:40.006521 31324 solver.cpp:273]     Train net output #0: loss = 2.51126 (* 1 = 2.51126 loss)
I0822 19:49:40.006546 31324 sgd_solver.cpp:790] Iteration 3180, lr = 0.01
I0822 19:49:50.642339 31324 solver.cpp:254] Iteration 3200 (1.88045 iter/s, 10.6358s/20 iters), loss = 2.60592
I0822 19:49:50.642519 31324 solver.cpp:273]     Train net output #0: loss = 2.60592 (* 1 = 2.60592 loss)
I0822 19:49:50.642546 31324 sgd_solver.cpp:790] Iteration 3200, lr = 0.01
I0822 19:50:01.209534 31324 solver.cpp:254] Iteration 3220 (1.89269 iter/s, 10.567s/20 iters), loss = 2.605
I0822 19:50:01.209602 31324 solver.cpp:273]     Train net output #0: loss = 2.605 (* 1 = 2.605 loss)
I0822 19:50:01.209614 31324 sgd_solver.cpp:790] Iteration 3220, lr = 0.01
I0822 19:50:11.617318 31324 solver.cpp:254] Iteration 3240 (1.92166 iter/s, 10.4076s/20 iters), loss = 2.32533
I0822 19:50:11.617385 31324 solver.cpp:273]     Train net output #0: loss = 2.32533 (* 1 = 2.32533 loss)
I0822 19:50:11.617400 31324 sgd_solver.cpp:790] Iteration 3240, lr = 0.01
I0822 19:50:21.971773 31324 solver.cpp:254] Iteration 3260 (1.93156 iter/s, 10.3543s/20 iters), loss = 2.66043
I0822 19:50:21.971941 31324 solver.cpp:273]     Train net output #0: loss = 2.66043 (* 1 = 2.66043 loss)
I0822 19:50:21.972672 31324 sgd_solver.cpp:790] Iteration 3260, lr = 0.01
I0822 19:50:32.548360 31324 solver.cpp:254] Iteration 3280 (1.89101 iter/s, 10.5764s/20 iters), loss = 2.47755
I0822 19:50:32.548444 31324 solver.cpp:273]     Train net output #0: loss = 2.47755 (* 1 = 2.47755 loss)
I0822 19:50:32.549672 31324 sgd_solver.cpp:790] Iteration 3280, lr = 0.01
I0822 19:50:43.135747 31324 solver.cpp:254] Iteration 3300 (1.88907 iter/s, 10.5872s/20 iters), loss = 2.70034
I0822 19:50:43.135823 31324 solver.cpp:273]     Train net output #0: loss = 2.70034 (* 1 = 2.70034 loss)
I0822 19:50:43.136744 31324 sgd_solver.cpp:790] Iteration 3300, lr = 0.01
I0822 19:50:53.685631 31324 solver.cpp:254] Iteration 3320 (1.89578 iter/s, 10.5497s/20 iters), loss = 2.59326
I0822 19:50:53.685843 31324 solver.cpp:273]     Train net output #0: loss = 2.59326 (* 1 = 2.59326 loss)
I0822 19:50:53.687235 31324 sgd_solver.cpp:790] Iteration 3320, lr = 0.01
I0822 19:51:04.048030 31324 solver.cpp:254] Iteration 3340 (1.93011 iter/s, 10.3621s/20 iters), loss = 2.63431
I0822 19:51:04.048091 31324 solver.cpp:273]     Train net output #0: loss = 2.63431 (* 1 = 2.63431 loss)
I0822 19:51:04.048102 31324 sgd_solver.cpp:790] Iteration 3340, lr = 0.01
I0822 19:51:14.705860 31324 solver.cpp:254] Iteration 3360 (1.87658 iter/s, 10.6577s/20 iters), loss = 2.44242
I0822 19:51:14.705920 31324 solver.cpp:273]     Train net output #0: loss = 2.44242 (* 1 = 2.44242 loss)
I0822 19:51:14.705930 31324 sgd_solver.cpp:790] Iteration 3360, lr = 0.01
I0822 19:51:25.336835 31324 solver.cpp:254] Iteration 3380 (1.88132 iter/s, 10.6309s/20 iters), loss = 2.36479
I0822 19:51:25.337976 31324 solver.cpp:273]     Train net output #0: loss = 2.36479 (* 1 = 2.36479 loss)
I0822 19:51:25.337992 31324 sgd_solver.cpp:790] Iteration 3380, lr = 0.01
I0822 19:51:36.019080 31324 solver.cpp:254] Iteration 3400 (1.87248 iter/s, 10.681s/20 iters), loss = 2.4883
I0822 19:51:36.019155 31324 solver.cpp:273]     Train net output #0: loss = 2.4883 (* 1 = 2.4883 loss)
I0822 19:51:36.020830 31324 sgd_solver.cpp:790] Iteration 3400, lr = 0.01
I0822 19:51:46.611302 31324 solver.cpp:254] Iteration 3420 (1.8882 iter/s, 10.5921s/20 iters), loss = 2.62721
I0822 19:51:46.611393 31324 solver.cpp:273]     Train net output #0: loss = 2.62721 (* 1 = 2.62721 loss)
I0822 19:51:46.611802 31324 sgd_solver.cpp:790] Iteration 3420, lr = 0.01
I0822 19:51:55.738834 31324 solver.cpp:254] Iteration 3440 (2.19121 iter/s, 9.12739s/20 iters), loss = 2.69693
I0822 19:51:55.739032 31324 solver.cpp:273]     Train net output #0: loss = 2.69693 (* 1 = 2.69693 loss)
I0822 19:51:55.739049 31324 sgd_solver.cpp:790] Iteration 3440, lr = 0.01
I0822 19:52:04.687129 31324 solver.cpp:254] Iteration 3460 (2.23512 iter/s, 8.94805s/20 iters), loss = 2.62117
I0822 19:52:04.687189 31324 solver.cpp:273]     Train net output #0: loss = 2.62117 (* 1 = 2.62117 loss)
I0822 19:52:04.687201 31324 sgd_solver.cpp:790] Iteration 3460, lr = 0.01
I0822 19:52:14.730701 31324 solver.cpp:254] Iteration 3480 (1.99135 iter/s, 10.0435s/20 iters), loss = 2.88166
I0822 19:52:14.730762 31324 solver.cpp:273]     Train net output #0: loss = 2.88166 (* 1 = 2.88166 loss)
I0822 19:52:14.730780 31324 sgd_solver.cpp:790] Iteration 3480, lr = 0.01
I0822 19:52:23.852844 31324 solver.cpp:254] Iteration 3500 (2.19249 iter/s, 9.12203s/20 iters), loss = 2.37642
I0822 19:52:23.852913 31324 solver.cpp:273]     Train net output #0: loss = 2.37642 (* 1 = 2.37642 loss)
I0822 19:52:23.852923 31324 sgd_solver.cpp:790] Iteration 3500, lr = 0.01
I0822 19:52:34.292240 31324 solver.cpp:254] Iteration 3520 (1.91585 iter/s, 10.4393s/20 iters), loss = 2.76165
I0822 19:52:34.292829 31324 solver.cpp:273]     Train net output #0: loss = 2.76165 (* 1 = 2.76165 loss)
I0822 19:52:34.292843 31324 sgd_solver.cpp:790] Iteration 3520, lr = 0.01
I0822 19:52:44.908816 31324 solver.cpp:254] Iteration 3540 (1.88396 iter/s, 10.6159s/20 iters), loss = 2.71958
I0822 19:52:44.908880 31324 solver.cpp:273]     Train net output #0: loss = 2.71958 (* 1 = 2.71958 loss)
I0822 19:52:44.908891 31324 sgd_solver.cpp:790] Iteration 3540, lr = 0.01
I0822 19:52:55.485388 31324 solver.cpp:254] Iteration 3560 (1.89099 iter/s, 10.5765s/20 iters), loss = 2.45907
I0822 19:52:55.485456 31324 solver.cpp:273]     Train net output #0: loss = 2.45907 (* 1 = 2.45907 loss)
I0822 19:52:55.485469 31324 sgd_solver.cpp:790] Iteration 3560, lr = 0.01
I0822 19:53:05.855265 31324 solver.cpp:254] Iteration 3580 (1.92869 iter/s, 10.3698s/20 iters), loss = 2.47788
I0822 19:53:05.856266 31324 solver.cpp:273]     Train net output #0: loss = 2.47788 (* 1 = 2.47788 loss)
I0822 19:53:05.856282 31324 sgd_solver.cpp:790] Iteration 3580, lr = 0.01
I0822 19:53:16.557188 31324 solver.cpp:254] Iteration 3600 (1.86901 iter/s, 10.7009s/20 iters), loss = 2.52839
I0822 19:53:16.557266 31324 solver.cpp:273]     Train net output #0: loss = 2.52839 (* 1 = 2.52839 loss)
I0822 19:53:16.557281 31324 sgd_solver.cpp:790] Iteration 3600, lr = 0.01
I0822 19:53:27.059622 31324 solver.cpp:254] Iteration 3620 (1.90435 iter/s, 10.5023s/20 iters), loss = 2.62782
I0822 19:53:27.059717 31324 solver.cpp:273]     Train net output #0: loss = 2.62782 (* 1 = 2.62782 loss)
I0822 19:53:27.059737 31324 sgd_solver.cpp:790] Iteration 3620, lr = 0.01
I0822 19:53:37.544652 31324 solver.cpp:254] Iteration 3640 (1.90751 iter/s, 10.4849s/20 iters), loss = 2.8962
I0822 19:53:37.544816 31324 solver.cpp:273]     Train net output #0: loss = 2.8962 (* 1 = 2.8962 loss)
I0822 19:53:37.546802 31324 sgd_solver.cpp:790] Iteration 3640, lr = 0.01
I0822 19:53:47.134024 31324 solver.cpp:254] Iteration 3660 (2.08569 iter/s, 9.58916s/20 iters), loss = 2.51616
I0822 19:53:47.134097 31324 solver.cpp:273]     Train net output #0: loss = 2.51616 (* 1 = 2.51616 loss)
I0822 19:53:47.134107 31324 sgd_solver.cpp:790] Iteration 3660, lr = 0.01
I0822 19:53:56.055939 31324 solver.cpp:254] Iteration 3680 (2.2417 iter/s, 8.92179s/20 iters), loss = 2.80207
I0822 19:53:56.056004 31324 solver.cpp:273]     Train net output #0: loss = 2.80207 (* 1 = 2.80207 loss)
I0822 19:53:56.056015 31324 sgd_solver.cpp:790] Iteration 3680, lr = 0.01
I0822 19:54:06.173192 31324 solver.cpp:254] Iteration 3700 (1.97685 iter/s, 10.1171s/20 iters), loss = 2.75663
I0822 19:54:06.173300 31324 solver.cpp:273]     Train net output #0: loss = 2.75663 (* 1 = 2.75663 loss)
I0822 19:54:06.173321 31324 sgd_solver.cpp:790] Iteration 3700, lr = 0.01
I0822 19:54:16.728216 31324 solver.cpp:254] Iteration 3720 (1.89486 iter/s, 10.5549s/20 iters), loss = 2.51413
I0822 19:54:16.730811 31324 solver.cpp:273]     Train net output #0: loss = 2.51413 (* 1 = 2.51413 loss)
I0822 19:54:16.730828 31324 sgd_solver.cpp:790] Iteration 3720, lr = 0.01
I0822 19:54:25.978811 31324 solver.cpp:254] Iteration 3740 (2.16264 iter/s, 9.24796s/20 iters), loss = 2.77967
I0822 19:54:25.978869 31324 solver.cpp:273]     Train net output #0: loss = 2.77967 (* 1 = 2.77967 loss)
I0822 19:54:25.978879 31324 sgd_solver.cpp:790] Iteration 3740, lr = 0.01
I0822 19:54:34.611274 31324 solver.cpp:254] Iteration 3760 (2.31686 iter/s, 8.63235s/20 iters), loss = 2.43941
I0822 19:54:34.611342 31324 solver.cpp:273]     Train net output #0: loss = 2.43941 (* 1 = 2.43941 loss)
I0822 19:54:34.611361 31324 sgd_solver.cpp:790] Iteration 3760, lr = 0.01
I0822 19:54:44.219596 31324 solver.cpp:254] Iteration 3780 (2.08156 iter/s, 9.6082s/20 iters), loss = 2.61538
I0822 19:54:44.219666 31324 solver.cpp:273]     Train net output #0: loss = 2.61538 (* 1 = 2.61538 loss)
I0822 19:54:44.219678 31324 sgd_solver.cpp:790] Iteration 3780, lr = 0.01
I0822 19:54:54.903365 31324 solver.cpp:254] Iteration 3800 (1.87202 iter/s, 10.6836s/20 iters), loss = 2.25183
I0822 19:54:54.903535 31324 solver.cpp:273]     Train net output #0: loss = 2.25183 (* 1 = 2.25183 loss)
I0822 19:54:54.903550 31324 sgd_solver.cpp:790] Iteration 3800, lr = 0.01
I0822 19:55:05.247506 31324 solver.cpp:254] Iteration 3820 (1.9335 iter/s, 10.3439s/20 iters), loss = 2.54599
I0822 19:55:05.247572 31324 solver.cpp:273]     Train net output #0: loss = 2.54599 (* 1 = 2.54599 loss)
I0822 19:55:05.247586 31324 sgd_solver.cpp:790] Iteration 3820, lr = 0.01
I0822 19:55:16.033628 31324 solver.cpp:254] Iteration 3840 (1.85426 iter/s, 10.786s/20 iters), loss = 2.61667
I0822 19:55:16.033710 31324 solver.cpp:273]     Train net output #0: loss = 2.61667 (* 1 = 2.61667 loss)
I0822 19:55:16.033725 31324 sgd_solver.cpp:790] Iteration 3840, lr = 0.01
I0822 19:55:26.863945 31324 solver.cpp:254] Iteration 3860 (1.84669 iter/s, 10.8302s/20 iters), loss = 2.87997
I0822 19:55:26.864095 31324 solver.cpp:273]     Train net output #0: loss = 2.87997 (* 1 = 2.87997 loss)
I0822 19:55:26.864107 31324 sgd_solver.cpp:790] Iteration 3860, lr = 0.01
I0822 19:55:37.228785 31324 solver.cpp:254] Iteration 3880 (1.92964 iter/s, 10.3646s/20 iters), loss = 2.72069
I0822 19:55:37.228839 31324 solver.cpp:273]     Train net output #0: loss = 2.72069 (* 1 = 2.72069 loss)
I0822 19:55:37.228850 31324 sgd_solver.cpp:790] Iteration 3880, lr = 0.01
I0822 19:55:46.304869 31324 solver.cpp:254] Iteration 3900 (2.20362 iter/s, 9.07597s/20 iters), loss = 2.54554
I0822 19:55:46.304949 31324 solver.cpp:273]     Train net output #0: loss = 2.54554 (* 1 = 2.54554 loss)
I0822 19:55:46.304963 31324 sgd_solver.cpp:790] Iteration 3900, lr = 0.01
I0822 19:55:55.372957 31324 solver.cpp:254] Iteration 3920 (2.20557 iter/s, 9.06796s/20 iters), loss = 2.69423
I0822 19:55:55.373028 31324 solver.cpp:273]     Train net output #0: loss = 2.69423 (* 1 = 2.69423 loss)
I0822 19:55:55.373042 31324 sgd_solver.cpp:790] Iteration 3920, lr = 0.01
I0822 19:56:05.277043 31324 solver.cpp:254] Iteration 3940 (2.01939 iter/s, 9.90396s/20 iters), loss = 2.59565
I0822 19:56:05.277458 31324 solver.cpp:273]     Train net output #0: loss = 2.59565 (* 1 = 2.59565 loss)
I0822 19:56:05.277470 31324 sgd_solver.cpp:790] Iteration 3940, lr = 0.01
I0822 19:56:15.749368 31324 solver.cpp:254] Iteration 3960 (1.90988 iter/s, 10.4719s/20 iters), loss = 2.53813
I0822 19:56:15.749442 31324 solver.cpp:273]     Train net output #0: loss = 2.53813 (* 1 = 2.53813 loss)
I0822 19:56:15.749457 31324 sgd_solver.cpp:790] Iteration 3960, lr = 0.01
I0822 19:56:26.432301 31324 solver.cpp:254] Iteration 3980 (1.87217 iter/s, 10.6828s/20 iters), loss = 2.84925
I0822 19:56:26.432374 31324 solver.cpp:273]     Train net output #0: loss = 2.84925 (* 1 = 2.84925 loss)
I0822 19:56:26.432384 31324 sgd_solver.cpp:790] Iteration 3980, lr = 0.01
I0822 19:56:36.539185 31324 solver.cpp:366] Iteration 4000, Testing net (#0)
I0822 19:56:38.063925 31324 blocking_queue.cpp:49] Waiting for data
I0822 19:57:00.941074 31336 data_layer.cpp:73] Restarting data prefetching from start.
I0822 19:57:00.958369 31324 solver.cpp:433]     Test net output #0: accuracy = 0.46998
I0822 19:57:00.958410 31324 solver.cpp:433]     Test net output #1: accuracy5 = 0.728199
I0822 19:57:00.958420 31324 solver.cpp:433]     Test net output #2: loss = 2.3493 (* 1 = 2.3493 loss)
I0822 19:57:01.142858 31324 solver.cpp:254] Iteration 4000 (0.576197 iter/s, 34.7104s/20 iters), loss = 2.45262
I0822 19:57:01.145313 31324 solver.cpp:273]     Train net output #0: loss = 2.45262 (* 1 = 2.45262 loss)
I0822 19:57:01.145344 31324 sgd_solver.cpp:790] Iteration 4000, lr = 0.01
I0822 19:57:08.859145 31324 solver.cpp:254] Iteration 4020 (2.59275 iter/s, 7.7138s/20 iters), loss = 2.61257
I0822 19:57:08.859290 31324 solver.cpp:273]     Train net output #0: loss = 2.61257 (* 1 = 2.61257 loss)
I0822 19:57:08.859302 31324 sgd_solver.cpp:790] Iteration 4020, lr = 0.01
I0822 19:57:17.880198 31324 solver.cpp:254] Iteration 4040 (2.21708 iter/s, 9.02087s/20 iters), loss = 2.54188
I0822 19:57:17.880257 31324 solver.cpp:273]     Train net output #0: loss = 2.54188 (* 1 = 2.54188 loss)
I0822 19:57:17.880268 31324 sgd_solver.cpp:790] Iteration 4040, lr = 0.01
I0822 19:57:26.127223 31324 blocking_queue.cpp:49] Waiting for data
I0822 19:57:27.850210 31324 solver.cpp:254] Iteration 4060 (2.00604 iter/s, 9.9699s/20 iters), loss = 2.43127
I0822 19:57:27.850275 31324 solver.cpp:273]     Train net output #0: loss = 2.43127 (* 1 = 2.43127 loss)
I0822 19:57:27.850288 31324 sgd_solver.cpp:790] Iteration 4060, lr = 0.01
I0822 19:57:38.471175 31324 solver.cpp:254] Iteration 4080 (1.88309 iter/s, 10.6208s/20 iters), loss = 2.59805
I0822 19:57:38.471262 31324 solver.cpp:273]     Train net output #0: loss = 2.59805 (* 1 = 2.59805 loss)
I0822 19:57:38.471277 31324 sgd_solver.cpp:790] Iteration 4080, lr = 0.01
I0822 19:57:48.724334 31324 solver.cpp:254] Iteration 4100 (1.95065 iter/s, 10.253s/20 iters), loss = 2.52551
I0822 19:57:48.724522 31324 solver.cpp:273]     Train net output #0: loss = 2.52551 (* 1 = 2.52551 loss)
I0822 19:57:48.724541 31324 sgd_solver.cpp:790] Iteration 4100, lr = 0.01
I0822 19:57:59.372009 31324 solver.cpp:254] Iteration 4120 (1.87839 iter/s, 10.6474s/20 iters), loss = 2.7274
I0822 19:57:59.372071 31324 solver.cpp:273]     Train net output #0: loss = 2.7274 (* 1 = 2.7274 loss)
I0822 19:57:59.372081 31324 sgd_solver.cpp:790] Iteration 4120, lr = 0.01
I0822 19:58:09.788552 31324 solver.cpp:254] Iteration 4140 (1.92005 iter/s, 10.4164s/20 iters), loss = 2.74973
I0822 19:58:09.788648 31324 solver.cpp:273]     Train net output #0: loss = 2.74973 (* 1 = 2.74973 loss)
I0822 19:58:09.788662 31324 sgd_solver.cpp:790] Iteration 4140, lr = 0.01
I0822 19:58:20.275054 31324 solver.cpp:254] Iteration 4160 (1.90724 iter/s, 10.4863s/20 iters), loss = 2.50266
I0822 19:58:20.275221 31324 solver.cpp:273]     Train net output #0: loss = 2.50266 (* 1 = 2.50266 loss)
I0822 19:58:20.275234 31324 sgd_solver.cpp:790] Iteration 4160, lr = 0.01
I0822 19:58:30.627238 31324 solver.cpp:254] Iteration 4180 (1.932 iter/s, 10.352s/20 iters), loss = 2.49551
I0822 19:58:30.627321 31324 solver.cpp:273]     Train net output #0: loss = 2.49551 (* 1 = 2.49551 loss)
I0822 19:58:30.627337 31324 sgd_solver.cpp:790] Iteration 4180, lr = 0.01
I0822 19:58:41.375377 31324 solver.cpp:254] Iteration 4200 (1.86081 iter/s, 10.748s/20 iters), loss = 2.68533
I0822 19:58:41.375442 31324 solver.cpp:273]     Train net output #0: loss = 2.68533 (* 1 = 2.68533 loss)
I0822 19:58:41.375453 31324 sgd_solver.cpp:790] Iteration 4200, lr = 0.01
I0822 19:58:51.946236 31324 solver.cpp:254] Iteration 4220 (1.89202 iter/s, 10.5707s/20 iters), loss = 2.34404
I0822 19:58:51.947149 31324 solver.cpp:273]     Train net output #0: loss = 2.34404 (* 1 = 2.34404 loss)
I0822 19:58:51.949579 31324 sgd_solver.cpp:790] Iteration 4220, lr = 0.01
I0822 19:59:02.478437 31324 solver.cpp:254] Iteration 4240 (1.89911 iter/s, 10.5312s/20 iters), loss = 2.69896
I0822 19:59:02.478521 31324 solver.cpp:273]     Train net output #0: loss = 2.69896 (* 1 = 2.69896 loss)
I0822 19:59:02.480408 31324 sgd_solver.cpp:790] Iteration 4240, lr = 0.01
I0822 19:59:12.938139 31324 solver.cpp:254] Iteration 4260 (1.91213 iter/s, 10.4596s/20 iters), loss = 2.39874
I0822 19:59:12.938213 31324 solver.cpp:273]     Train net output #0: loss = 2.39874 (* 1 = 2.39874 loss)
I0822 19:59:12.938233 31324 sgd_solver.cpp:790] Iteration 4260, lr = 0.01
I0822 19:59:23.178890 31324 solver.cpp:254] Iteration 4280 (1.95301 iter/s, 10.2406s/20 iters), loss = 2.46589
I0822 19:59:23.179049 31324 solver.cpp:273]     Train net output #0: loss = 2.46589 (* 1 = 2.46589 loss)
I0822 19:59:23.179065 31324 sgd_solver.cpp:790] Iteration 4280, lr = 0.01
I0822 19:59:33.738932 31324 solver.cpp:254] Iteration 4300 (1.89397 iter/s, 10.5598s/20 iters), loss = 2.55788
I0822 19:59:33.739042 31324 solver.cpp:273]     Train net output #0: loss = 2.55788 (* 1 = 2.55788 loss)
I0822 19:59:33.739061 31324 sgd_solver.cpp:790] Iteration 4300, lr = 0.01
I0822 19:59:44.444488 31324 solver.cpp:254] Iteration 4320 (1.86822 iter/s, 10.7054s/20 iters), loss = 2.76628
I0822 19:59:44.444567 31324 solver.cpp:273]     Train net output #0: loss = 2.76628 (* 1 = 2.76628 loss)
I0822 19:59:44.444581 31324 sgd_solver.cpp:790] Iteration 4320, lr = 0.01
I0822 19:59:55.030613 31324 solver.cpp:254] Iteration 4340 (1.88929 iter/s, 10.586s/20 iters), loss = 2.81471
I0822 19:59:55.030768 31324 solver.cpp:273]     Train net output #0: loss = 2.81471 (* 1 = 2.81471 loss)
I0822 19:59:55.030781 31324 sgd_solver.cpp:790] Iteration 4340, lr = 0.01
I0822 20:00:05.740883 31324 solver.cpp:254] Iteration 4360 (1.8674 iter/s, 10.7101s/20 iters), loss = 2.57332
I0822 20:00:05.740962 31324 solver.cpp:273]     Train net output #0: loss = 2.57332 (* 1 = 2.57332 loss)
I0822 20:00:05.742738 31324 sgd_solver.cpp:790] Iteration 4360, lr = 0.01
I0822 20:00:16.460115 31324 solver.cpp:254] Iteration 4380 (1.86583 iter/s, 10.7191s/20 iters), loss = 2.75345
I0822 20:00:16.460211 31324 solver.cpp:273]     Train net output #0: loss = 2.75345 (* 1 = 2.75345 loss)
I0822 20:00:16.461799 31324 sgd_solver.cpp:790] Iteration 4380, lr = 0.01
I0822 20:00:27.069859 31324 solver.cpp:254] Iteration 4400 (1.88509 iter/s, 10.6096s/20 iters), loss = 2.76583
I0822 20:00:27.073853 31324 solver.cpp:273]     Train net output #0: loss = 2.76583 (* 1 = 2.76583 loss)
I0822 20:00:27.073873 31324 sgd_solver.cpp:790] Iteration 4400, lr = 0.01
I0822 20:00:37.336282 31324 solver.cpp:254] Iteration 4420 (1.94886 iter/s, 10.2624s/20 iters), loss = 2.38213
I0822 20:00:37.336349 31324 solver.cpp:273]     Train net output #0: loss = 2.38213 (* 1 = 2.38213 loss)
I0822 20:00:37.336361 31324 sgd_solver.cpp:790] Iteration 4420, lr = 0.01
I0822 20:00:47.890096 31324 solver.cpp:254] Iteration 4440 (1.89507 iter/s, 10.5537s/20 iters), loss = 2.54613
I0822 20:00:47.890163 31324 solver.cpp:273]     Train net output #0: loss = 2.54613 (* 1 = 2.54613 loss)
I0822 20:00:47.890175 31324 sgd_solver.cpp:790] Iteration 4440, lr = 0.01
I0822 20:00:58.563688 31324 solver.cpp:254] Iteration 4460 (1.87381 iter/s, 10.6735s/20 iters), loss = 2.54344
I0822 20:00:58.563845 31324 solver.cpp:273]     Train net output #0: loss = 2.54344 (* 1 = 2.54344 loss)
I0822 20:00:58.563858 31324 sgd_solver.cpp:790] Iteration 4460, lr = 0.01
I0822 20:01:09.393935 31324 solver.cpp:254] Iteration 4480 (1.84672 iter/s, 10.83s/20 iters), loss = 2.6164
I0822 20:01:09.394001 31324 solver.cpp:273]     Train net output #0: loss = 2.6164 (* 1 = 2.6164 loss)
I0822 20:01:09.394011 31324 sgd_solver.cpp:790] Iteration 4480, lr = 0.01
I0822 20:01:19.873706 31324 solver.cpp:254] Iteration 4500 (1.90846 iter/s, 10.4796s/20 iters), loss = 2.4709
I0822 20:01:19.873780 31324 solver.cpp:273]     Train net output #0: loss = 2.4709 (* 1 = 2.4709 loss)
I0822 20:01:19.873792 31324 sgd_solver.cpp:790] Iteration 4500, lr = 0.01
I0822 20:01:30.421042 31324 solver.cpp:254] Iteration 4520 (1.89624 iter/s, 10.5472s/20 iters), loss = 2.79631
I0822 20:01:30.421178 31324 solver.cpp:273]     Train net output #0: loss = 2.79631 (* 1 = 2.79631 loss)
I0822 20:01:30.421191 31324 sgd_solver.cpp:790] Iteration 4520, lr = 0.01
I0822 20:01:40.875522 31324 solver.cpp:254] Iteration 4540 (1.91309 iter/s, 10.4543s/20 iters), loss = 2.59058
I0822 20:01:40.875586 31324 solver.cpp:273]     Train net output #0: loss = 2.59058 (* 1 = 2.59058 loss)
I0822 20:01:40.875597 31324 sgd_solver.cpp:790] Iteration 4540, lr = 0.01
I0822 20:01:51.491999 31324 solver.cpp:254] Iteration 4560 (1.88389 iter/s, 10.6164s/20 iters), loss = 2.31017
I0822 20:01:51.492069 31324 solver.cpp:273]     Train net output #0: loss = 2.31017 (* 1 = 2.31017 loss)
I0822 20:01:51.492080 31324 sgd_solver.cpp:790] Iteration 4560, lr = 0.01
I0822 20:02:01.933678 31324 solver.cpp:254] Iteration 4580 (1.91542 iter/s, 10.4416s/20 iters), loss = 2.74039
I0822 20:02:01.933856 31324 solver.cpp:273]     Train net output #0: loss = 2.74039 (* 1 = 2.74039 loss)
I0822 20:02:01.933871 31324 sgd_solver.cpp:790] Iteration 4580, lr = 0.01
I0822 20:02:12.632689 31324 solver.cpp:254] Iteration 4600 (1.86937 iter/s, 10.6988s/20 iters), loss = 2.70498
I0822 20:02:12.632755 31324 solver.cpp:273]     Train net output #0: loss = 2.70498 (* 1 = 2.70498 loss)
I0822 20:02:12.632766 31324 sgd_solver.cpp:790] Iteration 4600, lr = 0.01
I0822 20:02:23.295634 31324 solver.cpp:254] Iteration 4620 (1.87568 iter/s, 10.6628s/20 iters), loss = 2.47564
I0822 20:02:23.295708 31324 solver.cpp:273]     Train net output #0: loss = 2.47564 (* 1 = 2.47564 loss)
I0822 20:02:23.295722 31324 sgd_solver.cpp:790] Iteration 4620, lr = 0.01
I0822 20:02:33.918485 31324 solver.cpp:254] Iteration 4640 (1.88276 iter/s, 10.6227s/20 iters), loss = 2.64154
I0822 20:02:33.918637 31324 solver.cpp:273]     Train net output #0: loss = 2.64154 (* 1 = 2.64154 loss)
I0822 20:02:33.918654 31324 sgd_solver.cpp:790] Iteration 4640, lr = 0.01
I0822 20:02:42.722483 31324 solver.cpp:483] Snapshotting to binary proto file /data/kaiqi/24_prune_quantization01/caffe_alexnet_1st_retrain_iter_4658.caffemodel
I0822 20:02:43.952455 31324 sgd_solver.cpp:1201] Snapshotting solver state to binary proto file /data/kaiqi/24_prune_quantization01/caffe_alexnet_1st_retrain_iter_4658.solverstate
I0822 20:02:44.830215 31324 solver.cpp:254] Iteration 4660 (1.83292 iter/s, 10.9115s/20 iters), loss = 2.62818
I0822 20:02:44.842346 31324 solver.cpp:273]     Train net output #0: loss = 2.62818 (* 1 = 2.62818 loss)
I0822 20:02:44.842375 31324 sgd_solver.cpp:790] Iteration 4660, lr = 0.01
I0822 20:02:54.972337 31324 solver.cpp:254] Iteration 4680 (1.97434 iter/s, 10.13s/20 iters), loss = 2.69905
I0822 20:02:54.972407 31324 solver.cpp:273]     Train net output #0: loss = 2.69905 (* 1 = 2.69905 loss)
I0822 20:02:54.972420 31324 sgd_solver.cpp:790] Iteration 4680, lr = 0.01
I0822 20:03:05.550030 31324 solver.cpp:254] Iteration 4700 (1.89079 iter/s, 10.5776s/20 iters), loss = 2.49278
I0822 20:03:05.550220 31324 solver.cpp:273]     Train net output #0: loss = 2.49278 (* 1 = 2.49278 loss)
I0822 20:03:05.550236 31324 sgd_solver.cpp:790] Iteration 4700, lr = 0.01
I0822 20:03:15.086256 31324 solver.cpp:254] Iteration 4720 (2.09732 iter/s, 9.53598s/20 iters), loss = 2.65011
I0822 20:03:15.086334 31324 solver.cpp:273]     Train net output #0: loss = 2.65011 (* 1 = 2.65011 loss)
I0822 20:03:15.086345 31324 sgd_solver.cpp:790] Iteration 4720, lr = 0.01
I0822 20:03:23.328619 31324 solver.cpp:254] Iteration 4740 (2.42653 iter/s, 8.24223s/20 iters), loss = 2.5278
I0822 20:03:23.328699 31324 solver.cpp:273]     Train net output #0: loss = 2.5278 (* 1 = 2.5278 loss)
I0822 20:03:23.328712 31324 sgd_solver.cpp:790] Iteration 4740, lr = 0.01
I0822 20:03:30.140225 31324 solver.cpp:254] Iteration 4760 (2.93622 iter/s, 6.81148s/20 iters), loss = 2.50863
I0822 20:03:30.140290 31324 solver.cpp:273]     Train net output #0: loss = 2.50863 (* 1 = 2.50863 loss)
I0822 20:03:30.140302 31324 sgd_solver.cpp:790] Iteration 4760, lr = 0.01
I0822 20:03:38.597426 31324 solver.cpp:254] Iteration 4780 (2.36488 iter/s, 8.45708s/20 iters), loss = 2.38319
I0822 20:03:38.599844 31324 solver.cpp:273]     Train net output #0: loss = 2.38319 (* 1 = 2.38319 loss)
I0822 20:03:38.599862 31324 sgd_solver.cpp:790] Iteration 4780, lr = 0.01
I0822 20:03:48.652482 31324 solver.cpp:254] Iteration 4800 (1.98954 iter/s, 10.0526s/20 iters), loss = 2.47995
I0822 20:03:48.652549 31324 solver.cpp:273]     Train net output #0: loss = 2.47995 (* 1 = 2.47995 loss)
I0822 20:03:48.652560 31324 sgd_solver.cpp:790] Iteration 4800, lr = 0.01
I0822 20:03:59.177659 31324 solver.cpp:254] Iteration 4820 (1.90023 iter/s, 10.5251s/20 iters), loss = 2.59315
I0822 20:03:59.177727 31324 solver.cpp:273]     Train net output #0: loss = 2.59315 (* 1 = 2.59315 loss)
I0822 20:03:59.177739 31324 sgd_solver.cpp:790] Iteration 4820, lr = 0.01
I0822 20:04:09.968196 31324 solver.cpp:254] Iteration 4840 (1.8535 iter/s, 10.7904s/20 iters), loss = 2.52652
I0822 20:04:09.968359 31324 solver.cpp:273]     Train net output #0: loss = 2.52652 (* 1 = 2.52652 loss)
I0822 20:04:09.968370 31324 sgd_solver.cpp:790] Iteration 4840, lr = 0.01
I0822 20:04:20.743616 31324 solver.cpp:254] Iteration 4860 (1.85611 iter/s, 10.7752s/20 iters), loss = 2.64459
I0822 20:04:20.743691 31324 solver.cpp:273]     Train net output #0: loss = 2.64459 (* 1 = 2.64459 loss)
I0822 20:04:20.743705 31324 sgd_solver.cpp:790] Iteration 4860, lr = 0.01
I0822 20:04:29.932469 31324 solver.cpp:254] Iteration 4880 (2.17658 iter/s, 9.18873s/20 iters), loss = 2.715
I0822 20:04:29.932531 31324 solver.cpp:273]     Train net output #0: loss = 2.715 (* 1 = 2.715 loss)
I0822 20:04:29.932544 31324 sgd_solver.cpp:790] Iteration 4880, lr = 0.01
I0822 20:04:39.027040 31324 solver.cpp:254] Iteration 4900 (2.19914 iter/s, 9.09446s/20 iters), loss = 2.90392
I0822 20:04:39.027117 31324 solver.cpp:273]     Train net output #0: loss = 2.90392 (* 1 = 2.90392 loss)
I0822 20:04:39.027129 31324 sgd_solver.cpp:790] Iteration 4900, lr = 0.01
I0822 20:04:48.242332 31324 solver.cpp:254] Iteration 4920 (2.17033 iter/s, 9.21517s/20 iters), loss = 2.53542
I0822 20:04:48.242491 31324 solver.cpp:273]     Train net output #0: loss = 2.53542 (* 1 = 2.53542 loss)
I0822 20:04:48.242502 31324 sgd_solver.cpp:790] Iteration 4920, lr = 0.01
I0822 20:04:59.000422 31324 solver.cpp:254] Iteration 4940 (1.8591 iter/s, 10.7579s/20 iters), loss = 2.40177
I0822 20:04:59.000494 31324 solver.cpp:273]     Train net output #0: loss = 2.40177 (* 1 = 2.40177 loss)
I0822 20:04:59.000509 31324 sgd_solver.cpp:790] Iteration 4940, lr = 0.01
I0822 20:05:09.297634 31324 solver.cpp:254] Iteration 4960 (1.9423 iter/s, 10.2971s/20 iters), loss = 2.54184
I0822 20:05:09.297710 31324 solver.cpp:273]     Train net output #0: loss = 2.54184 (* 1 = 2.54184 loss)
I0822 20:05:09.297726 31324 sgd_solver.cpp:790] Iteration 4960, lr = 0.01
I0822 20:05:18.795204 31324 solver.cpp:254] Iteration 4980 (2.10583 iter/s, 9.49745s/20 iters), loss = 2.72126
I0822 20:05:18.795377 31324 solver.cpp:273]     Train net output #0: loss = 2.72126 (* 1 = 2.72126 loss)
I0822 20:05:18.795399 31324 sgd_solver.cpp:790] Iteration 4980, lr = 0.01
I0822 20:05:27.554577 31324 solver.cpp:366] Iteration 5000, Testing net (#0)
I0822 20:05:29.335824 31324 blocking_queue.cpp:49] Waiting for data
I0822 20:05:50.971123 31336 data_layer.cpp:73] Restarting data prefetching from start.
I0822 20:05:50.988672 31324 solver.cpp:433]     Test net output #0: accuracy = 0.46762
I0822 20:05:50.988731 31324 solver.cpp:433]     Test net output #1: accuracy5 = 0.72776
I0822 20:05:50.988754 31324 solver.cpp:433]     Test net output #2: loss = 2.38381 (* 1 = 2.38381 loss)
I0822 20:05:51.169967 31324 solver.cpp:254] Iteration 5000 (0.617771 iter/s, 32.3745s/20 iters), loss = 2.71979
I0822 20:05:51.172955 31324 solver.cpp:273]     Train net output #0: loss = 2.71979 (* 1 = 2.71979 loss)
I0822 20:05:51.172973 31324 sgd_solver.cpp:790] Iteration 5000, lr = 0.01
I0822 20:05:51.806964 31332 data_layer.cpp:73] Restarting data prefetching from start.
I0822 20:05:59.261059 31324 solver.cpp:254] Iteration 5020 (2.47278 iter/s, 8.08807s/20 iters), loss = 2.55863
I0822 20:05:59.261143 31324 solver.cpp:273]     Train net output #0: loss = 2.55863 (* 1 = 2.55863 loss)
I0822 20:05:59.261158 31324 sgd_solver.cpp:790] Iteration 5020, lr = 0.01
I0822 20:06:09.889127 31324 solver.cpp:254] Iteration 5040 (1.88183 iter/s, 10.628s/20 iters), loss = 2.55209
I0822 20:06:09.889186 31324 solver.cpp:273]     Train net output #0: loss = 2.55209 (* 1 = 2.55209 loss)
I0822 20:06:09.889199 31324 sgd_solver.cpp:790] Iteration 5040, lr = 0.01
I0822 20:06:20.453142 31324 solver.cpp:254] Iteration 5060 (1.89324 iter/s, 10.5639s/20 iters), loss = 2.85639
I0822 20:06:20.453220 31324 solver.cpp:273]     Train net output #0: loss = 2.85639 (* 1 = 2.85639 loss)
I0822 20:06:20.453233 31324 sgd_solver.cpp:790] Iteration 5060, lr = 0.01
I0822 20:06:24.397763 31324 blocking_queue.cpp:49] Waiting for data
I0822 20:06:30.820626 31324 solver.cpp:254] Iteration 5080 (1.92913 iter/s, 10.3674s/20 iters), loss = 2.84463
I0822 20:06:30.820698 31324 solver.cpp:273]     Train net output #0: loss = 2.84463 (* 1 = 2.84463 loss)
I0822 20:06:30.820710 31324 sgd_solver.cpp:790] Iteration 5080, lr = 0.01
I0822 20:06:41.444515 31324 solver.cpp:254] Iteration 5100 (1.88257 iter/s, 10.6238s/20 iters), loss = 3.00872
I0822 20:06:41.444576 31324 solver.cpp:273]     Train net output #0: loss = 3.00872 (* 1 = 3.00872 loss)
I0822 20:06:41.444587 31324 sgd_solver.cpp:790] Iteration 5100, lr = 0.01
I0822 20:06:51.690168 31324 solver.cpp:254] Iteration 5120 (1.95207 iter/s, 10.2455s/20 iters), loss = 2.61313
I0822 20:06:51.690229 31324 solver.cpp:273]     Train net output #0: loss = 2.61313 (* 1 = 2.61313 loss)
I0822 20:06:51.690239 31324 sgd_solver.cpp:790] Iteration 5120, lr = 0.01
I0822 20:07:02.308128 31324 solver.cpp:254] Iteration 5140 (1.88362 iter/s, 10.6178s/20 iters), loss = 2.54377
I0822 20:07:02.308281 31324 solver.cpp:273]     Train net output #0: loss = 2.54377 (* 1 = 2.54377 loss)
I0822 20:07:02.309571 31324 sgd_solver.cpp:790] Iteration 5140, lr = 0.01
I0822 20:07:12.771168 31324 solver.cpp:254] Iteration 5160 (1.91153 iter/s, 10.4628s/20 iters), loss = 2.68872
I0822 20:07:12.771255 31324 solver.cpp:273]     Train net output #0: loss = 2.68872 (* 1 = 2.68872 loss)
I0822 20:07:12.771270 31324 sgd_solver.cpp:790] Iteration 5160, lr = 0.01
I0822 20:07:23.527640 31324 solver.cpp:254] Iteration 5180 (1.85937 iter/s, 10.7563s/20 iters), loss = 2.6222
I0822 20:07:23.527717 31324 solver.cpp:273]     Train net output #0: loss = 2.6222 (* 1 = 2.6222 loss)
I0822 20:07:23.527734 31324 sgd_solver.cpp:790] Iteration 5180, lr = 0.01
I0822 20:07:33.773574 31324 solver.cpp:254] Iteration 5200 (1.95202 iter/s, 10.2458s/20 iters), loss = 2.40487
I0822 20:07:33.773785 31324 solver.cpp:273]     Train net output #0: loss = 2.40487 (* 1 = 2.40487 loss)
I0822 20:07:33.773802 31324 sgd_solver.cpp:790] Iteration 5200, lr = 0.01
I0822 20:07:44.538321 31324 solver.cpp:254] Iteration 5220 (1.85797 iter/s, 10.7644s/20 iters), loss = 2.55931
I0822 20:07:44.538395 31324 solver.cpp:273]     Train net output #0: loss = 2.55931 (* 1 = 2.55931 loss)
I0822 20:07:44.538408 31324 sgd_solver.cpp:790] Iteration 5220, lr = 0.01
I0822 20:07:55.529510 31324 solver.cpp:254] Iteration 5240 (1.81967 iter/s, 10.991s/20 iters), loss = 2.65811
I0822 20:07:55.529580 31324 solver.cpp:273]     Train net output #0: loss = 2.65811 (* 1 = 2.65811 loss)
I0822 20:07:55.529592 31324 sgd_solver.cpp:790] Iteration 5240, lr = 0.01
I0822 20:08:05.973444 31324 solver.cpp:254] Iteration 5260 (1.91502 iter/s, 10.4438s/20 iters), loss = 2.49495
I0822 20:08:05.973589 31324 solver.cpp:273]     Train net output #0: loss = 2.49495 (* 1 = 2.49495 loss)
I0822 20:08:05.973606 31324 sgd_solver.cpp:790] Iteration 5260, lr = 0.01
I0822 20:08:16.484460 31324 solver.cpp:254] Iteration 5280 (1.90281 iter/s, 10.5108s/20 iters), loss = 2.67643
I0822 20:08:16.484535 31324 solver.cpp:273]     Train net output #0: loss = 2.67643 (* 1 = 2.67643 loss)
I0822 20:08:16.484549 31324 sgd_solver.cpp:790] Iteration 5280, lr = 0.01
I0822 20:08:26.803059 31324 solver.cpp:254] Iteration 5300 (1.93828 iter/s, 10.3184s/20 iters), loss = 2.42455
I0822 20:08:26.803120 31324 solver.cpp:273]     Train net output #0: loss = 2.42455 (* 1 = 2.42455 loss)
I0822 20:08:26.803131 31324 sgd_solver.cpp:790] Iteration 5300, lr = 0.01
I0822 20:08:37.565028 31324 solver.cpp:254] Iteration 5320 (1.85843 iter/s, 10.7618s/20 iters), loss = 2.38363
I0822 20:08:37.572232 31324 solver.cpp:273]     Train net output #0: loss = 2.38363 (* 1 = 2.38363 loss)
I0822 20:08:37.572253 31324 sgd_solver.cpp:790] Iteration 5320, lr = 0.01
I0822 20:08:48.556691 31324 solver.cpp:254] Iteration 5340 (1.82077 iter/s, 10.9844s/20 iters), loss = 2.56468
I0822 20:08:48.556764 31324 solver.cpp:273]     Train net output #0: loss = 2.56468 (* 1 = 2.56468 loss)
I0822 20:08:48.556779 31324 sgd_solver.cpp:790] Iteration 5340, lr = 0.01
I0822 20:08:59.309252 31324 solver.cpp:254] Iteration 5360 (1.86005 iter/s, 10.7524s/20 iters), loss = 2.70069
I0822 20:08:59.309345 31324 solver.cpp:273]     Train net output #0: loss = 2.70069 (* 1 = 2.70069 loss)
I0822 20:08:59.309360 31324 sgd_solver.cpp:790] Iteration 5360, lr = 0.01
I0822 20:09:09.705185 31324 solver.cpp:254] Iteration 5380 (1.92387 iter/s, 10.3957s/20 iters), loss = 2.50768
I0822 20:09:09.705348 31324 solver.cpp:273]     Train net output #0: loss = 2.50768 (* 1 = 2.50768 loss)
I0822 20:09:09.705363 31324 sgd_solver.cpp:790] Iteration 5380, lr = 0.01
I0822 20:09:19.634690 31324 solver.cpp:254] Iteration 5400 (2.01425 iter/s, 9.92924s/20 iters), loss = 2.45064
I0822 20:09:19.634762 31324 solver.cpp:273]     Train net output #0: loss = 2.45064 (* 1 = 2.45064 loss)
I0822 20:09:19.634773 31324 sgd_solver.cpp:790] Iteration 5400, lr = 0.01
I0822 20:09:29.205771 31324 solver.cpp:254] Iteration 5420 (2.08967 iter/s, 9.57089s/20 iters), loss = 2.51715
I0822 20:09:29.205829 31324 solver.cpp:273]     Train net output #0: loss = 2.51715 (* 1 = 2.51715 loss)
I0822 20:09:29.205840 31324 sgd_solver.cpp:790] Iteration 5420, lr = 0.01
I0822 20:09:37.642386 31324 solver.cpp:254] Iteration 5440 (2.37066 iter/s, 8.43647s/20 iters), loss = 2.5555
I0822 20:09:37.642441 31324 solver.cpp:273]     Train net output #0: loss = 2.5555 (* 1 = 2.5555 loss)
I0822 20:09:37.642452 31324 sgd_solver.cpp:790] Iteration 5440, lr = 0.01
I0822 20:09:46.635613 31324 solver.cpp:254] Iteration 5460 (2.22393 iter/s, 8.99308s/20 iters), loss = 2.58537
I0822 20:09:46.635756 31324 solver.cpp:273]     Train net output #0: loss = 2.58537 (* 1 = 2.58537 loss)
I0822 20:09:46.635767 31324 sgd_solver.cpp:790] Iteration 5460, lr = 0.01
I0822 20:09:57.156829 31324 solver.cpp:254] Iteration 5480 (1.90097 iter/s, 10.521s/20 iters), loss = 2.60848
I0822 20:09:57.156911 31324 solver.cpp:273]     Train net output #0: loss = 2.60848 (* 1 = 2.60848 loss)
I0822 20:09:57.156926 31324 sgd_solver.cpp:790] Iteration 5480, lr = 0.01
I0822 20:10:07.683816 31324 solver.cpp:254] Iteration 5500 (1.89991 iter/s, 10.5268s/20 iters), loss = 2.60538
I0822 20:10:07.683888 31324 solver.cpp:273]     Train net output #0: loss = 2.60538 (* 1 = 2.60538 loss)
I0822 20:10:07.683902 31324 sgd_solver.cpp:790] Iteration 5500, lr = 0.01
I0822 20:10:18.224506 31324 solver.cpp:254] Iteration 5520 (1.89744 iter/s, 10.5405s/20 iters), loss = 2.38937
I0822 20:10:18.224687 31324 solver.cpp:273]     Train net output #0: loss = 2.38937 (* 1 = 2.38937 loss)
I0822 20:10:18.224701 31324 sgd_solver.cpp:790] Iteration 5520, lr = 0.01
I0822 20:10:28.828119 31324 solver.cpp:254] Iteration 5540 (1.8862 iter/s, 10.6033s/20 iters), loss = 2.76707
I0822 20:10:28.828184 31324 solver.cpp:273]     Train net output #0: loss = 2.76707 (* 1 = 2.76707 loss)
I0822 20:10:28.828197 31324 sgd_solver.cpp:790] Iteration 5540, lr = 0.01
I0822 20:10:39.625910 31324 solver.cpp:254] Iteration 5560 (1.85226 iter/s, 10.7976s/20 iters), loss = 2.55096
I0822 20:10:39.625977 31324 solver.cpp:273]     Train net output #0: loss = 2.55096 (* 1 = 2.55096 loss)
I0822 20:10:39.625988 31324 sgd_solver.cpp:790] Iteration 5560, lr = 0.01
I0822 20:10:50.047904 31324 solver.cpp:254] Iteration 5580 (1.91905 iter/s, 10.4218s/20 iters), loss = 2.47854
I0822 20:10:50.048053 31324 solver.cpp:273]     Train net output #0: loss = 2.47854 (* 1 = 2.47854 loss)
I0822 20:10:50.048068 31324 sgd_solver.cpp:790] Iteration 5580, lr = 0.01
I0822 20:10:56.567891 31324 solver.cpp:254] Iteration 5600 (3.06759 iter/s, 6.51978s/20 iters), loss = 2.72644
I0822 20:10:56.580695 31324 solver.cpp:273]     Train net output #0: loss = 2.72644 (* 1 = 2.72644 loss)
I0822 20:10:56.580739 31324 sgd_solver.cpp:790] Iteration 5600, lr = 0.01
I0822 20:11:00.251662 31324 solver.cpp:254] Iteration 5620 (5.44818 iter/s, 3.67095s/20 iters), loss = 2.32608
I0822 20:11:00.263866 31324 solver.cpp:273]     Train net output #0: loss = 2.32608 (* 1 = 2.32608 loss)
I0822 20:11:00.263902 31324 sgd_solver.cpp:790] Iteration 5620, lr = 0.01
I0822 20:11:03.910852 31324 solver.cpp:254] Iteration 5640 (5.48401 iter/s, 3.64697s/20 iters), loss = 2.43414
I0822 20:11:03.923050 31324 solver.cpp:273]     Train net output #0: loss = 2.43414 (* 1 = 2.43414 loss)
I0822 20:11:03.923085 31324 sgd_solver.cpp:790] Iteration 5640, lr = 0.01
I0822 20:11:07.655977 31324 solver.cpp:254] Iteration 5660 (5.35776 iter/s, 3.7329s/20 iters), loss = 2.72987
I0822 20:11:07.668099 31324 solver.cpp:273]     Train net output #0: loss = 2.72987 (* 1 = 2.72987 loss)
I0822 20:11:07.668135 31324 sgd_solver.cpp:790] Iteration 5660, lr = 0.01
I0822 20:11:11.336432 31324 solver.cpp:254] Iteration 5680 (5.4521 iter/s, 3.66831s/20 iters), loss = 2.63981
I0822 20:11:11.348582 31324 solver.cpp:273]     Train net output #0: loss = 2.63981 (* 1 = 2.63981 loss)
I0822 20:11:11.348615 31324 sgd_solver.cpp:790] Iteration 5680, lr = 0.01
I0822 20:11:15.009380 31324 solver.cpp:254] Iteration 5700 (5.46332 iter/s, 3.66078s/20 iters), loss = 2.85594
I0822 20:11:15.021543 31324 solver.cpp:273]     Train net output #0: loss = 2.85594 (* 1 = 2.85594 loss)
I0822 20:11:15.021574 31324 sgd_solver.cpp:790] Iteration 5700, lr = 0.01
I0822 20:11:21.556691 31324 solver.cpp:254] Iteration 5720 (3.06039 iter/s, 6.53511s/20 iters), loss = 2.69972
I0822 20:11:21.568923 31324 solver.cpp:273]     Train net output #0: loss = 2.69972 (* 1 = 2.69972 loss)
I0822 20:11:21.568964 31324 sgd_solver.cpp:790] Iteration 5720, lr = 0.01
I0822 20:11:25.259771 31324 solver.cpp:254] Iteration 5740 (5.41915 iter/s, 3.69062s/20 iters), loss = 2.21423
I0822 20:11:25.271746 31324 solver.cpp:273]     Train net output #0: loss = 2.21423 (* 1 = 2.21423 loss)
I0822 20:11:25.271780 31324 sgd_solver.cpp:790] Iteration 5740, lr = 0.01
I0822 20:11:28.920245 31324 solver.cpp:254] Iteration 5760 (5.48175 iter/s, 3.64847s/20 iters), loss = 2.45536
I0822 20:11:28.932708 31324 solver.cpp:273]     Train net output #0: loss = 2.45536 (* 1 = 2.45536 loss)
I0822 20:11:28.932745 31324 sgd_solver.cpp:790] Iteration 5760, lr = 0.01
I0822 20:11:32.546648 31324 solver.cpp:254] Iteration 5780 (5.53415 iter/s, 3.61392s/20 iters), loss = 2.64014
I0822 20:11:32.558775 31324 solver.cpp:273]     Train net output #0: loss = 2.64014 (* 1 = 2.64014 loss)
I0822 20:11:32.558809 31324 sgd_solver.cpp:790] Iteration 5780, lr = 0.01
I0822 20:11:40.066784 31324 solver.cpp:254] Iteration 5800 (2.66383 iter/s, 7.50798s/20 iters), loss = 2.49856
I0822 20:11:40.066843 31324 solver.cpp:273]     Train net output #0: loss = 2.49856 (* 1 = 2.49856 loss)
I0822 20:11:40.066854 31324 sgd_solver.cpp:790] Iteration 5800, lr = 0.01
I0822 20:11:49.820578 31324 solver.cpp:254] Iteration 5820 (2.05051 iter/s, 9.75366s/20 iters), loss = 2.37582
I0822 20:11:49.820638 31324 solver.cpp:273]     Train net output #0: loss = 2.37582 (* 1 = 2.37582 loss)
I0822 20:11:49.820650 31324 sgd_solver.cpp:790] Iteration 5820, lr = 0.01
I0822 20:12:00.234997 31324 solver.cpp:254] Iteration 5840 (1.92044 iter/s, 10.4143s/20 iters), loss = 2.71126
I0822 20:12:00.235905 31324 solver.cpp:273]     Train net output #0: loss = 2.71126 (* 1 = 2.71126 loss)
I0822 20:12:00.235920 31324 sgd_solver.cpp:790] Iteration 5840, lr = 0.01
I0822 20:12:10.750686 31324 solver.cpp:254] Iteration 5860 (1.9021 iter/s, 10.5147s/20 iters), loss = 2.75299
I0822 20:12:10.750769 31324 solver.cpp:273]     Train net output #0: loss = 2.75299 (* 1 = 2.75299 loss)
I0822 20:12:10.750783 31324 sgd_solver.cpp:790] Iteration 5860, lr = 0.01
I0822 20:12:21.145004 31324 solver.cpp:254] Iteration 5880 (1.92416 iter/s, 10.3941s/20 iters), loss = 2.38423
I0822 20:12:21.145076 31324 solver.cpp:273]     Train net output #0: loss = 2.38423 (* 1 = 2.38423 loss)
I0822 20:12:21.145090 31324 sgd_solver.cpp:790] Iteration 5880, lr = 0.01
I0822 20:12:31.778015 31324 solver.cpp:254] Iteration 5900 (1.88096 iter/s, 10.6328s/20 iters), loss = 2.46148
I0822 20:12:31.779959 31324 solver.cpp:273]     Train net output #0: loss = 2.46148 (* 1 = 2.46148 loss)
I0822 20:12:31.779981 31324 sgd_solver.cpp:790] Iteration 5900, lr = 0.01
I0822 20:12:42.303153 31324 solver.cpp:254] Iteration 5920 (1.90058 iter/s, 10.5231s/20 iters), loss = 2.49802
I0822 20:12:42.303217 31324 solver.cpp:273]     Train net output #0: loss = 2.49802 (* 1 = 2.49802 loss)
I0822 20:12:42.303236 31324 sgd_solver.cpp:790] Iteration 5920, lr = 0.01
I0822 20:12:52.579002 31324 solver.cpp:254] Iteration 5940 (1.94634 iter/s, 10.2757s/20 iters), loss = 2.54803
I0822 20:12:52.579073 31324 solver.cpp:273]     Train net output #0: loss = 2.54803 (* 1 = 2.54803 loss)
I0822 20:12:52.579085 31324 sgd_solver.cpp:790] Iteration 5940, lr = 0.01
I0822 20:13:02.920886 31324 solver.cpp:254] Iteration 5960 (1.93391 iter/s, 10.3417s/20 iters), loss = 2.75126
I0822 20:13:02.921037 31324 solver.cpp:273]     Train net output #0: loss = 2.75126 (* 1 = 2.75126 loss)
I0822 20:13:02.921051 31324 sgd_solver.cpp:790] Iteration 5960, lr = 0.01
I0822 20:13:12.639647 31324 solver.cpp:254] Iteration 5980 (2.05793 iter/s, 9.71852s/20 iters), loss = 2.59703
I0822 20:13:12.639705 31324 solver.cpp:273]     Train net output #0: loss = 2.59703 (* 1 = 2.59703 loss)
I0822 20:13:12.639719 31324 sgd_solver.cpp:790] Iteration 5980, lr = 0.01
I0822 20:13:21.008707 31324 solver.cpp:366] Iteration 6000, Testing net (#0)
I0822 20:13:23.223568 31324 blocking_queue.cpp:49] Waiting for data
I0822 20:13:45.319932 31336 data_layer.cpp:73] Restarting data prefetching from start.
I0822 20:13:45.335878 31324 solver.cpp:433]     Test net output #0: accuracy = 0.47118
I0822 20:13:45.335917 31324 solver.cpp:433]     Test net output #1: accuracy5 = 0.731259
I0822 20:13:45.335927 31324 solver.cpp:433]     Test net output #2: loss = 2.36596 (* 1 = 2.36596 loss)
I0822 20:13:45.510277 31324 solver.cpp:254] Iteration 6000 (0.608452 iter/s, 32.8703s/20 iters), loss = 2.52907
I0822 20:13:45.512725 31324 solver.cpp:273]     Train net output #0: loss = 2.52907 (* 1 = 2.52907 loss)
I0822 20:13:45.512750 31324 sgd_solver.cpp:790] Iteration 6000, lr = 0.01
I0822 20:13:54.775707 31324 solver.cpp:254] Iteration 6020 (2.15915 iter/s, 9.26292s/20 iters), loss = 2.66151
I0822 20:13:54.775754 31324 solver.cpp:273]     Train net output #0: loss = 2.66151 (* 1 = 2.66151 loss)
I0822 20:13:54.775766 31324 sgd_solver.cpp:790] Iteration 6020, lr = 0.01
I0822 20:14:03.997233 31324 solver.cpp:254] Iteration 6040 (2.16887 iter/s, 9.2214s/20 iters), loss = 2.62309
I0822 20:14:03.997298 31324 solver.cpp:273]     Train net output #0: loss = 2.62309 (* 1 = 2.62309 loss)
I0822 20:14:03.997313 31324 sgd_solver.cpp:790] Iteration 6040, lr = 0.01
I0822 20:14:13.206856 31324 solver.cpp:254] Iteration 6060 (2.17167 iter/s, 9.20948s/20 iters), loss = 2.59124
I0822 20:14:13.206914 31324 solver.cpp:273]     Train net output #0: loss = 2.59124 (* 1 = 2.59124 loss)
I0822 20:14:13.206925 31324 sgd_solver.cpp:790] Iteration 6060, lr = 0.01
I0822 20:14:22.971220 31324 solver.cpp:254] Iteration 6080 (2.04829 iter/s, 9.76422s/20 iters), loss = 2.7154
I0822 20:14:22.971416 31324 solver.cpp:273]     Train net output #0: loss = 2.7154 (* 1 = 2.7154 loss)
I0822 20:14:22.971429 31324 sgd_solver.cpp:790] Iteration 6080, lr = 0.01
I0822 20:14:25.562263 31324 blocking_queue.cpp:49] Waiting for data
I0822 20:14:33.603528 31324 solver.cpp:254] Iteration 6100 (1.88111 iter/s, 10.632s/20 iters), loss = 2.54805
I0822 20:14:33.603606 31324 solver.cpp:273]     Train net output #0: loss = 2.54805 (* 1 = 2.54805 loss)
I0822 20:14:33.603623 31324 sgd_solver.cpp:790] Iteration 6100, lr = 0.01
I0822 20:14:44.244153 31324 solver.cpp:254] Iteration 6120 (1.87962 iter/s, 10.6405s/20 iters), loss = 2.52183
I0822 20:14:44.244222 31324 solver.cpp:273]     Train net output #0: loss = 2.52183 (* 1 = 2.52183 loss)
I0822 20:14:44.244235 31324 sgd_solver.cpp:790] Iteration 6120, lr = 0.01
I0822 20:14:54.462436 31324 solver.cpp:254] Iteration 6140 (1.95731 iter/s, 10.2181s/20 iters), loss = 2.5943
I0822 20:14:54.462602 31324 solver.cpp:273]     Train net output #0: loss = 2.5943 (* 1 = 2.5943 loss)
I0822 20:14:54.462615 31324 sgd_solver.cpp:790] Iteration 6140, lr = 0.01
I0822 20:15:05.033483 31324 solver.cpp:254] Iteration 6160 (1.89201 iter/s, 10.5708s/20 iters), loss = 2.71514
I0822 20:15:05.033568 31324 solver.cpp:273]     Train net output #0: loss = 2.71514 (* 1 = 2.71514 loss)
I0822 20:15:05.033591 31324 sgd_solver.cpp:790] Iteration 6160, lr = 0.01
I0822 20:15:15.485651 31324 solver.cpp:254] Iteration 6180 (1.91351 iter/s, 10.452s/20 iters), loss = 2.35128
I0822 20:15:15.485720 31324 solver.cpp:273]     Train net output #0: loss = 2.35128 (* 1 = 2.35128 loss)
I0822 20:15:15.485733 31324 sgd_solver.cpp:790] Iteration 6180, lr = 0.01
I0822 20:15:26.086431 31324 solver.cpp:254] Iteration 6200 (1.88669 iter/s, 10.6006s/20 iters), loss = 2.51296
I0822 20:15:26.088486 31324 solver.cpp:273]     Train net output #0: loss = 2.51296 (* 1 = 2.51296 loss)
I0822 20:15:26.088513 31324 sgd_solver.cpp:790] Iteration 6200, lr = 0.01
I0822 20:15:36.588788 31324 solver.cpp:254] Iteration 6220 (1.90472 iter/s, 10.5002s/20 iters), loss = 2.35492
I0822 20:15:36.588884 31324 solver.cpp:273]     Train net output #0: loss = 2.35492 (* 1 = 2.35492 loss)
I0822 20:15:36.588899 31324 sgd_solver.cpp:790] Iteration 6220, lr = 0.01
I0822 20:15:47.150238 31324 solver.cpp:254] Iteration 6240 (1.89371 iter/s, 10.5613s/20 iters), loss = 2.64147
I0822 20:15:47.150311 31324 solver.cpp:273]     Train net output #0: loss = 2.64147 (* 1 = 2.64147 loss)
I0822 20:15:47.150326 31324 sgd_solver.cpp:790] Iteration 6240, lr = 0.01
I0822 20:15:57.874753 31324 solver.cpp:254] Iteration 6260 (1.86491 iter/s, 10.7243s/20 iters), loss = 2.38458
I0822 20:15:57.875304 31324 solver.cpp:273]     Train net output #0: loss = 2.38458 (* 1 = 2.38458 loss)
I0822 20:15:57.875319 31324 sgd_solver.cpp:790] Iteration 6260, lr = 0.01
I0822 20:16:08.375388 31324 solver.cpp:254] Iteration 6280 (1.90476 iter/s, 10.5s/20 iters), loss = 2.54589
I0822 20:16:08.375458 31324 solver.cpp:273]     Train net output #0: loss = 2.54589 (* 1 = 2.54589 loss)
I0822 20:16:08.375475 31324 sgd_solver.cpp:790] Iteration 6280, lr = 0.01
I0822 20:16:18.845003 31324 solver.cpp:254] Iteration 6300 (1.91032 iter/s, 10.4695s/20 iters), loss = 2.42837
I0822 20:16:18.845082 31324 solver.cpp:273]     Train net output #0: loss = 2.42837 (* 1 = 2.42837 loss)
I0822 20:16:18.845096 31324 sgd_solver.cpp:790] Iteration 6300, lr = 0.01
I0822 20:16:29.625370 31324 solver.cpp:254] Iteration 6320 (1.85525 iter/s, 10.7802s/20 iters), loss = 2.59573
I0822 20:16:29.627009 31324 solver.cpp:273]     Train net output #0: loss = 2.59573 (* 1 = 2.59573 loss)
I0822 20:16:29.627028 31324 sgd_solver.cpp:790] Iteration 6320, lr = 0.01
I0822 20:16:40.359227 31324 solver.cpp:254] Iteration 6340 (1.86356 iter/s, 10.7321s/20 iters), loss = 2.19855
I0822 20:16:40.359299 31324 solver.cpp:273]     Train net output #0: loss = 2.19855 (* 1 = 2.19855 loss)
I0822 20:16:40.359314 31324 sgd_solver.cpp:790] Iteration 6340, lr = 0.01
I0822 20:16:50.882431 31324 solver.cpp:254] Iteration 6360 (1.90059 iter/s, 10.523s/20 iters), loss = 2.46856
I0822 20:16:50.882511 31324 solver.cpp:273]     Train net output #0: loss = 2.46856 (* 1 = 2.46856 loss)
I0822 20:16:50.882526 31324 sgd_solver.cpp:790] Iteration 6360, lr = 0.01
I0822 20:17:01.695865 31324 solver.cpp:254] Iteration 6380 (1.84958 iter/s, 10.8133s/20 iters), loss = 2.4884
I0822 20:17:01.696028 31324 solver.cpp:273]     Train net output #0: loss = 2.4884 (* 1 = 2.4884 loss)
I0822 20:17:01.696040 31324 sgd_solver.cpp:790] Iteration 6380, lr = 0.01
I0822 20:17:12.149165 31324 solver.cpp:254] Iteration 6400 (1.91332 iter/s, 10.4531s/20 iters), loss = 2.4866
I0822 20:17:12.149243 31324 solver.cpp:273]     Train net output #0: loss = 2.4866 (* 1 = 2.4866 loss)
I0822 20:17:12.149256 31324 sgd_solver.cpp:790] Iteration 6400, lr = 0.01
I0822 20:17:22.750802 31324 solver.cpp:254] Iteration 6420 (1.88653 iter/s, 10.6015s/20 iters), loss = 2.26367
I0822 20:17:22.750864 31324 solver.cpp:273]     Train net output #0: loss = 2.26367 (* 1 = 2.26367 loss)
I0822 20:17:22.750874 31324 sgd_solver.cpp:790] Iteration 6420, lr = 0.01
I0822 20:17:33.210939 31324 solver.cpp:254] Iteration 6440 (1.91205 iter/s, 10.46s/20 iters), loss = 2.39487
I0822 20:17:33.211097 31324 solver.cpp:273]     Train net output #0: loss = 2.39487 (* 1 = 2.39487 loss)
I0822 20:17:33.211110 31324 sgd_solver.cpp:790] Iteration 6440, lr = 0.01
I0822 20:17:43.795822 31324 solver.cpp:254] Iteration 6460 (1.88953 iter/s, 10.5846s/20 iters), loss = 2.59774
I0822 20:17:43.795888 31324 solver.cpp:273]     Train net output #0: loss = 2.59774 (* 1 = 2.59774 loss)
I0822 20:17:43.795902 31324 sgd_solver.cpp:790] Iteration 6460, lr = 0.01
I0822 20:17:54.524972 31324 solver.cpp:254] Iteration 6480 (1.86411 iter/s, 10.729s/20 iters), loss = 2.47909
I0822 20:17:54.525040 31324 solver.cpp:273]     Train net output #0: loss = 2.47909 (* 1 = 2.47909 loss)
I0822 20:17:54.525053 31324 sgd_solver.cpp:790] Iteration 6480, lr = 0.01
I0822 20:18:05.294970 31324 solver.cpp:254] Iteration 6500 (1.85704 iter/s, 10.7698s/20 iters), loss = 2.54229
I0822 20:18:05.295133 31324 solver.cpp:273]     Train net output #0: loss = 2.54229 (* 1 = 2.54229 loss)
I0822 20:18:05.295145 31324 sgd_solver.cpp:790] Iteration 6500, lr = 0.01
I0822 20:18:15.836112 31324 solver.cpp:254] Iteration 6520 (1.89737 iter/s, 10.5409s/20 iters), loss = 2.71805
I0822 20:18:15.836169 31324 solver.cpp:273]     Train net output #0: loss = 2.71805 (* 1 = 2.71805 loss)
I0822 20:18:15.836181 31324 sgd_solver.cpp:790] Iteration 6520, lr = 0.01
I0822 20:18:26.318599 31324 solver.cpp:254] Iteration 6540 (1.90797 iter/s, 10.4824s/20 iters), loss = 2.56433
I0822 20:18:26.318657 31324 solver.cpp:273]     Train net output #0: loss = 2.56433 (* 1 = 2.56433 loss)
I0822 20:18:26.318667 31324 sgd_solver.cpp:790] Iteration 6540, lr = 0.01
I0822 20:18:36.519310 31324 solver.cpp:254] Iteration 6560 (1.96067 iter/s, 10.2006s/20 iters), loss = 2.68806
I0822 20:18:36.519490 31324 solver.cpp:273]     Train net output #0: loss = 2.68806 (* 1 = 2.68806 loss)
I0822 20:18:36.519502 31324 sgd_solver.cpp:790] Iteration 6560, lr = 0.01
I0822 20:18:45.624989 31324 solver.cpp:254] Iteration 6580 (2.19649 iter/s, 9.10543s/20 iters), loss = 2.38584
I0822 20:18:45.625054 31324 solver.cpp:273]     Train net output #0: loss = 2.38584 (* 1 = 2.38584 loss)
I0822 20:18:45.625066 31324 sgd_solver.cpp:790] Iteration 6580, lr = 0.01
I0822 20:18:55.212311 31324 solver.cpp:254] Iteration 6600 (2.08612 iter/s, 9.58718s/20 iters), loss = 2.7292
I0822 20:18:55.212375 31324 solver.cpp:273]     Train net output #0: loss = 2.7292 (* 1 = 2.7292 loss)
I0822 20:18:55.212395 31324 sgd_solver.cpp:790] Iteration 6600, lr = 0.01
I0822 20:19:04.937288 31324 solver.cpp:254] Iteration 6620 (2.05659 iter/s, 9.72484s/20 iters), loss = 2.55143
I0822 20:19:04.937350 31324 solver.cpp:273]     Train net output #0: loss = 2.55143 (* 1 = 2.55143 loss)
I0822 20:19:04.937361 31324 sgd_solver.cpp:790] Iteration 6620, lr = 0.01
I0822 20:19:14.663746 31324 solver.cpp:254] Iteration 6640 (2.05627 iter/s, 9.72633s/20 iters), loss = 2.46758
I0822 20:19:14.663879 31324 solver.cpp:273]     Train net output #0: loss = 2.46758 (* 1 = 2.46758 loss)
I0822 20:19:14.663892 31324 sgd_solver.cpp:790] Iteration 6640, lr = 0.01
I0822 20:19:25.292510 31324 solver.cpp:254] Iteration 6660 (1.88172 iter/s, 10.6286s/20 iters), loss = 2.80767
I0822 20:19:25.292582 31324 solver.cpp:273]     Train net output #0: loss = 2.80767 (* 1 = 2.80767 loss)
I0822 20:19:25.292595 31324 sgd_solver.cpp:790] Iteration 6660, lr = 0.01
I0822 20:19:35.846382 31324 solver.cpp:254] Iteration 6680 (1.89507 iter/s, 10.5537s/20 iters), loss = 2.66703
I0822 20:19:35.846438 31324 solver.cpp:273]     Train net output #0: loss = 2.66703 (* 1 = 2.66703 loss)
I0822 20:19:35.846451 31324 sgd_solver.cpp:790] Iteration 6680, lr = 0.01
I0822 20:19:46.380352 31324 solver.cpp:254] Iteration 6700 (1.89864 iter/s, 10.5338s/20 iters), loss = 2.68009
I0822 20:19:46.380473 31324 solver.cpp:273]     Train net output #0: loss = 2.68009 (* 1 = 2.68009 loss)
I0822 20:19:46.380486 31324 sgd_solver.cpp:790] Iteration 6700, lr = 0.01
I0822 20:19:56.573423 31324 solver.cpp:254] Iteration 6720 (1.96215 iter/s, 10.1929s/20 iters), loss = 2.65498
I0822 20:19:56.573483 31324 solver.cpp:273]     Train net output #0: loss = 2.65498 (* 1 = 2.65498 loss)
I0822 20:19:56.573494 31324 sgd_solver.cpp:790] Iteration 6720, lr = 0.01
I0822 20:20:06.683115 31324 solver.cpp:254] Iteration 6740 (1.97833 iter/s, 10.1096s/20 iters), loss = 2.74041
I0822 20:20:06.683187 31324 solver.cpp:273]     Train net output #0: loss = 2.74041 (* 1 = 2.74041 loss)
I0822 20:20:06.683202 31324 sgd_solver.cpp:790] Iteration 6740, lr = 0.01
I0822 20:20:15.907451 31324 solver.cpp:254] Iteration 6760 (2.16821 iter/s, 9.2242s/20 iters), loss = 2.69831
I0822 20:20:15.907510 31324 solver.cpp:273]     Train net output #0: loss = 2.69831 (* 1 = 2.69831 loss)
I0822 20:20:15.907521 31324 sgd_solver.cpp:790] Iteration 6760, lr = 0.01
I0822 20:20:25.109730 31324 solver.cpp:254] Iteration 6780 (2.1734 iter/s, 9.20215s/20 iters), loss = 2.49072
I0822 20:20:25.109928 31324 solver.cpp:273]     Train net output #0: loss = 2.49072 (* 1 = 2.49072 loss)
I0822 20:20:25.109946 31324 sgd_solver.cpp:790] Iteration 6780, lr = 0.01
I0822 20:20:34.724558 31324 solver.cpp:254] Iteration 6800 (2.08018 iter/s, 9.61456s/20 iters), loss = 2.5804
I0822 20:20:34.724649 31324 solver.cpp:273]     Train net output #0: loss = 2.5804 (* 1 = 2.5804 loss)
I0822 20:20:34.724669 31324 sgd_solver.cpp:790] Iteration 6800, lr = 0.01
I0822 20:20:45.321138 31324 solver.cpp:254] Iteration 6820 (1.88743 iter/s, 10.5964s/20 iters), loss = 2.54117
I0822 20:20:45.321204 31324 solver.cpp:273]     Train net output #0: loss = 2.54117 (* 1 = 2.54117 loss)
I0822 20:20:45.321214 31324 sgd_solver.cpp:790] Iteration 6820, lr = 0.01
I0822 20:20:55.779822 31324 solver.cpp:254] Iteration 6840 (1.91231 iter/s, 10.4585s/20 iters), loss = 2.71962
I0822 20:20:55.780017 31324 solver.cpp:273]     Train net output #0: loss = 2.71962 (* 1 = 2.71962 loss)
I0822 20:20:55.780033 31324 sgd_solver.cpp:790] Iteration 6840, lr = 0.01
I0822 20:21:05.661255 31324 solver.cpp:254] Iteration 6860 (2.02405 iter/s, 9.88118s/20 iters), loss = 2.73594
I0822 20:21:05.661310 31324 solver.cpp:273]     Train net output #0: loss = 2.73594 (* 1 = 2.73594 loss)
I0822 20:21:05.661321 31324 sgd_solver.cpp:790] Iteration 6860, lr = 0.01
I0822 20:21:14.612423 31324 solver.cpp:254] Iteration 6880 (2.23437 iter/s, 8.95105s/20 iters), loss = 2.55783
I0822 20:21:14.612479 31324 solver.cpp:273]     Train net output #0: loss = 2.55783 (* 1 = 2.55783 loss)
I0822 20:21:14.612490 31324 sgd_solver.cpp:790] Iteration 6880, lr = 0.01
I0822 20:21:23.533586 31324 solver.cpp:254] Iteration 6900 (2.24189 iter/s, 8.92104s/20 iters), loss = 2.38154
I0822 20:21:23.533655 31324 solver.cpp:273]     Train net output #0: loss = 2.38154 (* 1 = 2.38154 loss)
I0822 20:21:23.533674 31324 sgd_solver.cpp:790] Iteration 6900, lr = 0.01
I0822 20:21:33.893081 31324 solver.cpp:254] Iteration 6920 (1.93062 iter/s, 10.3594s/20 iters), loss = 2.49421
I0822 20:21:33.893245 31324 solver.cpp:273]     Train net output #0: loss = 2.49421 (* 1 = 2.49421 loss)
I0822 20:21:33.893260 31324 sgd_solver.cpp:790] Iteration 6920, lr = 0.01
I0822 20:21:44.637600 31324 solver.cpp:254] Iteration 6940 (1.86145 iter/s, 10.7443s/20 iters), loss = 2.57931
I0822 20:21:44.637673 31324 solver.cpp:273]     Train net output #0: loss = 2.57931 (* 1 = 2.57931 loss)
I0822 20:21:44.637687 31324 sgd_solver.cpp:790] Iteration 6940, lr = 0.01
I0822 20:21:55.116470 31324 solver.cpp:254] Iteration 6960 (1.90863 iter/s, 10.4787s/20 iters), loss = 2.65271
I0822 20:21:55.116566 31324 solver.cpp:273]     Train net output #0: loss = 2.65271 (* 1 = 2.65271 loss)
I0822 20:21:55.116581 31324 sgd_solver.cpp:790] Iteration 6960, lr = 0.01
I0822 20:22:05.528023 31324 solver.cpp:254] Iteration 6980 (1.92097 iter/s, 10.4114s/20 iters), loss = 2.3821
I0822 20:22:05.528847 31324 solver.cpp:273]     Train net output #0: loss = 2.3821 (* 1 = 2.3821 loss)
I0822 20:22:05.528863 31324 sgd_solver.cpp:790] Iteration 6980, lr = 0.01
I0822 20:22:15.417848 31324 solver.cpp:366] Iteration 7000, Testing net (#0)
I0822 20:22:17.872673 31324 blocking_queue.cpp:49] Waiting for data
I0822 20:22:39.571847 31336 data_layer.cpp:73] Restarting data prefetching from start.
I0822 20:22:39.588171 31324 solver.cpp:433]     Test net output #0: accuracy = 0.47226
I0822 20:22:39.588214 31324 solver.cpp:433]     Test net output #1: accuracy5 = 0.73122
I0822 20:22:39.588223 31324 solver.cpp:433]     Test net output #2: loss = 2.34992 (* 1 = 2.34992 loss)
I0822 20:22:39.760476 31324 solver.cpp:254] Iteration 7000 (0.584258 iter/s, 34.2315s/20 iters), loss = 2.76682
I0822 20:22:39.762976 31324 solver.cpp:273]     Train net output #0: loss = 2.76682 (* 1 = 2.76682 loss)
I0822 20:22:39.763000 31324 sgd_solver.cpp:790] Iteration 7000, lr = 0.01
I0822 20:22:48.338925 31324 solver.cpp:254] Iteration 7020 (2.33212 iter/s, 8.57591s/20 iters), loss = 2.65178
I0822 20:22:48.338984 31324 solver.cpp:273]     Train net output #0: loss = 2.65178 (* 1 = 2.65178 loss)
I0822 20:22:48.338999 31324 sgd_solver.cpp:790] Iteration 7020, lr = 0.01
I0822 20:22:57.288789 31324 solver.cpp:254] Iteration 7040 (2.2347 iter/s, 8.94974s/20 iters), loss = 2.52936
I0822 20:22:57.288843 31324 solver.cpp:273]     Train net output #0: loss = 2.52936 (* 1 = 2.52936 loss)
I0822 20:22:57.288853 31324 sgd_solver.cpp:790] Iteration 7040, lr = 0.01
I0822 20:23:06.159591 31324 solver.cpp:254] Iteration 7060 (2.25462 iter/s, 8.87068s/20 iters), loss = 2.84211
I0822 20:23:06.159656 31324 solver.cpp:273]     Train net output #0: loss = 2.84211 (* 1 = 2.84211 loss)
I0822 20:23:06.159669 31324 sgd_solver.cpp:790] Iteration 7060, lr = 0.01
I0822 20:23:16.876742 31324 solver.cpp:254] Iteration 7080 (1.86619 iter/s, 10.717s/20 iters), loss = 2.52387
I0822 20:23:16.877221 31324 solver.cpp:273]     Train net output #0: loss = 2.52387 (* 1 = 2.52387 loss)
I0822 20:23:16.877244 31324 sgd_solver.cpp:790] Iteration 7080, lr = 0.01
I0822 20:23:23.083549 31324 blocking_queue.cpp:49] Waiting for data
I0822 20:23:27.428709 31324 solver.cpp:254] Iteration 7100 (1.89557 iter/s, 10.5509s/20 iters), loss = 2.59234
I0822 20:23:27.428783 31324 solver.cpp:273]     Train net output #0: loss = 2.59234 (* 1 = 2.59234 loss)
I0822 20:23:27.428797 31324 sgd_solver.cpp:790] Iteration 7100, lr = 0.01
I0822 20:23:38.004705 31324 solver.cpp:254] Iteration 7120 (1.8911 iter/s, 10.5758s/20 iters), loss = 2.56964
I0822 20:23:38.004776 31324 solver.cpp:273]     Train net output #0: loss = 2.56964 (* 1 = 2.56964 loss)
I0822 20:23:38.004793 31324 sgd_solver.cpp:790] Iteration 7120, lr = 0.01
I0822 20:23:48.561226 31324 solver.cpp:254] Iteration 7140 (1.89459 iter/s, 10.5564s/20 iters), loss = 2.60818
I0822 20:23:48.561444 31324 solver.cpp:273]     Train net output #0: loss = 2.60818 (* 1 = 2.60818 loss)
I0822 20:23:48.561463 31324 sgd_solver.cpp:790] Iteration 7140, lr = 0.01
I0822 20:23:58.962153 31324 solver.cpp:254] Iteration 7160 (1.92296 iter/s, 10.4006s/20 iters), loss = 2.64867
I0822 20:23:58.962236 31324 solver.cpp:273]     Train net output #0: loss = 2.64867 (* 1 = 2.64867 loss)
I0822 20:23:58.963160 31324 sgd_solver.cpp:790] Iteration 7160, lr = 0.01
I0822 20:24:09.564546 31324 solver.cpp:254] Iteration 7180 (1.8864 iter/s, 10.6022s/20 iters), loss = 2.62026
I0822 20:24:09.564616 31324 solver.cpp:273]     Train net output #0: loss = 2.62026 (* 1 = 2.62026 loss)
I0822 20:24:09.564628 31324 sgd_solver.cpp:790] Iteration 7180, lr = 0.01
I0822 20:24:20.644520 31324 solver.cpp:254] Iteration 7200 (1.80508 iter/s, 11.0798s/20 iters), loss = 2.40173
I0822 20:24:20.646934 31324 solver.cpp:273]     Train net output #0: loss = 2.40173 (* 1 = 2.40173 loss)
I0822 20:24:20.646950 31324 sgd_solver.cpp:790] Iteration 7200, lr = 0.01
I0822 20:24:31.163157 31324 solver.cpp:254] Iteration 7220 (1.90184 iter/s, 10.5162s/20 iters), loss = 2.70449
I0822 20:24:31.163215 31324 solver.cpp:273]     Train net output #0: loss = 2.70449 (* 1 = 2.70449 loss)
I0822 20:24:31.163228 31324 sgd_solver.cpp:790] Iteration 7220, lr = 0.01
I0822 20:24:39.266777 31324 solver.cpp:254] Iteration 7240 (2.46807 iter/s, 8.10349s/20 iters), loss = 2.56251
I0822 20:24:39.266875 31324 solver.cpp:273]     Train net output #0: loss = 2.56251 (* 1 = 2.56251 loss)
I0822 20:24:39.268592 31324 sgd_solver.cpp:790] Iteration 7240, lr = 0.01
I0822 20:24:49.754760 31324 solver.cpp:254] Iteration 7260 (1.90697 iter/s, 10.4878s/20 iters), loss = 2.75336
I0822 20:24:49.754827 31324 solver.cpp:273]     Train net output #0: loss = 2.75336 (* 1 = 2.75336 loss)
I0822 20:24:49.754838 31324 sgd_solver.cpp:790] Iteration 7260, lr = 0.01
I0822 20:25:00.110951 31324 solver.cpp:254] Iteration 7280 (1.93124 iter/s, 10.356s/20 iters), loss = 2.68421
I0822 20:25:00.111093 31324 solver.cpp:273]     Train net output #0: loss = 2.68421 (* 1 = 2.68421 loss)
I0822 20:25:00.111107 31324 sgd_solver.cpp:790] Iteration 7280, lr = 0.01
I0822 20:25:10.440938 31324 solver.cpp:254] Iteration 7300 (1.93615 iter/s, 10.3298s/20 iters), loss = 2.39135
I0822 20:25:10.441007 31324 solver.cpp:273]     Train net output #0: loss = 2.39135 (* 1 = 2.39135 loss)
I0822 20:25:10.441021 31324 sgd_solver.cpp:790] Iteration 7300, lr = 0.01
I0822 20:25:20.789081 31324 solver.cpp:254] Iteration 7320 (1.93274 iter/s, 10.348s/20 iters), loss = 2.60539
I0822 20:25:20.789152 31324 solver.cpp:273]     Train net output #0: loss = 2.60539 (* 1 = 2.60539 loss)
I0822 20:25:20.789166 31324 sgd_solver.cpp:790] Iteration 7320, lr = 0.01
I0822 20:25:31.388250 31324 solver.cpp:254] Iteration 7340 (1.88697 iter/s, 10.599s/20 iters), loss = 2.56152
I0822 20:25:31.388424 31324 solver.cpp:273]     Train net output #0: loss = 2.56152 (* 1 = 2.56152 loss)
I0822 20:25:31.388438 31324 sgd_solver.cpp:790] Iteration 7340, lr = 0.01
I0822 20:25:41.840744 31324 solver.cpp:254] Iteration 7360 (1.91346 iter/s, 10.4522s/20 iters), loss = 2.68168
I0822 20:25:41.840808 31324 solver.cpp:273]     Train net output #0: loss = 2.68168 (* 1 = 2.68168 loss)
I0822 20:25:41.840821 31324 sgd_solver.cpp:790] Iteration 7360, lr = 0.01
I0822 20:25:52.334435 31324 solver.cpp:254] Iteration 7380 (1.90593 iter/s, 10.4935s/20 iters), loss = 2.45819
I0822 20:25:52.334496 31324 solver.cpp:273]     Train net output #0: loss = 2.45819 (* 1 = 2.45819 loss)
I0822 20:25:52.334508 31324 sgd_solver.cpp:790] Iteration 7380, lr = 0.01
I0822 20:26:02.756528 31324 solver.cpp:254] Iteration 7400 (1.91903 iter/s, 10.422s/20 iters), loss = 2.67906
I0822 20:26:02.756819 31324 solver.cpp:273]     Train net output #0: loss = 2.67906 (* 1 = 2.67906 loss)
I0822 20:26:02.756834 31324 sgd_solver.cpp:790] Iteration 7400, lr = 0.01
I0822 20:26:13.230306 31324 solver.cpp:254] Iteration 7420 (1.9096 iter/s, 10.4734s/20 iters), loss = 2.73542
I0822 20:26:13.230376 31324 solver.cpp:273]     Train net output #0: loss = 2.73542 (* 1 = 2.73542 loss)
I0822 20:26:13.230386 31324 sgd_solver.cpp:790] Iteration 7420, lr = 0.01
I0822 20:26:23.730813 31324 solver.cpp:254] Iteration 7440 (1.9047 iter/s, 10.5004s/20 iters), loss = 2.34311
I0822 20:26:23.730865 31324 solver.cpp:273]     Train net output #0: loss = 2.34311 (* 1 = 2.34311 loss)
I0822 20:26:23.730880 31324 sgd_solver.cpp:790] Iteration 7440, lr = 0.01
I0822 20:26:34.014295 31324 solver.cpp:254] Iteration 7460 (1.94489 iter/s, 10.2834s/20 iters), loss = 2.65616
I0822 20:26:34.014914 31324 solver.cpp:273]     Train net output #0: loss = 2.65616 (* 1 = 2.65616 loss)
I0822 20:26:34.014928 31324 sgd_solver.cpp:790] Iteration 7460, lr = 0.01
I0822 20:26:44.221318 31324 solver.cpp:254] Iteration 7480 (1.95957 iter/s, 10.2063s/20 iters), loss = 2.42796
I0822 20:26:44.221380 31324 solver.cpp:273]     Train net output #0: loss = 2.42796 (* 1 = 2.42796 loss)
I0822 20:26:44.221391 31324 sgd_solver.cpp:790] Iteration 7480, lr = 0.01
I0822 20:26:54.898828 31324 solver.cpp:254] Iteration 7500 (1.87312 iter/s, 10.6774s/20 iters), loss = 2.71262
I0822 20:26:54.898892 31324 solver.cpp:273]     Train net output #0: loss = 2.71262 (* 1 = 2.71262 loss)
I0822 20:26:54.898903 31324 sgd_solver.cpp:790] Iteration 7500, lr = 0.01
I0822 20:27:05.254161 31324 solver.cpp:254] Iteration 7520 (1.9314 iter/s, 10.3552s/20 iters), loss = 2.62557
I0822 20:27:05.254335 31324 solver.cpp:273]     Train net output #0: loss = 2.62557 (* 1 = 2.62557 loss)
I0822 20:27:05.254350 31324 sgd_solver.cpp:790] Iteration 7520, lr = 0.01
I0822 20:27:15.684195 31324 solver.cpp:254] Iteration 7540 (1.91758 iter/s, 10.4298s/20 iters), loss = 2.4751
I0822 20:27:15.684271 31324 solver.cpp:273]     Train net output #0: loss = 2.4751 (* 1 = 2.4751 loss)
I0822 20:27:15.684298 31324 sgd_solver.cpp:790] Iteration 7540, lr = 0.01
I0822 20:27:26.057801 31324 solver.cpp:254] Iteration 7560 (1.928 iter/s, 10.3735s/20 iters), loss = 2.51638
I0822 20:27:26.057868 31324 solver.cpp:273]     Train net output #0: loss = 2.51638 (* 1 = 2.51638 loss)
I0822 20:27:26.057880 31324 sgd_solver.cpp:790] Iteration 7560, lr = 0.01
I0822 20:27:36.356431 31324 solver.cpp:254] Iteration 7580 (1.94203 iter/s, 10.2985s/20 iters), loss = 2.71753
I0822 20:27:36.359109 31324 solver.cpp:273]     Train net output #0: loss = 2.71753 (* 1 = 2.71753 loss)
I0822 20:27:36.359124 31324 sgd_solver.cpp:790] Iteration 7580, lr = 0.01
I0822 20:27:46.719406 31324 solver.cpp:254] Iteration 7600 (1.93046 iter/s, 10.3602s/20 iters), loss = 2.66877
I0822 20:27:46.719471 31324 solver.cpp:273]     Train net output #0: loss = 2.66877 (* 1 = 2.66877 loss)
I0822 20:27:46.719483 31324 sgd_solver.cpp:790] Iteration 7600, lr = 0.01
I0822 20:27:57.068981 31324 solver.cpp:254] Iteration 7620 (1.93247 iter/s, 10.3494s/20 iters), loss = 2.25824
I0822 20:27:57.069047 31324 solver.cpp:273]     Train net output #0: loss = 2.25824 (* 1 = 2.25824 loss)
I0822 20:27:57.069061 31324 sgd_solver.cpp:790] Iteration 7620, lr = 0.01
I0822 20:28:07.610785 31324 solver.cpp:254] Iteration 7640 (1.89723 iter/s, 10.5417s/20 iters), loss = 2.50763
I0822 20:28:07.611608 31324 solver.cpp:273]     Train net output #0: loss = 2.50763 (* 1 = 2.50763 loss)
I0822 20:28:07.611620 31324 sgd_solver.cpp:790] Iteration 7640, lr = 0.01
I0822 20:28:17.207954 31324 solver.cpp:254] Iteration 7660 (2.08414 iter/s, 9.59629s/20 iters), loss = 2.64121
I0822 20:28:17.208024 31324 solver.cpp:273]     Train net output #0: loss = 2.64121 (* 1 = 2.64121 loss)
I0822 20:28:17.208037 31324 sgd_solver.cpp:790] Iteration 7660, lr = 0.01
I0822 20:28:26.598338 31324 solver.cpp:254] Iteration 7680 (2.12987 iter/s, 9.39024s/20 iters), loss = 2.7174
I0822 20:28:26.598415 31324 solver.cpp:273]     Train net output #0: loss = 2.7174 (* 1 = 2.7174 loss)
I0822 20:28:26.599493 31324 sgd_solver.cpp:790] Iteration 7680, lr = 0.01
I0822 20:28:36.504503 31324 solver.cpp:254] Iteration 7700 (2.01897 iter/s, 9.90602s/20 iters), loss = 2.38253
I0822 20:28:36.504592 31324 solver.cpp:273]     Train net output #0: loss = 2.38253 (* 1 = 2.38253 loss)
I0822 20:28:36.504606 31324 sgd_solver.cpp:790] Iteration 7700, lr = 0.01
I0822 20:28:45.614076 31324 solver.cpp:254] Iteration 7720 (2.19553 iter/s, 9.10944s/20 iters), loss = 2.63193
I0822 20:28:45.626726 31324 solver.cpp:273]     Train net output #0: loss = 2.63193 (* 1 = 2.63193 loss)
I0822 20:28:45.626765 31324 sgd_solver.cpp:790] Iteration 7720, lr = 0.01
I0822 20:28:49.282377 31324 solver.cpp:254] Iteration 7740 (5.47101 iter/s, 3.65563s/20 iters), loss = 2.43893
I0822 20:28:49.302496 31324 solver.cpp:273]     Train net output #0: loss = 2.43893 (* 1 = 2.43893 loss)
I0822 20:28:49.302538 31324 sgd_solver.cpp:790] Iteration 7740, lr = 0.01
I0822 20:28:52.915989 31324 solver.cpp:254] Iteration 7760 (5.53483 iter/s, 3.61348s/20 iters), loss = 2.36281
I0822 20:28:52.928140 31324 solver.cpp:273]     Train net output #0: loss = 2.36281 (* 1 = 2.36281 loss)
I0822 20:28:52.928184 31324 sgd_solver.cpp:790] Iteration 7760, lr = 0.01
I0822 20:28:56.536478 31324 solver.cpp:254] Iteration 7780 (5.54272 iter/s, 3.60833s/20 iters), loss = 2.64966
I0822 20:28:56.548570 31324 solver.cpp:273]     Train net output #0: loss = 2.64966 (* 1 = 2.64966 loss)
I0822 20:28:56.548611 31324 sgd_solver.cpp:790] Iteration 7780, lr = 0.01
I0822 20:29:00.176084 31324 solver.cpp:254] Iteration 7800 (5.51343 iter/s, 3.62751s/20 iters), loss = 2.53213
I0822 20:29:00.188158 31324 solver.cpp:273]     Train net output #0: loss = 2.53213 (* 1 = 2.53213 loss)
I0822 20:29:00.188195 31324 sgd_solver.cpp:790] Iteration 7800, lr = 0.01
I0822 20:29:03.813374 31324 solver.cpp:254] Iteration 7820 (5.51695 iter/s, 3.62519s/20 iters), loss = 2.48208
I0822 20:29:03.825992 31324 solver.cpp:273]     Train net output #0: loss = 2.48208 (* 1 = 2.48208 loss)
I0822 20:29:03.826041 31324 sgd_solver.cpp:790] Iteration 7820, lr = 0.01
I0822 20:29:11.665144 31324 solver.cpp:254] Iteration 7840 (2.5513 iter/s, 7.83914s/20 iters), loss = 2.65066
I0822 20:29:11.665199 31324 solver.cpp:273]     Train net output #0: loss = 2.65066 (* 1 = 2.65066 loss)
I0822 20:29:11.665210 31324 sgd_solver.cpp:790] Iteration 7840, lr = 0.01
I0822 20:29:21.543131 31324 solver.cpp:254] Iteration 7860 (2.02473 iter/s, 9.87787s/20 iters), loss = 2.62771
I0822 20:29:21.543260 31324 solver.cpp:273]     Train net output #0: loss = 2.62771 (* 1 = 2.62771 loss)
I0822 20:29:21.543282 31324 sgd_solver.cpp:790] Iteration 7860, lr = 0.01
I0822 20:29:31.968497 31324 solver.cpp:254] Iteration 7880 (1.91843 iter/s, 10.4252s/20 iters), loss = 2.71738
I0822 20:29:31.968560 31324 solver.cpp:273]     Train net output #0: loss = 2.71738 (* 1 = 2.71738 loss)
I0822 20:29:31.968571 31324 sgd_solver.cpp:790] Iteration 7880, lr = 0.01
I0822 20:29:42.419445 31324 solver.cpp:254] Iteration 7900 (1.91373 iter/s, 10.4508s/20 iters), loss = 2.81676
I0822 20:29:42.419541 31324 solver.cpp:273]     Train net output #0: loss = 2.81676 (* 1 = 2.81676 loss)
I0822 20:29:42.419559 31324 sgd_solver.cpp:790] Iteration 7900, lr = 0.01
I0822 20:29:51.477108 31324 solver.cpp:254] Iteration 7920 (2.20811 iter/s, 9.05751s/20 iters), loss = 2.61558
I0822 20:29:51.477171 31324 solver.cpp:273]     Train net output #0: loss = 2.61558 (* 1 = 2.61558 loss)
I0822 20:29:51.477185 31324 sgd_solver.cpp:790] Iteration 7920, lr = 0.01
I0822 20:29:59.930455 31324 solver.cpp:254] Iteration 7940 (2.36596 iter/s, 8.45322s/20 iters), loss = 2.45714
I0822 20:29:59.930618 31324 solver.cpp:273]     Train net output #0: loss = 2.45714 (* 1 = 2.45714 loss)
I0822 20:29:59.930631 31324 sgd_solver.cpp:790] Iteration 7940, lr = 0.01
I0822 20:30:09.356714 31324 solver.cpp:254] Iteration 7960 (2.12178 iter/s, 9.42603s/20 iters), loss = 2.69049
I0822 20:30:09.356772 31324 solver.cpp:273]     Train net output #0: loss = 2.69049 (* 1 = 2.69049 loss)
I0822 20:30:09.356782 31324 sgd_solver.cpp:790] Iteration 7960, lr = 0.01
I0822 20:30:19.541785 31324 solver.cpp:254] Iteration 7980 (1.96369 iter/s, 10.1849s/20 iters), loss = 2.78056
I0822 20:30:19.541852 31324 solver.cpp:273]     Train net output #0: loss = 2.78056 (* 1 = 2.78056 loss)
I0822 20:30:19.542824 31324 sgd_solver.cpp:790] Iteration 7980, lr = 0.01
I0822 20:30:29.267427 31324 solver.cpp:366] Iteration 8000, Testing net (#0)
I0822 20:30:31.901222 31324 blocking_queue.cpp:49] Waiting for data
I0822 20:30:53.437496 31336 data_layer.cpp:73] Restarting data prefetching from start.
I0822 20:30:53.456225 31324 solver.cpp:433]     Test net output #0: accuracy = 0.47368
I0822 20:30:53.456276 31324 solver.cpp:433]     Test net output #1: accuracy5 = 0.732219
I0822 20:30:53.456291 31324 solver.cpp:433]     Test net output #2: loss = 2.32701 (* 1 = 2.32701 loss)
I0822 20:30:53.630551 31324 solver.cpp:254] Iteration 8000 (0.586708 iter/s, 34.0885s/20 iters), loss = 2.464
I0822 20:30:53.632930 31324 solver.cpp:273]     Train net output #0: loss = 2.464 (* 1 = 2.464 loss)
I0822 20:30:53.632947 31324 sgd_solver.cpp:790] Iteration 8000, lr = 0.01
I0822 20:31:03.093940 31324 solver.cpp:254] Iteration 8020 (2.11395 iter/s, 9.46094s/20 iters), loss = 2.56824
I0822 20:31:03.096817 31324 solver.cpp:273]     Train net output #0: loss = 2.56824 (* 1 = 2.56824 loss)
I0822 20:31:03.096832 31324 sgd_solver.cpp:790] Iteration 8020, lr = 0.01
I0822 20:31:13.564613 31324 solver.cpp:254] Iteration 8040 (1.91063 iter/s, 10.4677s/20 iters), loss = 2.5326
I0822 20:31:13.564703 31324 solver.cpp:273]     Train net output #0: loss = 2.5326 (* 1 = 2.5326 loss)
I0822 20:31:13.564719 31324 sgd_solver.cpp:790] Iteration 8040, lr = 0.01
I0822 20:31:23.854142 31324 solver.cpp:254] Iteration 8060 (1.94375 iter/s, 10.2894s/20 iters), loss = 2.53429
I0822 20:31:23.854212 31324 solver.cpp:273]     Train net output #0: loss = 2.53429 (* 1 = 2.53429 loss)
I0822 20:31:23.854228 31324 sgd_solver.cpp:790] Iteration 8060, lr = 0.01
I0822 20:31:34.388417 31324 solver.cpp:254] Iteration 8080 (1.89859 iter/s, 10.5341s/20 iters), loss = 2.59748
I0822 20:31:34.397907 31324 solver.cpp:273]     Train net output #0: loss = 2.59748 (* 1 = 2.59748 loss)
I0822 20:31:34.397948 31324 sgd_solver.cpp:790] Iteration 8080, lr = 0.01
I0822 20:31:44.734213 31324 solver.cpp:254] Iteration 8100 (1.93494 iter/s, 10.3363s/20 iters), loss = 2.51809
I0822 20:31:44.734272 31324 solver.cpp:273]     Train net output #0: loss = 2.51809 (* 1 = 2.51809 loss)
I0822 20:31:44.734283 31324 sgd_solver.cpp:790] Iteration 8100, lr = 0.01
I0822 20:31:47.313556 31324 blocking_queue.cpp:49] Waiting for data
I0822 20:31:55.229806 31324 solver.cpp:254] Iteration 8120 (1.90559 iter/s, 10.4955s/20 iters), loss = 2.44118
I0822 20:31:55.229897 31324 solver.cpp:273]     Train net output #0: loss = 2.44118 (* 1 = 2.44118 loss)
I0822 20:31:55.229914 31324 sgd_solver.cpp:790] Iteration 8120, lr = 0.01
I0822 20:32:05.700781 31324 solver.cpp:254] Iteration 8140 (1.91007 iter/s, 10.4708s/20 iters), loss = 2.36464
I0822 20:32:05.701473 31324 solver.cpp:273]     Train net output #0: loss = 2.36464 (* 1 = 2.36464 loss)
I0822 20:32:05.701486 31324 sgd_solver.cpp:790] Iteration 8140, lr = 0.01
I0822 20:32:16.069294 31324 solver.cpp:254] Iteration 8160 (1.92906 iter/s, 10.3677s/20 iters), loss = 2.48861
I0822 20:32:16.069406 31324 solver.cpp:273]     Train net output #0: loss = 2.48861 (* 1 = 2.48861 loss)
I0822 20:32:16.069428 31324 sgd_solver.cpp:790] Iteration 8160, lr = 0.01
I0822 20:32:26.476367 31324 solver.cpp:254] Iteration 8180 (1.9218 iter/s, 10.4069s/20 iters), loss = 2.55366
I0822 20:32:26.476449 31324 solver.cpp:273]     Train net output #0: loss = 2.55366 (* 1 = 2.55366 loss)
I0822 20:32:26.476464 31324 sgd_solver.cpp:790] Iteration 8180, lr = 0.01
I0822 20:32:37.089757 31324 solver.cpp:254] Iteration 8200 (1.88444 iter/s, 10.6132s/20 iters), loss = 2.30097
I0822 20:32:37.089959 31324 solver.cpp:273]     Train net output #0: loss = 2.30097 (* 1 = 2.30097 loss)
I0822 20:32:37.089974 31324 sgd_solver.cpp:790] Iteration 8200, lr = 0.01
I0822 20:32:47.539511 31324 solver.cpp:254] Iteration 8220 (1.91397 iter/s, 10.4495s/20 iters), loss = 2.68354
I0822 20:32:47.539587 31324 solver.cpp:273]     Train net output #0: loss = 2.68354 (* 1 = 2.68354 loss)
I0822 20:32:47.539600 31324 sgd_solver.cpp:790] Iteration 8220, lr = 0.01
I0822 20:32:58.192023 31324 solver.cpp:254] Iteration 8240 (1.87752 iter/s, 10.6524s/20 iters), loss = 2.38562
I0822 20:32:58.192090 31324 solver.cpp:273]     Train net output #0: loss = 2.38562 (* 1 = 2.38562 loss)
I0822 20:32:58.192102 31324 sgd_solver.cpp:790] Iteration 8240, lr = 0.01
I0822 20:33:08.977933 31324 solver.cpp:254] Iteration 8260 (1.85429 iter/s, 10.7858s/20 iters), loss = 2.72045
I0822 20:33:08.979387 31324 solver.cpp:273]     Train net output #0: loss = 2.72045 (* 1 = 2.72045 loss)
I0822 20:33:08.979400 31324 sgd_solver.cpp:790] Iteration 8260, lr = 0.01
I0822 20:33:19.412634 31324 solver.cpp:254] Iteration 8280 (1.91696 iter/s, 10.4332s/20 iters), loss = 2.66771
I0822 20:33:19.412698 31324 solver.cpp:273]     Train net output #0: loss = 2.66771 (* 1 = 2.66771 loss)
I0822 20:33:19.412708 31324 sgd_solver.cpp:790] Iteration 8280, lr = 0.01
I0822 20:33:30.094180 31324 solver.cpp:254] Iteration 8300 (1.87241 iter/s, 10.6814s/20 iters), loss = 2.60486
I0822 20:33:30.094255 31324 solver.cpp:273]     Train net output #0: loss = 2.60486 (* 1 = 2.60486 loss)
I0822 20:33:30.094269 31324 sgd_solver.cpp:790] Iteration 8300, lr = 0.01
I0822 20:33:40.475850 31324 solver.cpp:254] Iteration 8320 (1.9265 iter/s, 10.3815s/20 iters), loss = 2.55244
I0822 20:33:40.475997 31324 solver.cpp:273]     Train net output #0: loss = 2.55244 (* 1 = 2.55244 loss)
I0822 20:33:40.476009 31324 sgd_solver.cpp:790] Iteration 8320, lr = 0.01
I0822 20:33:50.775030 31324 solver.cpp:254] Iteration 8340 (1.94194 iter/s, 10.299s/20 iters), loss = 2.57494
I0822 20:33:50.775100 31324 solver.cpp:273]     Train net output #0: loss = 2.57494 (* 1 = 2.57494 loss)
I0822 20:33:50.775111 31324 sgd_solver.cpp:790] Iteration 8340, lr = 0.01
I0822 20:34:01.384279 31324 solver.cpp:254] Iteration 8360 (1.88517 iter/s, 10.6091s/20 iters), loss = 2.78705
I0822 20:34:01.384342 31324 solver.cpp:273]     Train net output #0: loss = 2.78705 (* 1 = 2.78705 loss)
I0822 20:34:01.384356 31324 sgd_solver.cpp:790] Iteration 8360, lr = 0.01
I0822 20:34:11.498476 31324 solver.cpp:254] Iteration 8380 (1.97744 iter/s, 10.1141s/20 iters), loss = 2.56857
I0822 20:34:11.499704 31324 solver.cpp:273]     Train net output #0: loss = 2.56857 (* 1 = 2.56857 loss)
I0822 20:34:11.499719 31324 sgd_solver.cpp:790] Iteration 8380, lr = 0.01
I0822 20:34:20.765338 31324 solver.cpp:254] Iteration 8400 (2.15853 iter/s, 9.26558s/20 iters), loss = 2.55544
I0822 20:34:20.765403 31324 solver.cpp:273]     Train net output #0: loss = 2.55544 (* 1 = 2.55544 loss)
I0822 20:34:20.765414 31324 sgd_solver.cpp:790] Iteration 8400, lr = 0.01
I0822 20:34:30.288894 31324 solver.cpp:254] Iteration 8420 (2.10009 iter/s, 9.52342s/20 iters), loss = 2.61556
I0822 20:34:30.288987 31324 solver.cpp:273]     Train net output #0: loss = 2.61556 (* 1 = 2.61556 loss)
I0822 20:34:30.289001 31324 sgd_solver.cpp:790] Iteration 8420, lr = 0.01
I0822 20:34:39.680233 31324 solver.cpp:254] Iteration 8440 (2.12966 iter/s, 9.39119s/20 iters), loss = 2.74071
I0822 20:34:39.680302 31324 solver.cpp:273]     Train net output #0: loss = 2.74071 (* 1 = 2.74071 loss)
I0822 20:34:39.680318 31324 sgd_solver.cpp:790] Iteration 8440, lr = 0.01
I0822 20:34:49.244029 31324 solver.cpp:254] Iteration 8460 (2.09125 iter/s, 9.56367s/20 iters), loss = 2.73088
I0822 20:34:49.244204 31324 solver.cpp:273]     Train net output #0: loss = 2.73088 (* 1 = 2.73088 loss)
I0822 20:34:49.244215 31324 sgd_solver.cpp:790] Iteration 8460, lr = 0.01
I0822 20:34:59.969734 31324 solver.cpp:254] Iteration 8480 (1.86472 iter/s, 10.7255s/20 iters), loss = 2.63644
I0822 20:34:59.969807 31324 solver.cpp:273]     Train net output #0: loss = 2.63644 (* 1 = 2.63644 loss)
I0822 20:34:59.969825 31324 sgd_solver.cpp:790] Iteration 8480, lr = 0.01
I0822 20:35:10.468430 31324 solver.cpp:254] Iteration 8500 (1.90503 iter/s, 10.4985s/20 iters), loss = 2.55999
I0822 20:35:10.468513 31324 solver.cpp:273]     Train net output #0: loss = 2.55999 (* 1 = 2.55999 loss)
I0822 20:35:10.468528 31324 sgd_solver.cpp:790] Iteration 8500, lr = 0.01
I0822 20:35:21.263079 31324 solver.cpp:254] Iteration 8520 (1.8528 iter/s, 10.7945s/20 iters), loss = 2.69597
I0822 20:35:21.265043 31324 solver.cpp:273]     Train net output #0: loss = 2.69597 (* 1 = 2.69597 loss)
I0822 20:35:21.265058 31324 sgd_solver.cpp:790] Iteration 8520, lr = 0.01
I0822 20:35:31.603246 31324 solver.cpp:254] Iteration 8540 (1.93459 iter/s, 10.3381s/20 iters), loss = 2.55604
I0822 20:35:31.603345 31324 solver.cpp:273]     Train net output #0: loss = 2.55604 (* 1 = 2.55604 loss)
I0822 20:35:31.603365 31324 sgd_solver.cpp:790] Iteration 8540, lr = 0.01
I0822 20:35:42.164062 31324 solver.cpp:254] Iteration 8560 (1.89382 iter/s, 10.5607s/20 iters), loss = 2.61529
I0822 20:35:42.164139 31324 solver.cpp:273]     Train net output #0: loss = 2.61529 (* 1 = 2.61529 loss)
I0822 20:35:42.164155 31324 sgd_solver.cpp:790] Iteration 8560, lr = 0.01
I0822 20:35:52.452692 31324 solver.cpp:254] Iteration 8580 (1.94392 iter/s, 10.2885s/20 iters), loss = 2.69148
I0822 20:35:52.452873 31324 solver.cpp:273]     Train net output #0: loss = 2.69148 (* 1 = 2.69148 loss)
I0822 20:35:52.452885 31324 sgd_solver.cpp:790] Iteration 8580, lr = 0.01
I0822 20:36:01.858115 31324 solver.cpp:254] Iteration 8600 (2.12649 iter/s, 9.40518s/20 iters), loss = 2.64667
I0822 20:36:01.858192 31324 solver.cpp:273]     Train net output #0: loss = 2.64667 (* 1 = 2.64667 loss)
I0822 20:36:01.858206 31324 sgd_solver.cpp:790] Iteration 8600, lr = 0.01
I0822 20:36:11.472147 31324 solver.cpp:254] Iteration 8620 (2.08032 iter/s, 9.61389s/20 iters), loss = 2.44857
I0822 20:36:11.472211 31324 solver.cpp:273]     Train net output #0: loss = 2.44857 (* 1 = 2.44857 loss)
I0822 20:36:11.472223 31324 sgd_solver.cpp:790] Iteration 8620, lr = 0.01
I0822 20:36:21.057093 31324 solver.cpp:254] Iteration 8640 (2.08663 iter/s, 9.58482s/20 iters), loss = 2.44833
I0822 20:36:21.057163 31324 solver.cpp:273]     Train net output #0: loss = 2.44833 (* 1 = 2.44833 loss)
I0822 20:36:21.057178 31324 sgd_solver.cpp:790] Iteration 8640, lr = 0.01
I0822 20:36:30.747709 31324 solver.cpp:254] Iteration 8660 (2.06388 iter/s, 9.69048s/20 iters), loss = 2.58875
I0822 20:36:30.747864 31324 solver.cpp:273]     Train net output #0: loss = 2.58875 (* 1 = 2.58875 loss)
I0822 20:36:30.747876 31324 sgd_solver.cpp:790] Iteration 8660, lr = 0.01
I0822 20:36:40.408264 31324 solver.cpp:254] Iteration 8680 (2.07032 iter/s, 9.66034s/20 iters), loss = 2.66988
I0822 20:36:40.408339 31324 solver.cpp:273]     Train net output #0: loss = 2.66988 (* 1 = 2.66988 loss)
I0822 20:36:40.408354 31324 sgd_solver.cpp:790] Iteration 8680, lr = 0.01
I0822 20:36:49.595685 31324 solver.cpp:254] Iteration 8700 (2.17692 iter/s, 9.18729s/20 iters), loss = 2.46381
I0822 20:36:49.595737 31324 solver.cpp:273]     Train net output #0: loss = 2.46381 (* 1 = 2.46381 loss)
I0822 20:36:49.595747 31324 sgd_solver.cpp:790] Iteration 8700, lr = 0.01
I0822 20:36:58.605541 31324 solver.cpp:254] Iteration 8720 (2.21982 iter/s, 9.00974s/20 iters), loss = 2.7929
I0822 20:36:58.605612 31324 solver.cpp:273]     Train net output #0: loss = 2.7929 (* 1 = 2.7929 loss)
I0822 20:36:58.605624 31324 sgd_solver.cpp:790] Iteration 8720, lr = 0.01
I0822 20:37:08.841194 31324 solver.cpp:254] Iteration 8740 (1.95398 iter/s, 10.2355s/20 iters), loss = 2.24725
I0822 20:37:08.841413 31324 solver.cpp:273]     Train net output #0: loss = 2.24725 (* 1 = 2.24725 loss)
I0822 20:37:08.841429 31324 sgd_solver.cpp:790] Iteration 8740, lr = 0.01
I0822 20:37:19.505885 31324 solver.cpp:254] Iteration 8760 (1.8754 iter/s, 10.6644s/20 iters), loss = 2.40576
I0822 20:37:19.505957 31324 solver.cpp:273]     Train net output #0: loss = 2.40576 (* 1 = 2.40576 loss)
I0822 20:37:19.505970 31324 sgd_solver.cpp:790] Iteration 8760, lr = 0.01
I0822 20:37:30.149444 31324 solver.cpp:254] Iteration 8780 (1.87909 iter/s, 10.6434s/20 iters), loss = 2.50672
I0822 20:37:30.149504 31324 solver.cpp:273]     Train net output #0: loss = 2.50672 (* 1 = 2.50672 loss)
I0822 20:37:30.149514 31324 sgd_solver.cpp:790] Iteration 8780, lr = 0.01
I0822 20:37:40.861850 31324 solver.cpp:254] Iteration 8800 (1.86702 iter/s, 10.7123s/20 iters), loss = 2.68168
I0822 20:37:40.861975 31324 solver.cpp:273]     Train net output #0: loss = 2.68168 (* 1 = 2.68168 loss)
I0822 20:37:40.861989 31324 sgd_solver.cpp:790] Iteration 8800, lr = 0.01
I0822 20:37:51.411166 31324 solver.cpp:254] Iteration 8820 (1.89589 iter/s, 10.5491s/20 iters), loss = 2.32139
I0822 20:37:51.411255 31324 solver.cpp:273]     Train net output #0: loss = 2.32139 (* 1 = 2.32139 loss)
I0822 20:37:51.411269 31324 sgd_solver.cpp:790] Iteration 8820, lr = 0.01
I0822 20:38:01.204116 31324 solver.cpp:254] Iteration 8840 (2.04231 iter/s, 9.79281s/20 iters), loss = 2.34991
I0822 20:38:01.204165 31324 solver.cpp:273]     Train net output #0: loss = 2.34991 (* 1 = 2.34991 loss)
I0822 20:38:01.204175 31324 sgd_solver.cpp:790] Iteration 8840, lr = 0.01
I0822 20:38:10.736984 31324 solver.cpp:254] Iteration 8860 (2.09803 iter/s, 9.53276s/20 iters), loss = 2.48779
I0822 20:38:10.737041 31324 solver.cpp:273]     Train net output #0: loss = 2.48779 (* 1 = 2.48779 loss)
I0822 20:38:10.737052 31324 sgd_solver.cpp:790] Iteration 8860, lr = 0.01
I0822 20:38:20.558913 31324 solver.cpp:254] Iteration 8880 (2.03629 iter/s, 9.82181s/20 iters), loss = 2.57763
I0822 20:38:20.561496 31324 solver.cpp:273]     Train net output #0: loss = 2.57763 (* 1 = 2.57763 loss)
I0822 20:38:20.561513 31324 sgd_solver.cpp:790] Iteration 8880, lr = 0.01
I0822 20:38:30.888500 31324 solver.cpp:254] Iteration 8900 (1.93668 iter/s, 10.3269s/20 iters), loss = 2.33358
I0822 20:38:30.888572 31324 solver.cpp:273]     Train net output #0: loss = 2.33358 (* 1 = 2.33358 loss)
I0822 20:38:30.888586 31324 sgd_solver.cpp:790] Iteration 8900, lr = 0.01
I0822 20:38:41.171911 31324 solver.cpp:254] Iteration 8920 (1.94491 iter/s, 10.2833s/20 iters), loss = 2.40196
I0822 20:38:41.171981 31324 solver.cpp:273]     Train net output #0: loss = 2.40196 (* 1 = 2.40196 loss)
I0822 20:38:41.171993 31324 sgd_solver.cpp:790] Iteration 8920, lr = 0.01
I0822 20:38:51.922284 31324 solver.cpp:254] Iteration 8940 (1.86042 iter/s, 10.7502s/20 iters), loss = 2.41866
I0822 20:38:51.922418 31324 solver.cpp:273]     Train net output #0: loss = 2.41866 (* 1 = 2.41866 loss)
I0822 20:38:51.922430 31324 sgd_solver.cpp:790] Iteration 8940, lr = 0.01
I0822 20:39:02.471232 31324 solver.cpp:254] Iteration 8960 (1.89596 iter/s, 10.5487s/20 iters), loss = 2.54515
I0822 20:39:02.471309 31324 solver.cpp:273]     Train net output #0: loss = 2.54515 (* 1 = 2.54515 loss)
I0822 20:39:02.471324 31324 sgd_solver.cpp:790] Iteration 8960, lr = 0.01
I0822 20:39:12.933612 31324 solver.cpp:254] Iteration 8980 (1.91164 iter/s, 10.4622s/20 iters), loss = 2.57929
I0822 20:39:12.933674 31324 solver.cpp:273]     Train net output #0: loss = 2.57929 (* 1 = 2.57929 loss)
I0822 20:39:12.933686 31324 sgd_solver.cpp:790] Iteration 8980, lr = 0.01
I0822 20:39:22.882642 31324 solver.cpp:366] Iteration 9000, Testing net (#0)
I0822 20:39:25.734820 31324 blocking_queue.cpp:49] Waiting for data
I0822 20:39:48.017202 31336 data_layer.cpp:73] Restarting data prefetching from start.
I0822 20:39:48.033973 31324 solver.cpp:433]     Test net output #0: accuracy = 0.46234
I0822 20:39:48.034010 31324 solver.cpp:433]     Test net output #1: accuracy5 = 0.723859
I0822 20:39:48.034019 31324 solver.cpp:433]     Test net output #2: loss = 2.38908 (* 1 = 2.38908 loss)
I0822 20:39:48.207446 31324 solver.cpp:254] Iteration 9000 (0.566996 iter/s, 35.2736s/20 iters), loss = 2.68437
I0822 20:39:48.209820 31324 solver.cpp:273]     Train net output #0: loss = 2.68437 (* 1 = 2.68437 loss)
I0822 20:39:48.209841 31324 sgd_solver.cpp:790] Iteration 9000, lr = 0.01
I0822 20:39:57.813344 31324 solver.cpp:254] Iteration 9020 (2.08258 iter/s, 9.60347s/20 iters), loss = 2.64813
I0822 20:39:57.813514 31324 solver.cpp:273]     Train net output #0: loss = 2.64813 (* 1 = 2.64813 loss)
I0822 20:39:57.813525 31324 sgd_solver.cpp:790] Iteration 9020, lr = 0.01
I0822 20:40:08.558223 31324 solver.cpp:254] Iteration 9040 (1.86139 iter/s, 10.7447s/20 iters), loss = 2.60162
I0822 20:40:08.558281 31324 solver.cpp:273]     Train net output #0: loss = 2.60162 (* 1 = 2.60162 loss)
I0822 20:40:08.558291 31324 sgd_solver.cpp:790] Iteration 9040, lr = 0.01
I0822 20:40:19.085084 31324 solver.cpp:254] Iteration 9060 (1.89992 iter/s, 10.5267s/20 iters), loss = 2.71136
I0822 20:40:19.085172 31324 solver.cpp:273]     Train net output #0: loss = 2.71136 (* 1 = 2.71136 loss)
I0822 20:40:19.085191 31324 sgd_solver.cpp:790] Iteration 9060, lr = 0.01
I0822 20:40:29.927155 31324 solver.cpp:254] Iteration 9080 (1.84469 iter/s, 10.8419s/20 iters), loss = 2.71182
I0822 20:40:29.927325 31324 solver.cpp:273]     Train net output #0: loss = 2.71182 (* 1 = 2.71182 loss)
I0822 20:40:29.927342 31324 sgd_solver.cpp:790] Iteration 9080, lr = 0.01
I0822 20:40:40.464470 31324 solver.cpp:254] Iteration 9100 (1.89806 iter/s, 10.5371s/20 iters), loss = 2.72028
I0822 20:40:40.464545 31324 solver.cpp:273]     Train net output #0: loss = 2.72028 (* 1 = 2.72028 loss)
I0822 20:40:40.464557 31324 sgd_solver.cpp:790] Iteration 9100, lr = 0.01
I0822 20:40:47.330955 31324 blocking_queue.cpp:49] Waiting for data
I0822 20:40:51.194056 31324 solver.cpp:254] Iteration 9120 (1.86403 iter/s, 10.7294s/20 iters), loss = 2.62581
I0822 20:40:51.194123 31324 solver.cpp:273]     Train net output #0: loss = 2.62581 (* 1 = 2.62581 loss)
I0822 20:40:51.194134 31324 sgd_solver.cpp:790] Iteration 9120, lr = 0.01
I0822 20:41:01.494200 31324 solver.cpp:254] Iteration 9140 (1.94175 iter/s, 10.3s/20 iters), loss = 2.37887
I0822 20:41:01.494546 31324 solver.cpp:273]     Train net output #0: loss = 2.37887 (* 1 = 2.37887 loss)
I0822 20:41:01.494562 31324 sgd_solver.cpp:790] Iteration 9140, lr = 0.01
I0822 20:41:11.866470 31324 solver.cpp:254] Iteration 9160 (1.9283 iter/s, 10.3718s/20 iters), loss = 2.5654
I0822 20:41:11.866569 31324 solver.cpp:273]     Train net output #0: loss = 2.5654 (* 1 = 2.5654 loss)
I0822 20:41:11.866585 31324 sgd_solver.cpp:790] Iteration 9160, lr = 0.01
I0822 20:41:22.278286 31324 solver.cpp:254] Iteration 9180 (1.92093 iter/s, 10.4116s/20 iters), loss = 2.69344
I0822 20:41:22.278372 31324 solver.cpp:273]     Train net output #0: loss = 2.69344 (* 1 = 2.69344 loss)
I0822 20:41:22.278388 31324 sgd_solver.cpp:790] Iteration 9180, lr = 0.01
I0822 20:41:32.713465 31324 solver.cpp:254] Iteration 9200 (1.91662 iter/s, 10.435s/20 iters), loss = 2.60242
I0822 20:41:32.713603 31324 solver.cpp:273]     Train net output #0: loss = 2.60242 (* 1 = 2.60242 loss)
I0822 20:41:32.713613 31324 sgd_solver.cpp:790] Iteration 9200, lr = 0.01
I0822 20:41:42.988216 31324 solver.cpp:254] Iteration 9220 (1.94656 iter/s, 10.2745s/20 iters), loss = 2.60235
I0822 20:41:42.988277 31324 solver.cpp:273]     Train net output #0: loss = 2.60235 (* 1 = 2.60235 loss)
I0822 20:41:42.988291 31324 sgd_solver.cpp:790] Iteration 9220, lr = 0.01
I0822 20:41:53.426143 31324 solver.cpp:254] Iteration 9240 (1.91611 iter/s, 10.4378s/20 iters), loss = 2.44733
I0822 20:41:53.426205 31324 solver.cpp:273]     Train net output #0: loss = 2.44733 (* 1 = 2.44733 loss)
I0822 20:41:53.426216 31324 sgd_solver.cpp:790] Iteration 9240, lr = 0.01
I0822 20:42:03.989877 31324 solver.cpp:254] Iteration 9260 (1.8933 iter/s, 10.5636s/20 iters), loss = 2.48551
I0822 20:42:03.990065 31324 solver.cpp:273]     Train net output #0: loss = 2.48551 (* 1 = 2.48551 loss)
I0822 20:42:03.990108 31324 sgd_solver.cpp:790] Iteration 9260, lr = 0.01
I0822 20:42:14.304585 31324 solver.cpp:254] Iteration 9280 (1.93903 iter/s, 10.3145s/20 iters), loss = 2.32341
I0822 20:42:14.304672 31324 solver.cpp:273]     Train net output #0: loss = 2.32341 (* 1 = 2.32341 loss)
I0822 20:42:14.304687 31324 sgd_solver.cpp:790] Iteration 9280, lr = 0.01
I0822 20:42:24.852882 31324 solver.cpp:254] Iteration 9300 (1.89607 iter/s, 10.5481s/20 iters), loss = 2.51822
I0822 20:42:24.852965 31324 solver.cpp:273]     Train net output #0: loss = 2.51822 (* 1 = 2.51822 loss)
I0822 20:42:24.852984 31324 sgd_solver.cpp:790] Iteration 9300, lr = 0.01
I0822 20:42:35.544771 31324 solver.cpp:254] Iteration 9320 (1.8706 iter/s, 10.6917s/20 iters), loss = 2.5119
I0822 20:42:35.544987 31324 solver.cpp:273]     Train net output #0: loss = 2.5119 (* 1 = 2.5119 loss)
I0822 20:42:35.545003 31324 sgd_solver.cpp:790] Iteration 9320, lr = 0.01
I0822 20:42:46.285688 31324 solver.cpp:254] Iteration 9340 (1.86209 iter/s, 10.7406s/20 iters), loss = 2.34941
I0822 20:42:46.285760 31324 solver.cpp:273]     Train net output #0: loss = 2.34941 (* 1 = 2.34941 loss)
I0822 20:42:46.285774 31324 sgd_solver.cpp:790] Iteration 9340, lr = 0.01
I0822 20:42:56.882222 31324 solver.cpp:254] Iteration 9360 (1.88743 iter/s, 10.5964s/20 iters), loss = 2.80344
I0822 20:42:56.882295 31324 solver.cpp:273]     Train net output #0: loss = 2.80344 (* 1 = 2.80344 loss)
I0822 20:42:56.882308 31324 sgd_solver.cpp:790] Iteration 9360, lr = 0.01
I0822 20:43:07.294469 31324 solver.cpp:254] Iteration 9380 (1.92084 iter/s, 10.4121s/20 iters), loss = 2.45883
I0822 20:43:07.294627 31324 solver.cpp:273]     Train net output #0: loss = 2.45883 (* 1 = 2.45883 loss)
I0822 20:43:07.296676 31324 sgd_solver.cpp:790] Iteration 9380, lr = 0.01
I0822 20:43:17.556478 31324 solver.cpp:254] Iteration 9400 (1.94898 iter/s, 10.2618s/20 iters), loss = 2.42491
I0822 20:43:17.556567 31324 solver.cpp:273]     Train net output #0: loss = 2.42491 (* 1 = 2.42491 loss)
I0822 20:43:17.556584 31324 sgd_solver.cpp:790] Iteration 9400, lr = 0.01
I0822 20:43:27.894678 31324 solver.cpp:254] Iteration 9420 (1.9346 iter/s, 10.338s/20 iters), loss = 2.80228
I0822 20:43:27.894752 31324 solver.cpp:273]     Train net output #0: loss = 2.80228 (* 1 = 2.80228 loss)
I0822 20:43:27.894764 31324 sgd_solver.cpp:790] Iteration 9420, lr = 0.01
I0822 20:43:38.655876 31324 solver.cpp:254] Iteration 9440 (1.85855 iter/s, 10.7611s/20 iters), loss = 2.43677
I0822 20:43:38.656036 31324 solver.cpp:273]     Train net output #0: loss = 2.43677 (* 1 = 2.43677 loss)
I0822 20:43:38.656059 31324 sgd_solver.cpp:790] Iteration 9440, lr = 0.01
I0822 20:43:49.372910 31324 solver.cpp:254] Iteration 9460 (1.86623 iter/s, 10.7168s/20 iters), loss = 2.6696
I0822 20:43:49.372973 31324 solver.cpp:273]     Train net output #0: loss = 2.6696 (* 1 = 2.6696 loss)
I0822 20:43:49.372983 31324 sgd_solver.cpp:790] Iteration 9460, lr = 0.01
I0822 20:43:59.944881 31324 solver.cpp:254] Iteration 9480 (1.89182 iter/s, 10.5718s/20 iters), loss = 2.68954
I0822 20:43:59.944947 31324 solver.cpp:273]     Train net output #0: loss = 2.68954 (* 1 = 2.68954 loss)
I0822 20:43:59.944957 31324 sgd_solver.cpp:790] Iteration 9480, lr = 0.01
I0822 20:44:10.710814 31324 solver.cpp:254] Iteration 9500 (1.85774 iter/s, 10.7658s/20 iters), loss = 2.70303
I0822 20:44:10.710981 31324 solver.cpp:273]     Train net output #0: loss = 2.70303 (* 1 = 2.70303 loss)
I0822 20:44:10.710994 31324 sgd_solver.cpp:790] Iteration 9500, lr = 0.01
I0822 20:44:21.387239 31324 solver.cpp:254] Iteration 9520 (1.87333 iter/s, 10.6762s/20 iters), loss = 2.70194
I0822 20:44:21.387331 31324 solver.cpp:273]     Train net output #0: loss = 2.70194 (* 1 = 2.70194 loss)
I0822 20:44:21.387351 31324 sgd_solver.cpp:790] Iteration 9520, lr = 0.01
I0822 20:44:32.012310 31324 solver.cpp:254] Iteration 9540 (1.88237 iter/s, 10.6249s/20 iters), loss = 2.63528
I0822 20:44:32.012389 31324 solver.cpp:273]     Train net output #0: loss = 2.63528 (* 1 = 2.63528 loss)
I0822 20:44:32.012403 31324 sgd_solver.cpp:790] Iteration 9540, lr = 0.01
I0822 20:44:42.553407 31324 solver.cpp:254] Iteration 9560 (1.89736 iter/s, 10.5409s/20 iters), loss = 2.58759
I0822 20:44:42.553601 31324 solver.cpp:273]     Train net output #0: loss = 2.58759 (* 1 = 2.58759 loss)
I0822 20:44:42.553617 31324 sgd_solver.cpp:790] Iteration 9560, lr = 0.01
I0822 20:44:53.238744 31324 solver.cpp:254] Iteration 9580 (1.87177 iter/s, 10.6851s/20 iters), loss = 2.45014
I0822 20:44:53.238811 31324 solver.cpp:273]     Train net output #0: loss = 2.45014 (* 1 = 2.45014 loss)
I0822 20:44:53.238823 31324 sgd_solver.cpp:790] Iteration 9580, lr = 0.01
I0822 20:45:03.690943 31324 solver.cpp:254] Iteration 9600 (1.9135 iter/s, 10.4521s/20 iters), loss = 2.43807
I0822 20:45:03.691005 31324 solver.cpp:273]     Train net output #0: loss = 2.43807 (* 1 = 2.43807 loss)
I0822 20:45:03.691015 31324 sgd_solver.cpp:790] Iteration 9600, lr = 0.01
I0822 20:45:14.331986 31324 solver.cpp:254] Iteration 9620 (1.87954 iter/s, 10.6409s/20 iters), loss = 2.64481
I0822 20:45:14.332156 31324 solver.cpp:273]     Train net output #0: loss = 2.64481 (* 1 = 2.64481 loss)
I0822 20:45:14.332172 31324 sgd_solver.cpp:790] Iteration 9620, lr = 0.01
I0822 20:45:24.712150 31324 solver.cpp:254] Iteration 9640 (1.9268 iter/s, 10.3799s/20 iters), loss = 2.65269
I0822 20:45:24.712219 31324 solver.cpp:273]     Train net output #0: loss = 2.65269 (* 1 = 2.65269 loss)
I0822 20:45:24.712231 31324 sgd_solver.cpp:790] Iteration 9640, lr = 0.01
I0822 20:45:34.165777 31324 solver.cpp:254] Iteration 9660 (2.11562 iter/s, 9.45349s/20 iters), loss = 2.50373
I0822 20:45:34.165845 31324 solver.cpp:273]     Train net output #0: loss = 2.50373 (* 1 = 2.50373 loss)
I0822 20:45:34.165858 31324 sgd_solver.cpp:790] Iteration 9660, lr = 0.01
I0822 20:45:43.120702 31324 solver.cpp:254] Iteration 9680 (2.23344 iter/s, 8.95479s/20 iters), loss = 2.97818
I0822 20:45:43.120776 31324 solver.cpp:273]     Train net output #0: loss = 2.97818 (* 1 = 2.97818 loss)
I0822 20:45:43.120790 31324 sgd_solver.cpp:790] Iteration 9680, lr = 0.01
I0822 20:45:51.950529 31324 solver.cpp:254] Iteration 9700 (2.26508 iter/s, 8.8297s/20 iters), loss = 2.28121
I0822 20:45:51.950697 31324 solver.cpp:273]     Train net output #0: loss = 2.28121 (* 1 = 2.28121 loss)
I0822 20:45:51.950712 31324 sgd_solver.cpp:790] Iteration 9700, lr = 0.01
I0822 20:46:01.730245 31324 solver.cpp:254] Iteration 9720 (2.0451 iter/s, 9.77948s/20 iters), loss = 2.60469
I0822 20:46:01.730310 31324 solver.cpp:273]     Train net output #0: loss = 2.60469 (* 1 = 2.60469 loss)
I0822 20:46:01.730329 31324 sgd_solver.cpp:790] Iteration 9720, lr = 0.01
I0822 20:46:11.129266 31324 solver.cpp:254] Iteration 9740 (2.12791 iter/s, 9.3989s/20 iters), loss = 2.65863
I0822 20:46:11.129312 31324 solver.cpp:273]     Train net output #0: loss = 2.65863 (* 1 = 2.65863 loss)
I0822 20:46:11.129321 31324 sgd_solver.cpp:790] Iteration 9740, lr = 0.01
I0822 20:46:21.501230 31324 solver.cpp:254] Iteration 9760 (1.9283 iter/s, 10.3718s/20 iters), loss = 2.57785
I0822 20:46:21.501305 31324 solver.cpp:273]     Train net output #0: loss = 2.57785 (* 1 = 2.57785 loss)
I0822 20:46:21.501318 31324 sgd_solver.cpp:790] Iteration 9760, lr = 0.01
I0822 20:46:32.321943 31324 solver.cpp:254] Iteration 9780 (1.84833 iter/s, 10.8206s/20 iters), loss = 2.67124
I0822 20:46:32.322098 31324 solver.cpp:273]     Train net output #0: loss = 2.67124 (* 1 = 2.67124 loss)
I0822 20:46:32.322113 31324 sgd_solver.cpp:790] Iteration 9780, lr = 0.01
I0822 20:46:43.002115 31324 solver.cpp:254] Iteration 9800 (1.87267 iter/s, 10.68s/20 iters), loss = 2.48089
I0822 20:46:43.002182 31324 solver.cpp:273]     Train net output #0: loss = 2.48089 (* 1 = 2.48089 loss)
I0822 20:46:43.002195 31324 sgd_solver.cpp:790] Iteration 9800, lr = 0.01
I0822 20:46:52.508970 31324 solver.cpp:254] Iteration 9820 (2.10377 iter/s, 9.50673s/20 iters), loss = 2.46096
I0822 20:46:52.509027 31324 solver.cpp:273]     Train net output #0: loss = 2.46096 (* 1 = 2.46096 loss)
I0822 20:46:52.509040 31324 sgd_solver.cpp:790] Iteration 9820, lr = 0.01
I0822 20:47:01.123973 31324 solver.cpp:254] Iteration 9840 (2.32156 iter/s, 8.61489s/20 iters), loss = 2.42323
I0822 20:47:01.124049 31324 solver.cpp:273]     Train net output #0: loss = 2.42323 (* 1 = 2.42323 loss)
I0822 20:47:01.124063 31324 sgd_solver.cpp:790] Iteration 9840, lr = 0.01
I0822 20:47:10.448921 31324 solver.cpp:254] Iteration 9860 (2.14482 iter/s, 9.3248s/20 iters), loss = 2.34728
I0822 20:47:10.449143 31324 solver.cpp:273]     Train net output #0: loss = 2.34728 (* 1 = 2.34728 loss)
I0822 20:47:10.449162 31324 sgd_solver.cpp:790] Iteration 9860, lr = 0.01
I0822 20:47:20.848460 31324 solver.cpp:254] Iteration 9880 (1.92321 iter/s, 10.3993s/20 iters), loss = 2.57279
I0822 20:47:20.848523 31324 solver.cpp:273]     Train net output #0: loss = 2.57279 (* 1 = 2.57279 loss)
I0822 20:47:20.848534 31324 sgd_solver.cpp:790] Iteration 9880, lr = 0.01
I0822 20:47:31.428874 31324 solver.cpp:254] Iteration 9900 (1.89031 iter/s, 10.5803s/20 iters), loss = 2.77558
I0822 20:47:31.428933 31324 solver.cpp:273]     Train net output #0: loss = 2.77558 (* 1 = 2.77558 loss)
I0822 20:47:31.428944 31324 sgd_solver.cpp:790] Iteration 9900, lr = 0.01
I0822 20:47:41.753999 31324 solver.cpp:254] Iteration 9920 (1.93705 iter/s, 10.325s/20 iters), loss = 2.78599
I0822 20:47:41.754130 31324 solver.cpp:273]     Train net output #0: loss = 2.78599 (* 1 = 2.78599 loss)
I0822 20:47:41.755553 31324 sgd_solver.cpp:790] Iteration 9920, lr = 0.01
I0822 20:47:51.474350 31324 solver.cpp:254] Iteration 9940 (2.05758 iter/s, 9.72016s/20 iters), loss = 2.43197
I0822 20:47:51.474408 31324 solver.cpp:273]     Train net output #0: loss = 2.43197 (* 1 = 2.43197 loss)
I0822 20:47:51.474421 31324 sgd_solver.cpp:790] Iteration 9940, lr = 0.01
I0822 20:48:00.142123 31324 solver.cpp:254] Iteration 9960 (2.30743 iter/s, 8.66765s/20 iters), loss = 2.73546
I0822 20:48:00.142192 31324 solver.cpp:273]     Train net output #0: loss = 2.73546 (* 1 = 2.73546 loss)
I0822 20:48:00.142206 31324 sgd_solver.cpp:790] Iteration 9960, lr = 0.01
I0822 20:48:09.389991 31324 solver.cpp:254] Iteration 9980 (2.16269 iter/s, 9.24774s/20 iters), loss = 2.48831
I0822 20:48:09.390051 31324 solver.cpp:273]     Train net output #0: loss = 2.48831 (* 1 = 2.48831 loss)
I0822 20:48:09.390063 31324 sgd_solver.cpp:790] Iteration 9980, lr = 0.01
I0822 20:48:19.269284 31324 solver.cpp:483] Snapshotting to binary proto file /data/kaiqi/24_prune_quantization01/caffe_alexnet_1st_retrain_iter_10000.caffemodel
I0822 20:48:20.323122 31324 sgd_solver.cpp:1201] Snapshotting solver state to binary proto file /data/kaiqi/24_prune_quantization01/caffe_alexnet_1st_retrain_iter_10000.solverstate
I0822 20:48:20.652557 31324 solver.cpp:366] Iteration 10000, Testing net (#0)
I0822 20:48:23.445463 31324 blocking_queue.cpp:49] Waiting for data
I0822 20:48:44.397260 31336 data_layer.cpp:73] Restarting data prefetching from start.
I0822 20:48:44.413265 31324 solver.cpp:433]     Test net output #0: accuracy = 0.45898
I0822 20:48:44.413319 31324 solver.cpp:433]     Test net output #1: accuracy5 = 0.715
I0822 20:48:44.413336 31324 solver.cpp:433]     Test net output #2: loss = 2.44974 (* 1 = 2.44974 loss)
I0822 20:48:44.581887 31324 solver.cpp:254] Iteration 10000 (0.568316 iter/s, 35.1917s/20 iters), loss = 2.76385
I0822 20:48:44.584280 31324 solver.cpp:273]     Train net output #0: loss = 2.76385 (* 1 = 2.76385 loss)
I0822 20:48:44.584307 31324 sgd_solver.cpp:790] Iteration 10000, lr = 0.01
I0822 20:48:47.620095 31332 data_layer.cpp:73] Restarting data prefetching from start.
I0822 20:48:52.684808 31324 solver.cpp:254] Iteration 10020 (2.46899 iter/s, 8.10049s/20 iters), loss = 2.3575
I0822 20:48:52.684952 31324 solver.cpp:273]     Train net output #0: loss = 2.3575 (* 1 = 2.3575 loss)
I0822 20:48:52.684963 31324 sgd_solver.cpp:790] Iteration 10020, lr = 0.01
I0822 20:49:03.491883 31324 solver.cpp:254] Iteration 10040 (1.85067 iter/s, 10.8069s/20 iters), loss = 2.55578
I0822 20:49:03.491947 31324 solver.cpp:273]     Train net output #0: loss = 2.55578 (* 1 = 2.55578 loss)
I0822 20:49:03.491961 31324 sgd_solver.cpp:790] Iteration 10040, lr = 0.01
I0822 20:49:14.056345 31324 solver.cpp:254] Iteration 10060 (1.89316 iter/s, 10.5643s/20 iters), loss = 2.63127
I0822 20:49:14.056445 31324 solver.cpp:273]     Train net output #0: loss = 2.63127 (* 1 = 2.63127 loss)
I0822 20:49:14.056468 31324 sgd_solver.cpp:790] Iteration 10060, lr = 0.01
I0822 20:49:24.547411 31324 solver.cpp:254] Iteration 10080 (1.90641 iter/s, 10.4909s/20 iters), loss = 2.6132
I0822 20:49:24.547592 31324 solver.cpp:273]     Train net output #0: loss = 2.6132 (* 1 = 2.6132 loss)
I0822 20:49:24.547605 31324 sgd_solver.cpp:790] Iteration 10080, lr = 0.01
I0822 20:49:34.919682 31324 solver.cpp:254] Iteration 10100 (1.92826 iter/s, 10.372s/20 iters), loss = 2.4001
I0822 20:49:34.919746 31324 solver.cpp:273]     Train net output #0: loss = 2.4001 (* 1 = 2.4001 loss)
I0822 20:49:34.919757 31324 sgd_solver.cpp:790] Iteration 10100, lr = 0.01
I0822 20:49:44.854795 31324 blocking_queue.cpp:49] Waiting for data
I0822 20:49:45.486161 31324 solver.cpp:254] Iteration 10120 (1.8928 iter/s, 10.5663s/20 iters), loss = 2.75644
I0822 20:49:45.486222 31324 solver.cpp:273]     Train net output #0: loss = 2.75644 (* 1 = 2.75644 loss)
I0822 20:49:45.486234 31324 sgd_solver.cpp:790] Iteration 10120, lr = 0.01
I0822 20:49:55.917903 31324 solver.cpp:254] Iteration 10140 (1.91725 iter/s, 10.4316s/20 iters), loss = 2.74947
I0822 20:49:55.918040 31324 solver.cpp:273]     Train net output #0: loss = 2.74947 (* 1 = 2.74947 loss)
I0822 20:49:55.918051 31324 sgd_solver.cpp:790] Iteration 10140, lr = 0.01
I0822 20:50:06.599478 31324 solver.cpp:254] Iteration 10160 (1.87242 iter/s, 10.6814s/20 iters), loss = 2.71297
I0822 20:50:06.599545 31324 solver.cpp:273]     Train net output #0: loss = 2.71297 (* 1 = 2.71297 loss)
I0822 20:50:06.599558 31324 sgd_solver.cpp:790] Iteration 10160, lr = 0.01
I0822 20:50:17.202392 31324 solver.cpp:254] Iteration 10180 (1.8863 iter/s, 10.6028s/20 iters), loss = 2.33796
I0822 20:50:17.202462 31324 solver.cpp:273]     Train net output #0: loss = 2.33796 (* 1 = 2.33796 loss)
I0822 20:50:17.202476 31324 sgd_solver.cpp:790] Iteration 10180, lr = 0.01
I0822 20:50:27.846218 31324 solver.cpp:254] Iteration 10200 (1.87905 iter/s, 10.6437s/20 iters), loss = 2.56247
I0822 20:50:27.846375 31324 solver.cpp:273]     Train net output #0: loss = 2.56247 (* 1 = 2.56247 loss)
I0822 20:50:27.846390 31324 sgd_solver.cpp:790] Iteration 10200, lr = 0.01
I0822 20:50:38.246899 31324 solver.cpp:254] Iteration 10220 (1.92299 iter/s, 10.4004s/20 iters), loss = 2.50738
I0822 20:50:38.246994 31324 solver.cpp:273]     Train net output #0: loss = 2.50738 (* 1 = 2.50738 loss)
I0822 20:50:38.247011 31324 sgd_solver.cpp:790] Iteration 10220, lr = 0.01
I0822 20:50:48.697216 31324 solver.cpp:254] Iteration 10240 (1.91385 iter/s, 10.4501s/20 iters), loss = 2.20744
I0822 20:50:48.697280 31324 solver.cpp:273]     Train net output #0: loss = 2.20744 (* 1 = 2.20744 loss)
I0822 20:50:48.697291 31324 sgd_solver.cpp:790] Iteration 10240, lr = 0.01
I0822 20:50:59.116171 31324 solver.cpp:254] Iteration 10260 (1.9196 iter/s, 10.4188s/20 iters), loss = 2.50527
I0822 20:50:59.116327 31324 solver.cpp:273]     Train net output #0: loss = 2.50527 (* 1 = 2.50527 loss)
I0822 20:50:59.116338 31324 sgd_solver.cpp:790] Iteration 10260, lr = 0.01
I0822 20:51:09.652953 31324 solver.cpp:254] Iteration 10280 (1.89816 iter/s, 10.5365s/20 iters), loss = 2.51187
I0822 20:51:09.653034 31324 solver.cpp:273]     Train net output #0: loss = 2.51187 (* 1 = 2.51187 loss)
I0822 20:51:09.653050 31324 sgd_solver.cpp:790] Iteration 10280, lr = 0.01
I0822 20:51:20.268906 31324 solver.cpp:254] Iteration 10300 (1.88398 iter/s, 10.6158s/20 iters), loss = 2.58997
I0822 20:51:20.268976 31324 solver.cpp:273]     Train net output #0: loss = 2.58997 (* 1 = 2.58997 loss)
I0822 20:51:20.268990 31324 sgd_solver.cpp:790] Iteration 10300, lr = 0.01
I0822 20:51:30.814646 31324 solver.cpp:254] Iteration 10320 (1.89653 iter/s, 10.5456s/20 iters), loss = 2.41206
I0822 20:51:30.814781 31324 solver.cpp:273]     Train net output #0: loss = 2.41206 (* 1 = 2.41206 loss)
I0822 20:51:30.814793 31324 sgd_solver.cpp:790] Iteration 10320, lr = 0.01
I0822 20:51:40.866989 31324 solver.cpp:254] Iteration 10340 (1.98963 iter/s, 10.0521s/20 iters), loss = 2.63716
I0822 20:51:40.867048 31324 solver.cpp:273]     Train net output #0: loss = 2.63716 (* 1 = 2.63716 loss)
I0822 20:51:40.867058 31324 sgd_solver.cpp:790] Iteration 10340, lr = 0.01
I0822 20:51:49.941314 31324 solver.cpp:254] Iteration 10360 (2.20405 iter/s, 9.07421s/20 iters), loss = 2.68315
I0822 20:51:49.941370 31324 solver.cpp:273]     Train net output #0: loss = 2.68315 (* 1 = 2.68315 loss)
I0822 20:51:49.941380 31324 sgd_solver.cpp:790] Iteration 10360, lr = 0.01
I0822 20:51:58.962729 31324 solver.cpp:254] Iteration 10380 (2.21698 iter/s, 9.0213s/20 iters), loss = 2.69251
I0822 20:51:58.962796 31324 solver.cpp:273]     Train net output #0: loss = 2.69251 (* 1 = 2.69251 loss)
I0822 20:51:58.962810 31324 sgd_solver.cpp:790] Iteration 10380, lr = 0.01
I0822 20:52:08.735252 31324 solver.cpp:254] Iteration 10400 (2.04658 iter/s, 9.77238s/20 iters), loss = 2.86919
I0822 20:52:08.735460 31324 solver.cpp:273]     Train net output #0: loss = 2.86919 (* 1 = 2.86919 loss)
I0822 20:52:08.735477 31324 sgd_solver.cpp:790] Iteration 10400, lr = 0.01
I0822 20:52:19.555620 31324 solver.cpp:254] Iteration 10420 (1.84841 iter/s, 10.8201s/20 iters), loss = 2.58923
I0822 20:52:19.555692 31324 solver.cpp:273]     Train net output #0: loss = 2.58923 (* 1 = 2.58923 loss)
I0822 20:52:19.555718 31324 sgd_solver.cpp:790] Iteration 10420, lr = 0.01
I0822 20:52:30.113445 31324 solver.cpp:254] Iteration 10440 (1.89435 iter/s, 10.5577s/20 iters), loss = 2.84547
I0822 20:52:30.113505 31324 solver.cpp:273]     Train net output #0: loss = 2.84547 (* 1 = 2.84547 loss)
I0822 20:52:30.113515 31324 sgd_solver.cpp:790] Iteration 10440, lr = 0.01
I0822 20:52:40.658890 31324 solver.cpp:254] Iteration 10460 (1.89658 iter/s, 10.5453s/20 iters), loss = 2.83706
I0822 20:52:40.659034 31324 solver.cpp:273]     Train net output #0: loss = 2.83706 (* 1 = 2.83706 loss)
I0822 20:52:40.659046 31324 sgd_solver.cpp:790] Iteration 10460, lr = 0.01
I0822 20:52:51.394809 31324 solver.cpp:254] Iteration 10480 (1.86294 iter/s, 10.7357s/20 iters), loss = 2.57566
I0822 20:52:51.394883 31324 solver.cpp:273]     Train net output #0: loss = 2.57566 (* 1 = 2.57566 loss)
I0822 20:52:51.394898 31324 sgd_solver.cpp:790] Iteration 10480, lr = 0.01
I0822 20:53:02.086454 31324 solver.cpp:254] Iteration 10500 (1.87064 iter/s, 10.6915s/20 iters), loss = 2.277
I0822 20:53:02.086516 31324 solver.cpp:273]     Train net output #0: loss = 2.277 (* 1 = 2.277 loss)
I0822 20:53:02.086527 31324 sgd_solver.cpp:790] Iteration 10500, lr = 0.01
I0822 20:53:12.515064 31324 solver.cpp:254] Iteration 10520 (1.91782 iter/s, 10.4285s/20 iters), loss = 2.267
I0822 20:53:12.515226 31324 solver.cpp:273]     Train net output #0: loss = 2.267 (* 1 = 2.267 loss)
I0822 20:53:12.515240 31324 sgd_solver.cpp:790] Iteration 10520, lr = 0.01
I0822 20:53:23.034173 31324 solver.cpp:254] Iteration 10540 (1.90134 iter/s, 10.5189s/20 iters), loss = 2.63165
I0822 20:53:23.034251 31324 solver.cpp:273]     Train net output #0: loss = 2.63165 (* 1 = 2.63165 loss)
I0822 20:53:23.034267 31324 sgd_solver.cpp:790] Iteration 10540, lr = 0.01
I0822 20:53:33.367348 31324 solver.cpp:254] Iteration 10560 (1.93554 iter/s, 10.333s/20 iters), loss = 2.40186
I0822 20:53:33.367432 31324 solver.cpp:273]     Train net output #0: loss = 2.40186 (* 1 = 2.40186 loss)
I0822 20:53:33.367446 31324 sgd_solver.cpp:790] Iteration 10560, lr = 0.01
I0822 20:53:43.168339 31324 solver.cpp:254] Iteration 10580 (2.04064 iter/s, 9.80085s/20 iters), loss = 2.76541
I0822 20:53:43.168442 31324 solver.cpp:273]     Train net output #0: loss = 2.76541 (* 1 = 2.76541 loss)
I0822 20:53:43.168454 31324 sgd_solver.cpp:790] Iteration 10580, lr = 0.01
I0822 20:53:50.760388 31324 solver.cpp:254] Iteration 10600 (2.63439 iter/s, 7.59189s/20 iters), loss = 2.41267
I0822 20:53:50.772513 31324 solver.cpp:273]     Train net output #0: loss = 2.41267 (* 1 = 2.41267 loss)
I0822 20:53:50.772553 31324 sgd_solver.cpp:790] Iteration 10600, lr = 0.01
I0822 20:53:54.406865 31324 solver.cpp:254] Iteration 10620 (5.50306 iter/s, 3.63434s/20 iters), loss = 2.72101
I0822 20:53:54.418972 31324 solver.cpp:273]     Train net output #0: loss = 2.72101 (* 1 = 2.72101 loss)
I0822 20:53:54.419018 31324 sgd_solver.cpp:790] Iteration 10620, lr = 0.01
I0822 20:53:58.018615 31324 solver.cpp:254] Iteration 10640 (5.55612 iter/s, 3.59963s/20 iters), loss = 2.5737
I0822 20:53:58.031365 31324 solver.cpp:273]     Train net output #0: loss = 2.5737 (* 1 = 2.5737 loss)
I0822 20:53:58.031404 31324 sgd_solver.cpp:790] Iteration 10640, lr = 0.01
I0822 20:54:01.976686 31324 solver.cpp:254] Iteration 10660 (5.06931 iter/s, 3.94531s/20 iters), loss = 2.52671
I0822 20:54:01.988831 31324 solver.cpp:273]     Train net output #0: loss = 2.52671 (* 1 = 2.52671 loss)
I0822 20:54:01.988858 31324 sgd_solver.cpp:790] Iteration 10660, lr = 0.01
I0822 20:54:05.677800 31324 solver.cpp:254] Iteration 10680 (5.4216 iter/s, 3.68895s/20 iters), loss = 2.93066
I0822 20:54:05.689937 31324 solver.cpp:273]     Train net output #0: loss = 2.93066 (* 1 = 2.93066 loss)
I0822 20:54:05.689998 31324 sgd_solver.cpp:790] Iteration 10680, lr = 0.01
I0822 20:54:09.341259 31324 solver.cpp:254] Iteration 10700 (5.47746 iter/s, 3.65133s/20 iters), loss = 2.58944
I0822 20:54:09.353416 31324 solver.cpp:273]     Train net output #0: loss = 2.58944 (* 1 = 2.58944 loss)
I0822 20:54:09.353447 31324 sgd_solver.cpp:790] Iteration 10700, lr = 0.01
I0822 20:54:16.347506 31324 solver.cpp:254] Iteration 10720 (2.85957 iter/s, 6.99407s/20 iters), loss = 2.42738
I0822 20:54:16.359663 31324 solver.cpp:273]     Train net output #0: loss = 2.42738 (* 1 = 2.42738 loss)
I0822 20:54:16.359699 31324 sgd_solver.cpp:790] Iteration 10720, lr = 0.01
I0822 20:54:19.999732 31324 solver.cpp:254] Iteration 10740 (5.49441 iter/s, 3.64007s/20 iters), loss = 2.65498
I0822 20:54:20.011875 31324 solver.cpp:273]     Train net output #0: loss = 2.65498 (* 1 = 2.65498 loss)
I0822 20:54:20.011906 31324 sgd_solver.cpp:790] Iteration 10740, lr = 0.01
I0822 20:54:23.653164 31324 solver.cpp:254] Iteration 10760 (5.49258 iter/s, 3.64128s/20 iters), loss = 2.7311
I0822 20:54:23.665288 31324 solver.cpp:273]     Train net output #0: loss = 2.7311 (* 1 = 2.7311 loss)
I0822 20:54:23.665319 31324 sgd_solver.cpp:790] Iteration 10760, lr = 0.01
I0822 20:54:27.311892 31324 solver.cpp:254] Iteration 10780 (5.48457 iter/s, 3.64659s/20 iters), loss = 2.66328
I0822 20:54:27.323974 31324 solver.cpp:273]     Train net output #0: loss = 2.66328 (* 1 = 2.66328 loss)
I0822 20:54:27.324013 31324 sgd_solver.cpp:790] Iteration 10780, lr = 0.01
I0822 20:54:34.877646 31324 solver.cpp:254] Iteration 10800 (2.64773 iter/s, 7.55364s/20 iters), loss = 2.35536
I0822 20:54:34.877724 31324 solver.cpp:273]     Train net output #0: loss = 2.35536 (* 1 = 2.35536 loss)
I0822 20:54:34.877739 31324 sgd_solver.cpp:790] Iteration 10800, lr = 0.01
I0822 20:54:44.919457 31324 solver.cpp:254] Iteration 10820 (1.9917 iter/s, 10.0417s/20 iters), loss = 2.67135
I0822 20:54:44.919548 31324 solver.cpp:273]     Train net output #0: loss = 2.67135 (* 1 = 2.67135 loss)
I0822 20:54:44.919565 31324 sgd_solver.cpp:790] Iteration 10820, lr = 0.01
I0822 20:54:55.297122 31324 solver.cpp:254] Iteration 10840 (1.92724 iter/s, 10.3775s/20 iters), loss = 2.51844
I0822 20:54:55.297276 31324 solver.cpp:273]     Train net output #0: loss = 2.51844 (* 1 = 2.51844 loss)
I0822 20:54:55.297287 31324 sgd_solver.cpp:790] Iteration 10840, lr = 0.01
I0822 20:55:05.987850 31324 solver.cpp:254] Iteration 10860 (1.87082 iter/s, 10.6905s/20 iters), loss = 2.44877
I0822 20:55:05.987905 31324 solver.cpp:273]     Train net output #0: loss = 2.44877 (* 1 = 2.44877 loss)
I0822 20:55:05.987917 31324 sgd_solver.cpp:790] Iteration 10860, lr = 0.01
I0822 20:55:16.342818 31324 solver.cpp:254] Iteration 10880 (1.93146 iter/s, 10.3548s/20 iters), loss = 2.62379
I0822 20:55:16.342876 31324 solver.cpp:273]     Train net output #0: loss = 2.62379 (* 1 = 2.62379 loss)
I0822 20:55:16.342888 31324 sgd_solver.cpp:790] Iteration 10880, lr = 0.01
I0822 20:55:26.832690 31324 solver.cpp:254] Iteration 10900 (1.90663 iter/s, 10.4897s/20 iters), loss = 2.63722
I0822 20:55:26.832851 31324 solver.cpp:273]     Train net output #0: loss = 2.63722 (* 1 = 2.63722 loss)
I0822 20:55:26.832864 31324 sgd_solver.cpp:790] Iteration 10900, lr = 0.01
I0822 20:55:36.874147 31324 solver.cpp:254] Iteration 10920 (1.99179 iter/s, 10.0412s/20 iters), loss = 2.59463
I0822 20:55:36.874209 31324 solver.cpp:273]     Train net output #0: loss = 2.59463 (* 1 = 2.59463 loss)
I0822 20:55:36.874218 31324 sgd_solver.cpp:790] Iteration 10920, lr = 0.01
I0822 20:55:45.974766 31324 solver.cpp:254] Iteration 10940 (2.19768 iter/s, 9.10049s/20 iters), loss = 2.45582
I0822 20:55:45.974819 31324 solver.cpp:273]     Train net output #0: loss = 2.45582 (* 1 = 2.45582 loss)
I0822 20:55:45.974829 31324 sgd_solver.cpp:790] Iteration 10940, lr = 0.01
I0822 20:55:55.150321 31324 solver.cpp:254] Iteration 10960 (2.17973 iter/s, 9.17543s/20 iters), loss = 2.64938
I0822 20:55:55.150385 31324 solver.cpp:273]     Train net output #0: loss = 2.64938 (* 1 = 2.64938 loss)
I0822 20:55:55.150398 31324 sgd_solver.cpp:790] Iteration 10960, lr = 0.01
I0822 20:56:05.417403 31324 solver.cpp:254] Iteration 10980 (1.948 iter/s, 10.2669s/20 iters), loss = 2.4358
I0822 20:56:05.417569 31324 solver.cpp:273]     Train net output #0: loss = 2.4358 (* 1 = 2.4358 loss)
I0822 20:56:05.417587 31324 sgd_solver.cpp:790] Iteration 10980, lr = 0.01
I0822 20:56:15.376263 31324 solver.cpp:366] Iteration 11000, Testing net (#0)
I0822 20:56:18.693410 31324 blocking_queue.cpp:49] Waiting for data
I0822 20:56:39.350709 31336 data_layer.cpp:73] Restarting data prefetching from start.
I0822 20:56:39.366644 31324 solver.cpp:433]     Test net output #0: accuracy = 0.46736
I0822 20:56:39.366693 31324 solver.cpp:433]     Test net output #1: accuracy5 = 0.73002
I0822 20:56:39.366706 31324 solver.cpp:433]     Test net output #2: loss = 2.35163 (* 1 = 2.35163 loss)
I0822 20:56:39.535802 31324 solver.cpp:254] Iteration 11000 (0.5862 iter/s, 34.118s/20 iters), loss = 2.3203
I0822 20:56:39.538200 31324 solver.cpp:273]     Train net output #0: loss = 2.3203 (* 1 = 2.3203 loss)
I0822 20:56:39.538225 31324 sgd_solver.cpp:790] Iteration 11000, lr = 0.01
I0822 20:56:47.802345 31324 solver.cpp:254] Iteration 11020 (2.42011 iter/s, 8.26409s/20 iters), loss = 2.56693
I0822 20:56:47.802414 31324 solver.cpp:273]     Train net output #0: loss = 2.56693 (* 1 = 2.56693 loss)
I0822 20:56:47.802439 31324 sgd_solver.cpp:790] Iteration 11020, lr = 0.01
I0822 20:56:57.862951 31324 solver.cpp:254] Iteration 11040 (1.98798 iter/s, 10.0605s/20 iters), loss = 2.64485
I0822 20:56:57.863010 31324 solver.cpp:273]     Train net output #0: loss = 2.64485 (* 1 = 2.64485 loss)
I0822 20:56:57.863021 31324 sgd_solver.cpp:790] Iteration 11040, lr = 0.01
I0822 20:57:08.553485 31324 solver.cpp:254] Iteration 11060 (1.87084 iter/s, 10.6904s/20 iters), loss = 2.46865
I0822 20:57:08.553547 31324 solver.cpp:273]     Train net output #0: loss = 2.46865 (* 1 = 2.46865 loss)
I0822 20:57:08.553560 31324 sgd_solver.cpp:790] Iteration 11060, lr = 0.01
I0822 20:57:19.089702 31324 solver.cpp:254] Iteration 11080 (1.89824 iter/s, 10.5361s/20 iters), loss = 2.38225
I0822 20:57:19.089920 31324 solver.cpp:273]     Train net output #0: loss = 2.38225 (* 1 = 2.38225 loss)
I0822 20:57:19.089932 31324 sgd_solver.cpp:790] Iteration 11080, lr = 0.01
I0822 20:57:29.523624 31324 solver.cpp:254] Iteration 11100 (1.91688 iter/s, 10.4336s/20 iters), loss = 2.47512
I0822 20:57:29.523694 31324 solver.cpp:273]     Train net output #0: loss = 2.47512 (* 1 = 2.47512 loss)
I0822 20:57:29.523707 31324 sgd_solver.cpp:790] Iteration 11100, lr = 0.01
I0822 20:57:39.977341 31324 solver.cpp:254] Iteration 11120 (1.91322 iter/s, 10.4536s/20 iters), loss = 2.60682
I0822 20:57:39.977408 31324 solver.cpp:273]     Train net output #0: loss = 2.60682 (* 1 = 2.60682 loss)
I0822 20:57:39.977421 31324 sgd_solver.cpp:790] Iteration 11120, lr = 0.01
I0822 20:57:48.135198 31324 blocking_queue.cpp:49] Waiting for data
I0822 20:57:50.277914 31324 solver.cpp:254] Iteration 11140 (1.94167 iter/s, 10.3004s/20 iters), loss = 2.66685
I0822 20:57:50.278084 31324 solver.cpp:273]     Train net output #0: loss = 2.66685 (* 1 = 2.66685 loss)
I0822 20:57:50.278096 31324 sgd_solver.cpp:790] Iteration 11140, lr = 0.01
I0822 20:58:00.688625 31324 solver.cpp:254] Iteration 11160 (1.92114 iter/s, 10.4105s/20 iters), loss = 2.7093
I0822 20:58:00.688686 31324 solver.cpp:273]     Train net output #0: loss = 2.7093 (* 1 = 2.7093 loss)
I0822 20:58:00.688696 31324 sgd_solver.cpp:790] Iteration 11160, lr = 0.01
I0822 20:58:11.036741 31324 solver.cpp:254] Iteration 11180 (1.93274 iter/s, 10.348s/20 iters), loss = 2.84745
I0822 20:58:11.036816 31324 solver.cpp:273]     Train net output #0: loss = 2.84745 (* 1 = 2.84745 loss)
I0822 20:58:11.036829 31324 sgd_solver.cpp:790] Iteration 11180, lr = 0.01
I0822 20:58:21.447649 31324 solver.cpp:254] Iteration 11200 (1.92109 iter/s, 10.4108s/20 iters), loss = 2.39238
I0822 20:58:21.448421 31324 solver.cpp:273]     Train net output #0: loss = 2.39238 (* 1 = 2.39238 loss)
I0822 20:58:21.448436 31324 sgd_solver.cpp:790] Iteration 11200, lr = 0.01
I0822 20:58:31.712473 31324 solver.cpp:254] Iteration 11220 (1.94856 iter/s, 10.264s/20 iters), loss = 2.65201
I0822 20:58:31.712568 31324 solver.cpp:273]     Train net output #0: loss = 2.65201 (* 1 = 2.65201 loss)
I0822 20:58:31.712585 31324 sgd_solver.cpp:790] Iteration 11220, lr = 0.01
I0822 20:58:41.973839 31324 solver.cpp:254] Iteration 11240 (1.94909 iter/s, 10.2612s/20 iters), loss = 2.53934
I0822 20:58:41.973901 31324 solver.cpp:273]     Train net output #0: loss = 2.53934 (* 1 = 2.53934 loss)
I0822 20:58:41.973912 31324 sgd_solver.cpp:790] Iteration 11240, lr = 0.01
I0822 20:58:52.579984 31324 solver.cpp:254] Iteration 11260 (1.88572 iter/s, 10.606s/20 iters), loss = 2.48718
I0822 20:58:52.580097 31324 solver.cpp:273]     Train net output #0: loss = 2.48718 (* 1 = 2.48718 loss)
I0822 20:58:52.580109 31324 sgd_solver.cpp:790] Iteration 11260, lr = 0.01
I0822 20:59:02.727087 31324 solver.cpp:254] Iteration 11280 (1.97104 iter/s, 10.1469s/20 iters), loss = 2.78401
I0822 20:59:02.727161 31324 solver.cpp:273]     Train net output #0: loss = 2.78401 (* 1 = 2.78401 loss)
I0822 20:59:02.727175 31324 sgd_solver.cpp:790] Iteration 11280, lr = 0.01
I0822 20:59:13.047083 31324 solver.cpp:254] Iteration 11300 (1.93801 iter/s, 10.3199s/20 iters), loss = 2.53634
I0822 20:59:13.047157 31324 solver.cpp:273]     Train net output #0: loss = 2.53634 (* 1 = 2.53634 loss)
I0822 20:59:13.047175 31324 sgd_solver.cpp:790] Iteration 11300, lr = 0.01
I0822 20:59:23.414752 31324 solver.cpp:254] Iteration 11320 (1.9291 iter/s, 10.3675s/20 iters), loss = 2.66963
I0822 20:59:23.414898 31324 solver.cpp:273]     Train net output #0: loss = 2.66963 (* 1 = 2.66963 loss)
I0822 20:59:23.414909 31324 sgd_solver.cpp:790] Iteration 11320, lr = 0.01
I0822 20:59:33.904937 31324 solver.cpp:254] Iteration 11340 (1.90659 iter/s, 10.49s/20 iters), loss = 2.5639
I0822 20:59:33.905010 31324 solver.cpp:273]     Train net output #0: loss = 2.5639 (* 1 = 2.5639 loss)
I0822 20:59:33.905025 31324 sgd_solver.cpp:790] Iteration 11340, lr = 0.01
I0822 20:59:44.297302 31324 solver.cpp:254] Iteration 11360 (1.92452 iter/s, 10.3922s/20 iters), loss = 2.7242
I0822 20:59:44.297371 31324 solver.cpp:273]     Train net output #0: loss = 2.7242 (* 1 = 2.7242 loss)
I0822 20:59:44.297386 31324 sgd_solver.cpp:790] Iteration 11360, lr = 0.01
I0822 20:59:54.887261 31324 solver.cpp:254] Iteration 11380 (1.88861 iter/s, 10.5898s/20 iters), loss = 2.65182
I0822 20:59:54.887415 31324 solver.cpp:273]     Train net output #0: loss = 2.65182 (* 1 = 2.65182 loss)
I0822 20:59:54.887431 31324 sgd_solver.cpp:790] Iteration 11380, lr = 0.01
I0822 21:00:05.382294 31324 solver.cpp:254] Iteration 11400 (1.9057 iter/s, 10.4948s/20 iters), loss = 2.4902
I0822 21:00:05.382357 31324 solver.cpp:273]     Train net output #0: loss = 2.4902 (* 1 = 2.4902 loss)
I0822 21:00:05.382370 31324 sgd_solver.cpp:790] Iteration 11400, lr = 0.01
I0822 21:00:15.634099 31324 solver.cpp:254] Iteration 11420 (1.9509 iter/s, 10.2517s/20 iters), loss = 2.66118
I0822 21:00:15.634174 31324 solver.cpp:273]     Train net output #0: loss = 2.66118 (* 1 = 2.66118 loss)
I0822 21:00:15.634188 31324 sgd_solver.cpp:790] Iteration 11420, lr = 0.01
I0822 21:00:26.140008 31324 solver.cpp:254] Iteration 11440 (1.90372 iter/s, 10.5058s/20 iters), loss = 2.44379
I0822 21:00:26.140178 31324 solver.cpp:273]     Train net output #0: loss = 2.44379 (* 1 = 2.44379 loss)
I0822 21:00:26.140193 31324 sgd_solver.cpp:790] Iteration 11440, lr = 0.01
I0822 21:00:36.662477 31324 solver.cpp:254] Iteration 11460 (1.90074 iter/s, 10.5222s/20 iters), loss = 2.69524
I0822 21:00:36.662537 31324 solver.cpp:273]     Train net output #0: loss = 2.69524 (* 1 = 2.69524 loss)
I0822 21:00:36.662547 31324 sgd_solver.cpp:790] Iteration 11460, lr = 0.01
I0822 21:00:47.120767 31324 solver.cpp:254] Iteration 11480 (1.91238 iter/s, 10.4582s/20 iters), loss = 2.67405
I0822 21:00:47.120833 31324 solver.cpp:273]     Train net output #0: loss = 2.67405 (* 1 = 2.67405 loss)
I0822 21:00:47.120846 31324 sgd_solver.cpp:790] Iteration 11480, lr = 0.01
I0822 21:00:57.642534 31324 solver.cpp:254] Iteration 11500 (1.90085 iter/s, 10.5216s/20 iters), loss = 2.14003
I0822 21:00:57.642704 31324 solver.cpp:273]     Train net output #0: loss = 2.14003 (* 1 = 2.14003 loss)
I0822 21:00:57.642721 31324 sgd_solver.cpp:790] Iteration 11500, lr = 0.01
I0822 21:01:06.773138 31324 solver.cpp:254] Iteration 11520 (2.19049 iter/s, 9.13037s/20 iters), loss = 2.77969
I0822 21:01:06.773212 31324 solver.cpp:273]     Train net output #0: loss = 2.77969 (* 1 = 2.77969 loss)
I0822 21:01:06.773228 31324 sgd_solver.cpp:790] Iteration 11520, lr = 0.01
I0822 21:01:15.895934 31324 solver.cpp:254] Iteration 11540 (2.19234 iter/s, 9.12267s/20 iters), loss = 2.60555
I0822 21:01:15.896001 31324 solver.cpp:273]     Train net output #0: loss = 2.60555 (* 1 = 2.60555 loss)
I0822 21:01:15.896013 31324 sgd_solver.cpp:790] Iteration 11540, lr = 0.01
I0822 21:01:25.442839 31324 solver.cpp:254] Iteration 11560 (2.09495 iter/s, 9.54678s/20 iters), loss = 2.64567
I0822 21:01:25.442893 31324 solver.cpp:273]     Train net output #0: loss = 2.64567 (* 1 = 2.64567 loss)
I0822 21:01:25.442904 31324 sgd_solver.cpp:790] Iteration 11560, lr = 0.01
I0822 21:01:34.546218 31324 solver.cpp:254] Iteration 11580 (2.19701 iter/s, 9.10326s/20 iters), loss = 2.57934
I0822 21:01:34.546381 31324 solver.cpp:273]     Train net output #0: loss = 2.57934 (* 1 = 2.57934 loss)
I0822 21:01:34.546406 31324 sgd_solver.cpp:790] Iteration 11580, lr = 0.01
I0822 21:01:44.664578 31324 solver.cpp:254] Iteration 11600 (1.97665 iter/s, 10.1181s/20 iters), loss = 2.50925
I0822 21:01:44.664640 31324 solver.cpp:273]     Train net output #0: loss = 2.50925 (* 1 = 2.50925 loss)
I0822 21:01:44.664651 31324 sgd_solver.cpp:790] Iteration 11600, lr = 0.01
I0822 21:01:55.015861 31324 solver.cpp:254] Iteration 11620 (1.93215 iter/s, 10.3512s/20 iters), loss = 2.23805
I0822 21:01:55.015919 31324 solver.cpp:273]     Train net output #0: loss = 2.23805 (* 1 = 2.23805 loss)
I0822 21:01:55.015931 31324 sgd_solver.cpp:790] Iteration 11620, lr = 0.01
I0822 21:02:05.579190 31324 solver.cpp:254] Iteration 11640 (1.89336 iter/s, 10.5632s/20 iters), loss = 2.66733
I0822 21:02:05.579342 31324 solver.cpp:273]     Train net output #0: loss = 2.66733 (* 1 = 2.66733 loss)
I0822 21:02:05.579355 31324 sgd_solver.cpp:790] Iteration 11640, lr = 0.01
I0822 21:02:16.050321 31324 solver.cpp:254] Iteration 11660 (1.91005 iter/s, 10.4709s/20 iters), loss = 2.51262
I0822 21:02:16.050387 31324 solver.cpp:273]     Train net output #0: loss = 2.51262 (* 1 = 2.51262 loss)
I0822 21:02:16.050398 31324 sgd_solver.cpp:790] Iteration 11660, lr = 0.01
I0822 21:02:25.044102 31324 solver.cpp:254] Iteration 11680 (2.22379 iter/s, 8.99366s/20 iters), loss = 2.94389
I0822 21:02:25.044158 31324 solver.cpp:273]     Train net output #0: loss = 2.94389 (* 1 = 2.94389 loss)
I0822 21:02:25.044174 31324 sgd_solver.cpp:790] Iteration 11680, lr = 0.01
I0822 21:02:33.863479 31324 solver.cpp:254] Iteration 11700 (2.26776 iter/s, 8.81927s/20 iters), loss = 2.36125
I0822 21:02:33.863533 31324 solver.cpp:273]     Train net output #0: loss = 2.36125 (* 1 = 2.36125 loss)
I0822 21:02:33.863543 31324 sgd_solver.cpp:790] Iteration 11700, lr = 0.01
I0822 21:02:43.254369 31324 solver.cpp:254] Iteration 11720 (2.12975 iter/s, 9.39077s/20 iters), loss = 2.38075
I0822 21:02:43.254559 31324 solver.cpp:273]     Train net output #0: loss = 2.38075 (* 1 = 2.38075 loss)
I0822 21:02:43.254575 31324 sgd_solver.cpp:790] Iteration 11720, lr = 0.01
I0822 21:02:53.299945 31324 solver.cpp:254] Iteration 11740 (1.99098 iter/s, 10.0453s/20 iters), loss = 2.40869
I0822 21:02:53.300011 31324 solver.cpp:273]     Train net output #0: loss = 2.40869 (* 1 = 2.40869 loss)
I0822 21:02:53.300024 31324 sgd_solver.cpp:790] Iteration 11740, lr = 0.01
I0822 21:03:03.786240 31324 solver.cpp:254] Iteration 11760 (1.90728 iter/s, 10.4862s/20 iters), loss = 2.6348
I0822 21:03:03.786303 31324 solver.cpp:273]     Train net output #0: loss = 2.6348 (* 1 = 2.6348 loss)
I0822 21:03:03.786315 31324 sgd_solver.cpp:790] Iteration 11760, lr = 0.01
I0822 21:03:14.098186 31324 solver.cpp:254] Iteration 11780 (1.93952 iter/s, 10.3118s/20 iters), loss = 2.60648
I0822 21:03:14.098340 31324 solver.cpp:273]     Train net output #0: loss = 2.60648 (* 1 = 2.60648 loss)
I0822 21:03:14.098353 31324 sgd_solver.cpp:790] Iteration 11780, lr = 0.01
I0822 21:03:24.642323 31324 solver.cpp:254] Iteration 11800 (1.89683 iter/s, 10.5439s/20 iters), loss = 2.51346
I0822 21:03:24.642380 31324 solver.cpp:273]     Train net output #0: loss = 2.51346 (* 1 = 2.51346 loss)
I0822 21:03:24.642390 31324 sgd_solver.cpp:790] Iteration 11800, lr = 0.01
I0822 21:03:33.905973 31324 solver.cpp:254] Iteration 11820 (2.159 iter/s, 9.26354s/20 iters), loss = 2.68165
I0822 21:03:33.906031 31324 solver.cpp:273]     Train net output #0: loss = 2.68165 (* 1 = 2.68165 loss)
I0822 21:03:33.906041 31324 sgd_solver.cpp:790] Iteration 11820, lr = 0.01
I0822 21:03:42.706718 31324 solver.cpp:254] Iteration 11840 (2.27257 iter/s, 8.80063s/20 iters), loss = 2.69375
I0822 21:03:42.706784 31324 solver.cpp:273]     Train net output #0: loss = 2.69375 (* 1 = 2.69375 loss)
I0822 21:03:42.706797 31324 sgd_solver.cpp:790] Iteration 11840, lr = 0.01
I0822 21:03:52.401952 31324 solver.cpp:254] Iteration 11860 (2.0629 iter/s, 9.69511s/20 iters), loss = 2.53912
I0822 21:03:52.402086 31324 solver.cpp:273]     Train net output #0: loss = 2.53912 (* 1 = 2.53912 loss)
I0822 21:03:52.402107 31324 sgd_solver.cpp:790] Iteration 11860, lr = 0.01
I0822 21:04:03.278200 31324 solver.cpp:254] Iteration 11880 (1.8389 iter/s, 10.876s/20 iters), loss = 2.48149
I0822 21:04:03.278270 31324 solver.cpp:273]     Train net output #0: loss = 2.48149 (* 1 = 2.48149 loss)
I0822 21:04:03.278283 31324 sgd_solver.cpp:790] Iteration 11880, lr = 0.01
I0822 21:04:14.050928 31324 solver.cpp:254] Iteration 11900 (1.85656 iter/s, 10.7726s/20 iters), loss = 2.4057
I0822 21:04:14.051000 31324 solver.cpp:273]     Train net output #0: loss = 2.4057 (* 1 = 2.4057 loss)
I0822 21:04:14.051014 31324 sgd_solver.cpp:790] Iteration 11900, lr = 0.01
I0822 21:04:24.474156 31324 solver.cpp:254] Iteration 11920 (1.91882 iter/s, 10.4231s/20 iters), loss = 2.40324
I0822 21:04:24.475783 31324 solver.cpp:273]     Train net output #0: loss = 2.40324 (* 1 = 2.40324 loss)
I0822 21:04:24.477455 31324 sgd_solver.cpp:790] Iteration 11920, lr = 0.01
I0822 21:04:35.341697 31324 solver.cpp:254] Iteration 11940 (1.84063 iter/s, 10.8659s/20 iters), loss = 2.58385
I0822 21:04:35.341771 31324 solver.cpp:273]     Train net output #0: loss = 2.58385 (* 1 = 2.58385 loss)
I0822 21:04:35.341784 31324 sgd_solver.cpp:790] Iteration 11940, lr = 0.01
I0822 21:04:45.751166 31324 solver.cpp:254] Iteration 11960 (1.92135 iter/s, 10.4093s/20 iters), loss = 2.68301
I0822 21:04:45.751227 31324 solver.cpp:273]     Train net output #0: loss = 2.68301 (* 1 = 2.68301 loss)
I0822 21:04:45.751237 31324 sgd_solver.cpp:790] Iteration 11960, lr = 0.01
I0822 21:04:56.217190 31324 solver.cpp:254] Iteration 11980 (1.91097 iter/s, 10.4659s/20 iters), loss = 2.52538
I0822 21:04:56.217355 31324 solver.cpp:273]     Train net output #0: loss = 2.52538 (* 1 = 2.52538 loss)
I0822 21:04:56.217375 31324 sgd_solver.cpp:790] Iteration 11980, lr = 0.01
I0822 21:05:06.214610 31324 solver.cpp:366] Iteration 12000, Testing net (#0)
I0822 21:05:09.741634 31324 blocking_queue.cpp:49] Waiting for data
I0822 21:05:30.503670 31336 data_layer.cpp:73] Restarting data prefetching from start.
I0822 21:05:30.520808 31324 solver.cpp:433]     Test net output #0: accuracy = 0.47108
I0822 21:05:30.520850 31324 solver.cpp:433]     Test net output #1: accuracy5 = 0.73332
I0822 21:05:30.520862 31324 solver.cpp:433]     Test net output #2: loss = 2.34683 (* 1 = 2.34683 loss)
I0822 21:05:30.689791 31324 solver.cpp:254] Iteration 12000 (0.580176 iter/s, 34.4723s/20 iters), loss = 2.43963
I0822 21:05:30.692212 31324 solver.cpp:273]     Train net output #0: loss = 2.43963 (* 1 = 2.43963 loss)
I0822 21:05:30.692242 31324 sgd_solver.cpp:790] Iteration 12000, lr = 0.01
I0822 21:05:38.595886 31324 solver.cpp:254] Iteration 12020 (2.53048 iter/s, 7.90364s/20 iters), loss = 2.61294
I0822 21:05:38.595948 31324 solver.cpp:273]     Train net output #0: loss = 2.61294 (* 1 = 2.61294 loss)
I0822 21:05:38.595966 31324 sgd_solver.cpp:790] Iteration 12020, lr = 0.01
I0822 21:05:48.171233 31324 solver.cpp:254] Iteration 12040 (2.08872 iter/s, 9.57523s/20 iters), loss = 2.57487
I0822 21:05:48.171290 31324 solver.cpp:273]     Train net output #0: loss = 2.57487 (* 1 = 2.57487 loss)
I0822 21:05:48.171303 31324 sgd_solver.cpp:790] Iteration 12040, lr = 0.01
I0822 21:05:58.601459 31324 solver.cpp:254] Iteration 12060 (1.91753 iter/s, 10.4301s/20 iters), loss = 2.60131
I0822 21:05:58.601544 31324 solver.cpp:273]     Train net output #0: loss = 2.60131 (* 1 = 2.60131 loss)
I0822 21:05:58.601559 31324 sgd_solver.cpp:790] Iteration 12060, lr = 0.01
I0822 21:06:08.849681 31324 solver.cpp:254] Iteration 12080 (1.95159 iter/s, 10.2481s/20 iters), loss = 2.56639
I0822 21:06:08.849854 31324 solver.cpp:273]     Train net output #0: loss = 2.56639 (* 1 = 2.56639 loss)
I0822 21:06:08.849871 31324 sgd_solver.cpp:790] Iteration 12080, lr = 0.01
I0822 21:06:19.182938 31324 solver.cpp:254] Iteration 12100 (1.93554 iter/s, 10.333s/20 iters), loss = 2.40734
I0822 21:06:19.183008 31324 solver.cpp:273]     Train net output #0: loss = 2.40734 (* 1 = 2.40734 loss)
I0822 21:06:19.183022 31324 sgd_solver.cpp:790] Iteration 12100, lr = 0.01
I0822 21:06:29.394750 31324 solver.cpp:254] Iteration 12120 (1.95854 iter/s, 10.2117s/20 iters), loss = 2.75519
I0822 21:06:29.394817 31324 solver.cpp:273]     Train net output #0: loss = 2.75519 (* 1 = 2.75519 loss)
I0822 21:06:29.394829 31324 sgd_solver.cpp:790] Iteration 12120, lr = 0.01
I0822 21:06:39.954535 31324 solver.cpp:254] Iteration 12140 (1.894 iter/s, 10.5596s/20 iters), loss = 2.793
I0822 21:06:39.954695 31324 solver.cpp:273]     Train net output #0: loss = 2.793 (* 1 = 2.793 loss)
I0822 21:06:39.954710 31324 sgd_solver.cpp:790] Iteration 12140, lr = 0.01
I0822 21:06:41.437250 31324 blocking_queue.cpp:49] Waiting for data
I0822 21:06:50.421021 31324 solver.cpp:254] Iteration 12160 (1.9109 iter/s, 10.4663s/20 iters), loss = 2.48083
I0822 21:06:50.421099 31324 solver.cpp:273]     Train net output #0: loss = 2.48083 (* 1 = 2.48083 loss)
I0822 21:06:50.421113 31324 sgd_solver.cpp:790] Iteration 12160, lr = 0.01
I0822 21:07:00.677079 31324 solver.cpp:254] Iteration 12180 (1.9501 iter/s, 10.2559s/20 iters), loss = 2.4995
I0822 21:07:00.677151 31324 solver.cpp:273]     Train net output #0: loss = 2.4995 (* 1 = 2.4995 loss)
I0822 21:07:00.677165 31324 sgd_solver.cpp:790] Iteration 12180, lr = 0.01
I0822 21:07:11.018497 31324 solver.cpp:254] Iteration 12200 (1.934 iter/s, 10.3413s/20 iters), loss = 2.68668
I0822 21:07:11.018638 31324 solver.cpp:273]     Train net output #0: loss = 2.68668 (* 1 = 2.68668 loss)
I0822 21:07:11.020912 31324 sgd_solver.cpp:790] Iteration 12200, lr = 0.01
I0822 21:07:21.354207 31324 solver.cpp:254] Iteration 12220 (1.93508 iter/s, 10.3355s/20 iters), loss = 2.52666
I0822 21:07:21.354286 31324 solver.cpp:273]     Train net output #0: loss = 2.52666 (* 1 = 2.52666 loss)
I0822 21:07:21.354686 31324 sgd_solver.cpp:790] Iteration 12220, lr = 0.01
I0822 21:07:29.274863 31324 solver.cpp:254] Iteration 12240 (2.52509 iter/s, 7.92052s/20 iters), loss = 2.31124
I0822 21:07:29.274922 31324 solver.cpp:273]     Train net output #0: loss = 2.31124 (* 1 = 2.31124 loss)
I0822 21:07:29.274932 31324 sgd_solver.cpp:790] Iteration 12240, lr = 0.01
I0822 21:07:39.551657 31324 solver.cpp:254] Iteration 12260 (1.94616 iter/s, 10.2767s/20 iters), loss = 2.39212
I0822 21:07:39.551736 31324 solver.cpp:273]     Train net output #0: loss = 2.39212 (* 1 = 2.39212 loss)
I0822 21:07:39.551751 31324 sgd_solver.cpp:790] Iteration 12260, lr = 0.01
I0822 21:07:50.123602 31324 solver.cpp:254] Iteration 12280 (1.89183 iter/s, 10.5718s/20 iters), loss = 2.51448
I0822 21:07:50.123792 31324 solver.cpp:273]     Train net output #0: loss = 2.51448 (* 1 = 2.51448 loss)
I0822 21:07:50.123807 31324 sgd_solver.cpp:790] Iteration 12280, lr = 0.01
I0822 21:08:00.327178 31324 solver.cpp:254] Iteration 12300 (1.96015 iter/s, 10.2033s/20 iters), loss = 2.37775
I0822 21:08:00.327262 31324 solver.cpp:273]     Train net output #0: loss = 2.37775 (* 1 = 2.37775 loss)
I0822 21:08:00.327280 31324 sgd_solver.cpp:790] Iteration 12300, lr = 0.01
I0822 21:08:10.739795 31324 solver.cpp:254] Iteration 12320 (1.92077 iter/s, 10.4125s/20 iters), loss = 2.69687
I0822 21:08:10.739856 31324 solver.cpp:273]     Train net output #0: loss = 2.69687 (* 1 = 2.69687 loss)
I0822 21:08:10.739866 31324 sgd_solver.cpp:790] Iteration 12320, lr = 0.01
I0822 21:08:21.212965 31324 solver.cpp:254] Iteration 12340 (1.90966 iter/s, 10.473s/20 iters), loss = 2.50489
I0822 21:08:21.213107 31324 solver.cpp:273]     Train net output #0: loss = 2.50489 (* 1 = 2.50489 loss)
I0822 21:08:21.213119 31324 sgd_solver.cpp:790] Iteration 12340, lr = 0.01
I0822 21:08:31.786849 31324 solver.cpp:254] Iteration 12360 (1.89149 iter/s, 10.5737s/20 iters), loss = 2.54005
I0822 21:08:31.786924 31324 solver.cpp:273]     Train net output #0: loss = 2.54005 (* 1 = 2.54005 loss)
I0822 21:08:31.786937 31324 sgd_solver.cpp:790] Iteration 12360, lr = 0.01
I0822 21:08:42.372965 31324 solver.cpp:254] Iteration 12380 (1.88929 iter/s, 10.586s/20 iters), loss = 2.43587
I0822 21:08:42.373073 31324 solver.cpp:273]     Train net output #0: loss = 2.43587 (* 1 = 2.43587 loss)
I0822 21:08:42.373093 31324 sgd_solver.cpp:790] Iteration 12380, lr = 0.01
I0822 21:08:53.028937 31324 solver.cpp:254] Iteration 12400 (1.87691 iter/s, 10.6558s/20 iters), loss = 2.71857
I0822 21:08:53.029099 31324 solver.cpp:273]     Train net output #0: loss = 2.71857 (* 1 = 2.71857 loss)
I0822 21:08:53.029114 31324 sgd_solver.cpp:790] Iteration 12400, lr = 0.01
I0822 21:09:03.610082 31324 solver.cpp:254] Iteration 12420 (1.8902 iter/s, 10.5809s/20 iters), loss = 2.55213
I0822 21:09:03.610147 31324 solver.cpp:273]     Train net output #0: loss = 2.55213 (* 1 = 2.55213 loss)
I0822 21:09:03.610159 31324 sgd_solver.cpp:790] Iteration 12420, lr = 0.01
I0822 21:09:14.104387 31324 solver.cpp:254] Iteration 12440 (1.90582 iter/s, 10.4942s/20 iters), loss = 2.49934
I0822 21:09:14.104475 31324 solver.cpp:273]     Train net output #0: loss = 2.49934 (* 1 = 2.49934 loss)
I0822 21:09:14.104490 31324 sgd_solver.cpp:790] Iteration 12440, lr = 0.01
I0822 21:09:24.849892 31324 solver.cpp:254] Iteration 12460 (1.86127 iter/s, 10.7454s/20 iters), loss = 2.3126
I0822 21:09:24.850069 31324 solver.cpp:273]     Train net output #0: loss = 2.3126 (* 1 = 2.3126 loss)
I0822 21:09:24.850085 31324 sgd_solver.cpp:790] Iteration 12460, lr = 0.01
I0822 21:09:35.355650 31324 solver.cpp:254] Iteration 12480 (1.90376 iter/s, 10.5055s/20 iters), loss = 2.57787
I0822 21:09:35.355715 31324 solver.cpp:273]     Train net output #0: loss = 2.57787 (* 1 = 2.57787 loss)
I0822 21:09:35.355726 31324 sgd_solver.cpp:790] Iteration 12480, lr = 0.01
I0822 21:09:46.025985 31324 solver.cpp:254] Iteration 12500 (1.87438 iter/s, 10.6702s/20 iters), loss = 2.54642
I0822 21:09:46.026065 31324 solver.cpp:273]     Train net output #0: loss = 2.54642 (* 1 = 2.54642 loss)
I0822 21:09:46.026082 31324 sgd_solver.cpp:790] Iteration 12500, lr = 0.01
I0822 21:09:56.726862 31324 solver.cpp:254] Iteration 12520 (1.86903 iter/s, 10.7007s/20 iters), loss = 2.69037
I0822 21:09:56.727028 31324 solver.cpp:273]     Train net output #0: loss = 2.69037 (* 1 = 2.69037 loss)
I0822 21:09:56.727039 31324 sgd_solver.cpp:790] Iteration 12520, lr = 0.01
I0822 21:10:06.906761 31324 solver.cpp:254] Iteration 12540 (1.9647 iter/s, 10.1797s/20 iters), loss = 2.59864
I0822 21:10:06.906831 31324 solver.cpp:273]     Train net output #0: loss = 2.59864 (* 1 = 2.59864 loss)
I0822 21:10:06.906844 31324 sgd_solver.cpp:790] Iteration 12540, lr = 0.01
I0822 21:10:17.196785 31324 solver.cpp:254] Iteration 12560 (1.94366 iter/s, 10.2899s/20 iters), loss = 2.75787
I0822 21:10:17.196856 31324 solver.cpp:273]     Train net output #0: loss = 2.75787 (* 1 = 2.75787 loss)
I0822 21:10:17.196869 31324 sgd_solver.cpp:790] Iteration 12560, lr = 0.01
I0822 21:10:27.771498 31324 solver.cpp:254] Iteration 12580 (1.89133 iter/s, 10.5746s/20 iters), loss = 2.65742
I0822 21:10:27.775251 31324 solver.cpp:273]     Train net output #0: loss = 2.65742 (* 1 = 2.65742 loss)
I0822 21:10:27.775266 31324 sgd_solver.cpp:790] Iteration 12580, lr = 0.01
I0822 21:10:38.173997 31324 solver.cpp:254] Iteration 12600 (1.92332 iter/s, 10.3987s/20 iters), loss = 2.49652
I0822 21:10:38.174065 31324 solver.cpp:273]     Train net output #0: loss = 2.49652 (* 1 = 2.49652 loss)
I0822 21:10:38.174079 31324 sgd_solver.cpp:790] Iteration 12600, lr = 0.01
I0822 21:10:48.355195 31324 solver.cpp:254] Iteration 12620 (1.96443 iter/s, 10.1811s/20 iters), loss = 2.70011
I0822 21:10:48.355252 31324 solver.cpp:273]     Train net output #0: loss = 2.70011 (* 1 = 2.70011 loss)
I0822 21:10:48.355263 31324 sgd_solver.cpp:790] Iteration 12620, lr = 0.01
I0822 21:10:57.802438 31324 solver.cpp:254] Iteration 12640 (2.11705 iter/s, 9.44712s/20 iters), loss = 2.62802
I0822 21:10:57.802603 31324 solver.cpp:273]     Train net output #0: loss = 2.62802 (* 1 = 2.62802 loss)
I0822 21:10:57.802614 31324 sgd_solver.cpp:790] Iteration 12640, lr = 0.01
I0822 21:11:06.574177 31324 solver.cpp:254] Iteration 12660 (2.28011 iter/s, 8.77152s/20 iters), loss = 2.68195
I0822 21:11:06.574254 31324 solver.cpp:273]     Train net output #0: loss = 2.68195 (* 1 = 2.68195 loss)
I0822 21:11:06.574272 31324 sgd_solver.cpp:790] Iteration 12660, lr = 0.01
I0822 21:11:13.432554 31324 solver.cpp:254] Iteration 12680 (2.91619 iter/s, 6.85826s/20 iters), loss = 2.32452
I0822 21:11:13.432620 31324 solver.cpp:273]     Train net output #0: loss = 2.32452 (* 1 = 2.32452 loss)
I0822 21:11:13.432634 31324 sgd_solver.cpp:790] Iteration 12680, lr = 0.01
I0822 21:11:21.967296 31324 solver.cpp:254] Iteration 12700 (2.34339 iter/s, 8.53463s/20 iters), loss = 2.40047
I0822 21:11:21.967355 31324 solver.cpp:273]     Train net output #0: loss = 2.40047 (* 1 = 2.40047 loss)
I0822 21:11:21.967366 31324 sgd_solver.cpp:790] Iteration 12700, lr = 0.01
I0822 21:11:29.827996 31324 solver.cpp:254] Iteration 12720 (2.54434 iter/s, 7.86059s/20 iters), loss = 2.67233
I0822 21:11:29.828281 31324 solver.cpp:273]     Train net output #0: loss = 2.67233 (* 1 = 2.67233 loss)
I0822 21:11:29.828303 31324 sgd_solver.cpp:790] Iteration 12720, lr = 0.01
I0822 21:11:33.653839 31324 solver.cpp:254] Iteration 12740 (5.22805 iter/s, 3.82552s/20 iters), loss = 2.55247
I0822 21:11:33.665948 31324 solver.cpp:273]     Train net output #0: loss = 2.55247 (* 1 = 2.55247 loss)
I0822 21:11:33.665983 31324 sgd_solver.cpp:790] Iteration 12740, lr = 0.01
I0822 21:11:37.319437 31324 solver.cpp:254] Iteration 12760 (5.47423 iter/s, 3.65348s/20 iters), loss = 2.73769
I0822 21:11:37.331594 31324 solver.cpp:273]     Train net output #0: loss = 2.73769 (* 1 = 2.73769 loss)
I0822 21:11:37.331620 31324 sgd_solver.cpp:790] Iteration 12760, lr = 0.01
I0822 21:11:40.984696 31324 solver.cpp:254] Iteration 12780 (5.47483 iter/s, 3.65308s/20 iters), loss = 2.75119
I0822 21:11:40.996839 31324 solver.cpp:273]     Train net output #0: loss = 2.75119 (* 1 = 2.75119 loss)
I0822 21:11:40.996870 31324 sgd_solver.cpp:790] Iteration 12780, lr = 0.01
I0822 21:11:44.643206 31324 solver.cpp:254] Iteration 12800 (5.48494 iter/s, 3.64635s/20 iters), loss = 2.43582
I0822 21:11:44.655386 31324 solver.cpp:273]     Train net output #0: loss = 2.43582 (* 1 = 2.43582 loss)
I0822 21:11:44.655414 31324 sgd_solver.cpp:790] Iteration 12800, lr = 0.01
I0822 21:11:48.331069 31324 solver.cpp:254] Iteration 12820 (5.44119 iter/s, 3.67567s/20 iters), loss = 2.6607
I0822 21:11:48.343236 31324 solver.cpp:273]     Train net output #0: loss = 2.6607 (* 1 = 2.6607 loss)
I0822 21:11:48.343278 31324 sgd_solver.cpp:790] Iteration 12820, lr = 0.01
I0822 21:11:55.691218 31324 solver.cpp:254] Iteration 12840 (2.72184 iter/s, 7.34798s/20 iters), loss = 2.50127
I0822 21:11:55.691283 31324 solver.cpp:273]     Train net output #0: loss = 2.50127 (* 1 = 2.50127 loss)
I0822 21:11:55.691296 31324 sgd_solver.cpp:790] Iteration 12840, lr = 0.01
I0822 21:12:06.179940 31324 solver.cpp:254] Iteration 12860 (1.90683 iter/s, 10.4886s/20 iters), loss = 2.43038
I0822 21:12:06.180124 31324 solver.cpp:273]     Train net output #0: loss = 2.43038 (* 1 = 2.43038 loss)
I0822 21:12:06.180158 31324 sgd_solver.cpp:790] Iteration 12860, lr = 0.01
I0822 21:12:15.601225 31324 solver.cpp:254] Iteration 12880 (2.12291 iter/s, 9.42105s/20 iters), loss = 2.54244
I0822 21:12:15.601279 31324 solver.cpp:273]     Train net output #0: loss = 2.54244 (* 1 = 2.54244 loss)
I0822 21:12:15.601289 31324 sgd_solver.cpp:790] Iteration 12880, lr = 0.01
I0822 21:12:24.721904 31324 solver.cpp:254] Iteration 12900 (2.19285 iter/s, 9.12055s/20 iters), loss = 2.35112
I0822 21:12:24.721961 31324 solver.cpp:273]     Train net output #0: loss = 2.35112 (* 1 = 2.35112 loss)
I0822 21:12:24.721973 31324 sgd_solver.cpp:790] Iteration 12900, lr = 0.01
I0822 21:12:34.714172 31324 solver.cpp:254] Iteration 12920 (2.00157 iter/s, 9.99214s/20 iters), loss = 2.64717
I0822 21:12:34.714262 31324 solver.cpp:273]     Train net output #0: loss = 2.64717 (* 1 = 2.64717 loss)
I0822 21:12:34.714275 31324 sgd_solver.cpp:790] Iteration 12920, lr = 0.01
I0822 21:12:45.396606 31324 solver.cpp:254] Iteration 12940 (1.87226 iter/s, 10.6823s/20 iters), loss = 2.57488
I0822 21:12:45.398665 31324 solver.cpp:273]     Train net output #0: loss = 2.57488 (* 1 = 2.57488 loss)
I0822 21:12:45.398682 31324 sgd_solver.cpp:790] Iteration 12940, lr = 0.01
I0822 21:12:56.127254 31324 solver.cpp:254] Iteration 12960 (1.86419 iter/s, 10.7285s/20 iters), loss = 2.55219
I0822 21:12:56.127331 31324 solver.cpp:273]     Train net output #0: loss = 2.55219 (* 1 = 2.55219 loss)
I0822 21:12:56.127344 31324 sgd_solver.cpp:790] Iteration 12960, lr = 0.01
I0822 21:13:06.883553 31324 solver.cpp:254] Iteration 12980 (1.8594 iter/s, 10.7561s/20 iters), loss = 2.4405
I0822 21:13:06.883607 31324 solver.cpp:273]     Train net output #0: loss = 2.4405 (* 1 = 2.4405 loss)
I0822 21:13:06.883618 31324 sgd_solver.cpp:790] Iteration 12980, lr = 0.01
I0822 21:13:16.743206 31324 solver.cpp:366] Iteration 13000, Testing net (#0)
I0822 21:13:21.021471 31324 blocking_queue.cpp:49] Waiting for data
I0822 21:13:41.137362 31336 data_layer.cpp:73] Restarting data prefetching from start.
I0822 21:13:41.153200 31324 solver.cpp:433]     Test net output #0: accuracy = 0.47554
I0822 21:13:41.153241 31324 solver.cpp:433]     Test net output #1: accuracy5 = 0.73118
I0822 21:13:41.153252 31324 solver.cpp:433]     Test net output #2: loss = 2.33839 (* 1 = 2.33839 loss)
I0822 21:13:41.325547 31324 solver.cpp:254] Iteration 13000 (0.580691 iter/s, 34.4417s/20 iters), loss = 2.41436
I0822 21:13:41.328073 31324 solver.cpp:273]     Train net output #0: loss = 2.41436 (* 1 = 2.41436 loss)
I0822 21:13:41.328094 31324 sgd_solver.cpp:790] Iteration 13000, lr = 0.01
I0822 21:13:50.591739 31324 solver.cpp:254] Iteration 13020 (2.15899 iter/s, 9.26359s/20 iters), loss = 2.46745
I0822 21:13:50.591892 31324 solver.cpp:273]     Train net output #0: loss = 2.46745 (* 1 = 2.46745 loss)
I0822 21:13:50.591907 31324 sgd_solver.cpp:790] Iteration 13020, lr = 0.01
I0822 21:14:01.089476 31324 solver.cpp:254] Iteration 13040 (1.90521 iter/s, 10.4975s/20 iters), loss = 2.53118
I0822 21:14:01.089538 31324 solver.cpp:273]     Train net output #0: loss = 2.53118 (* 1 = 2.53118 loss)
I0822 21:14:01.089548 31324 sgd_solver.cpp:790] Iteration 13040, lr = 0.01
I0822 21:14:11.614506 31324 solver.cpp:254] Iteration 13060 (1.90026 iter/s, 10.5249s/20 iters), loss = 2.58946
I0822 21:14:11.614586 31324 solver.cpp:273]     Train net output #0: loss = 2.58946 (* 1 = 2.58946 loss)
I0822 21:14:11.614603 31324 sgd_solver.cpp:790] Iteration 13060, lr = 0.01
I0822 21:14:21.904687 31324 solver.cpp:254] Iteration 13080 (1.94363 iter/s, 10.29s/20 iters), loss = 2.6997
I0822 21:14:21.904871 31324 solver.cpp:273]     Train net output #0: loss = 2.6997 (* 1 = 2.6997 loss)
I0822 21:14:21.904886 31324 sgd_solver.cpp:790] Iteration 13080, lr = 0.01
I0822 21:14:32.274669 31324 solver.cpp:254] Iteration 13100 (1.92869 iter/s, 10.3697s/20 iters), loss = 2.59774
I0822 21:14:32.274742 31324 solver.cpp:273]     Train net output #0: loss = 2.59774 (* 1 = 2.59774 loss)
I0822 21:14:32.274754 31324 sgd_solver.cpp:790] Iteration 13100, lr = 0.01
I0822 21:14:42.547597 31324 solver.cpp:254] Iteration 13120 (1.94689 iter/s, 10.2728s/20 iters), loss = 2.36434
I0822 21:14:42.547657 31324 solver.cpp:273]     Train net output #0: loss = 2.36434 (* 1 = 2.36434 loss)
I0822 21:14:42.547677 31324 sgd_solver.cpp:790] Iteration 13120, lr = 0.01
I0822 21:14:53.028404 31324 solver.cpp:254] Iteration 13140 (1.90827 iter/s, 10.4807s/20 iters), loss = 2.38568
I0822 21:14:53.030521 31324 solver.cpp:273]     Train net output #0: loss = 2.38568 (* 1 = 2.38568 loss)
I0822 21:14:53.030545 31324 sgd_solver.cpp:790] Iteration 13140, lr = 0.01
I0822 21:15:00.818594 31324 blocking_queue.cpp:49] Waiting for data
I0822 21:15:03.399701 31324 solver.cpp:254] Iteration 13160 (1.9288 iter/s, 10.3691s/20 iters), loss = 2.56621
I0822 21:15:03.399765 31324 solver.cpp:273]     Train net output #0: loss = 2.56621 (* 1 = 2.56621 loss)
I0822 21:15:03.402287 31324 sgd_solver.cpp:790] Iteration 13160, lr = 0.01
I0822 21:15:13.872637 31324 solver.cpp:254] Iteration 13180 (1.90971 iter/s, 10.4728s/20 iters), loss = 2.57025
I0822 21:15:13.872712 31324 solver.cpp:273]     Train net output #0: loss = 2.57025 (* 1 = 2.57025 loss)
I0822 21:15:13.872726 31324 sgd_solver.cpp:790] Iteration 13180, lr = 0.01
I0822 21:15:24.354882 31324 solver.cpp:254] Iteration 13200 (1.90802 iter/s, 10.4821s/20 iters), loss = 2.65742
I0822 21:15:24.355026 31324 solver.cpp:273]     Train net output #0: loss = 2.65742 (* 1 = 2.65742 loss)
I0822 21:15:24.355046 31324 sgd_solver.cpp:790] Iteration 13200, lr = 0.01
I0822 21:15:35.045536 31324 solver.cpp:254] Iteration 13220 (1.87083 iter/s, 10.6904s/20 iters), loss = 2.70738
I0822 21:15:35.045598 31324 solver.cpp:273]     Train net output #0: loss = 2.70738 (* 1 = 2.70738 loss)
I0822 21:15:35.045617 31324 sgd_solver.cpp:790] Iteration 13220, lr = 0.01
I0822 21:15:45.583936 31324 solver.cpp:254] Iteration 13240 (1.89785 iter/s, 10.5383s/20 iters), loss = 2.58866
I0822 21:15:45.584014 31324 solver.cpp:273]     Train net output #0: loss = 2.58866 (* 1 = 2.58866 loss)
I0822 21:15:45.584028 31324 sgd_solver.cpp:790] Iteration 13240, lr = 0.01
I0822 21:15:56.073585 31324 solver.cpp:254] Iteration 13260 (1.90667 iter/s, 10.4895s/20 iters), loss = 2.6964
I0822 21:15:56.073741 31324 solver.cpp:273]     Train net output #0: loss = 2.6964 (* 1 = 2.6964 loss)
I0822 21:15:56.073771 31324 sgd_solver.cpp:790] Iteration 13260, lr = 0.01
I0822 21:16:06.567317 31324 solver.cpp:254] Iteration 13280 (1.90594 iter/s, 10.4935s/20 iters), loss = 2.62803
I0822 21:16:06.567385 31324 solver.cpp:273]     Train net output #0: loss = 2.62803 (* 1 = 2.62803 loss)
I0822 21:16:06.567404 31324 sgd_solver.cpp:790] Iteration 13280, lr = 0.01
I0822 21:16:16.678985 31324 solver.cpp:254] Iteration 13300 (1.97794 iter/s, 10.1115s/20 iters), loss = 2.7039
I0822 21:16:16.679075 31324 solver.cpp:273]     Train net output #0: loss = 2.7039 (* 1 = 2.7039 loss)
I0822 21:16:16.679092 31324 sgd_solver.cpp:790] Iteration 13300, lr = 0.01
I0822 21:16:25.707798 31324 solver.cpp:254] Iteration 13320 (2.21517 iter/s, 9.02865s/20 iters), loss = 2.43893
I0822 21:16:25.707855 31324 solver.cpp:273]     Train net output #0: loss = 2.43893 (* 1 = 2.43893 loss)
I0822 21:16:25.707868 31324 sgd_solver.cpp:790] Iteration 13320, lr = 0.01
I0822 21:16:35.214100 31324 solver.cpp:254] Iteration 13340 (2.1039 iter/s, 9.50616s/20 iters), loss = 2.57926
I0822 21:16:35.217823 31324 solver.cpp:273]     Train net output #0: loss = 2.57926 (* 1 = 2.57926 loss)
I0822 21:16:35.217839 31324 sgd_solver.cpp:790] Iteration 13340, lr = 0.01
I0822 21:16:44.373065 31324 solver.cpp:254] Iteration 13360 (2.18456 iter/s, 9.15517s/20 iters), loss = 2.55258
I0822 21:16:44.373126 31324 solver.cpp:273]     Train net output #0: loss = 2.55258 (* 1 = 2.55258 loss)
I0822 21:16:44.373137 31324 sgd_solver.cpp:790] Iteration 13360, lr = 0.01
I0822 21:16:53.716168 31324 solver.cpp:254] Iteration 13380 (2.14065 iter/s, 9.34296s/20 iters), loss = 2.60976
I0822 21:16:53.716233 31324 solver.cpp:273]     Train net output #0: loss = 2.60976 (* 1 = 2.60976 loss)
I0822 21:16:53.716243 31324 sgd_solver.cpp:790] Iteration 13380, lr = 0.01
I0822 21:17:04.212961 31324 solver.cpp:254] Iteration 13400 (1.90537 iter/s, 10.4966s/20 iters), loss = 2.4791
I0822 21:17:04.213022 31324 solver.cpp:273]     Train net output #0: loss = 2.4791 (* 1 = 2.4791 loss)
I0822 21:17:04.213033 31324 sgd_solver.cpp:790] Iteration 13400, lr = 0.01
I0822 21:17:14.861629 31324 solver.cpp:254] Iteration 13420 (1.8782 iter/s, 10.6485s/20 iters), loss = 2.70681
I0822 21:17:14.861834 31324 solver.cpp:273]     Train net output #0: loss = 2.70681 (* 1 = 2.70681 loss)
I0822 21:17:14.861855 31324 sgd_solver.cpp:790] Iteration 13420, lr = 0.01
I0822 21:17:25.338351 31324 solver.cpp:254] Iteration 13440 (1.90905 iter/s, 10.4764s/20 iters), loss = 2.63086
I0822 21:17:25.338430 31324 solver.cpp:273]     Train net output #0: loss = 2.63086 (* 1 = 2.63086 loss)
I0822 21:17:25.338443 31324 sgd_solver.cpp:790] Iteration 13440, lr = 0.01
I0822 21:17:35.879591 31324 solver.cpp:254] Iteration 13460 (1.89734 iter/s, 10.5411s/20 iters), loss = 2.3387
I0822 21:17:35.879662 31324 solver.cpp:273]     Train net output #0: loss = 2.3387 (* 1 = 2.3387 loss)
I0822 21:17:35.879679 31324 sgd_solver.cpp:790] Iteration 13460, lr = 0.01
I0822 21:17:46.216753 31324 solver.cpp:254] Iteration 13480 (1.9348 iter/s, 10.337s/20 iters), loss = 2.61671
I0822 21:17:46.216893 31324 solver.cpp:273]     Train net output #0: loss = 2.61671 (* 1 = 2.61671 loss)
I0822 21:17:46.216905 31324 sgd_solver.cpp:790] Iteration 13480, lr = 0.01
I0822 21:17:56.957296 31324 solver.cpp:254] Iteration 13500 (1.86214 iter/s, 10.7403s/20 iters), loss = 2.64715
I0822 21:17:56.957362 31324 solver.cpp:273]     Train net output #0: loss = 2.64715 (* 1 = 2.64715 loss)
I0822 21:17:56.957375 31324 sgd_solver.cpp:790] Iteration 13500, lr = 0.01
I0822 21:18:07.303865 31324 solver.cpp:254] Iteration 13520 (1.93304 iter/s, 10.3464s/20 iters), loss = 2.44535
I0822 21:18:07.303936 31324 solver.cpp:273]     Train net output #0: loss = 2.44535 (* 1 = 2.44535 loss)
I0822 21:18:07.303948 31324 sgd_solver.cpp:790] Iteration 13520, lr = 0.01
I0822 21:18:17.691452 31324 solver.cpp:254] Iteration 13540 (1.9254 iter/s, 10.3874s/20 iters), loss = 2.61373
I0822 21:18:17.694147 31324 solver.cpp:273]     Train net output #0: loss = 2.61373 (* 1 = 2.61373 loss)
I0822 21:18:17.694628 31324 sgd_solver.cpp:790] Iteration 13540, lr = 0.01
I0822 21:18:27.430606 31324 solver.cpp:254] Iteration 13560 (2.05415 iter/s, 9.7364s/20 iters), loss = 2.85098
I0822 21:18:27.430680 31324 solver.cpp:273]     Train net output #0: loss = 2.85098 (* 1 = 2.85098 loss)
I0822 21:18:27.430694 31324 sgd_solver.cpp:790] Iteration 13560, lr = 0.01
I0822 21:18:36.983304 31324 solver.cpp:254] Iteration 13580 (2.09368 iter/s, 9.55255s/20 iters), loss = 2.51653
I0822 21:18:36.983383 31324 solver.cpp:273]     Train net output #0: loss = 2.51653 (* 1 = 2.51653 loss)
I0822 21:18:36.983397 31324 sgd_solver.cpp:790] Iteration 13580, lr = 0.01
I0822 21:18:44.880975 31324 solver.cpp:254] Iteration 13600 (2.53244 iter/s, 7.89753s/20 iters), loss = 2.85022
I0822 21:18:44.881036 31324 solver.cpp:273]     Train net output #0: loss = 2.85022 (* 1 = 2.85022 loss)
I0822 21:18:44.881052 31324 sgd_solver.cpp:790] Iteration 13600, lr = 0.01
I0822 21:18:53.181304 31324 solver.cpp:254] Iteration 13620 (2.40958 iter/s, 8.3002s/20 iters), loss = 2.55334
I0822 21:18:53.181488 31324 solver.cpp:273]     Train net output #0: loss = 2.55334 (* 1 = 2.55334 loss)
I0822 21:18:53.181499 31324 sgd_solver.cpp:790] Iteration 13620, lr = 0.01
I0822 21:19:02.165191 31324 solver.cpp:254] Iteration 13640 (2.22627 iter/s, 8.98363s/20 iters), loss = 2.61294
I0822 21:19:02.165252 31324 solver.cpp:273]     Train net output #0: loss = 2.61294 (* 1 = 2.61294 loss)
I0822 21:19:02.165266 31324 sgd_solver.cpp:790] Iteration 13640, lr = 0.01
I0822 21:19:12.770002 31324 solver.cpp:254] Iteration 13660 (1.88596 iter/s, 10.6047s/20 iters), loss = 2.64188
I0822 21:19:12.770078 31324 solver.cpp:273]     Train net output #0: loss = 2.64188 (* 1 = 2.64188 loss)
I0822 21:19:12.770092 31324 sgd_solver.cpp:790] Iteration 13660, lr = 0.01
I0822 21:19:23.251730 31324 solver.cpp:254] Iteration 13680 (1.90811 iter/s, 10.4816s/20 iters), loss = 2.73736
I0822 21:19:23.251905 31324 solver.cpp:273]     Train net output #0: loss = 2.73736 (* 1 = 2.73736 loss)
I0822 21:19:23.251922 31324 sgd_solver.cpp:790] Iteration 13680, lr = 0.01
I0822 21:19:33.547292 31324 solver.cpp:254] Iteration 13700 (1.94263 iter/s, 10.2953s/20 iters), loss = 2.50192
I0822 21:19:33.547374 31324 solver.cpp:273]     Train net output #0: loss = 2.50192 (* 1 = 2.50192 loss)
I0822 21:19:33.547390 31324 sgd_solver.cpp:790] Iteration 13700, lr = 0.01
I0822 21:19:44.007599 31324 solver.cpp:254] Iteration 13720 (1.91202 iter/s, 10.4601s/20 iters), loss = 2.42364
I0822 21:19:44.007684 31324 solver.cpp:273]     Train net output #0: loss = 2.42364 (* 1 = 2.42364 loss)
I0822 21:19:44.007700 31324 sgd_solver.cpp:790] Iteration 13720, lr = 0.01
I0822 21:19:54.456266 31324 solver.cpp:254] Iteration 13740 (1.91415 iter/s, 10.4485s/20 iters), loss = 2.51564
I0822 21:19:54.456432 31324 solver.cpp:273]     Train net output #0: loss = 2.51564 (* 1 = 2.51564 loss)
I0822 21:19:54.456445 31324 sgd_solver.cpp:790] Iteration 13740, lr = 0.01
I0822 21:20:05.039433 31324 solver.cpp:254] Iteration 13760 (1.88984 iter/s, 10.5829s/20 iters), loss = 2.57426
I0822 21:20:05.039501 31324 solver.cpp:273]     Train net output #0: loss = 2.57426 (* 1 = 2.57426 loss)
I0822 21:20:05.039512 31324 sgd_solver.cpp:790] Iteration 13760, lr = 0.01
I0822 21:20:15.421367 31324 solver.cpp:254] Iteration 13780 (1.92645 iter/s, 10.3818s/20 iters), loss = 2.59532
I0822 21:20:15.421463 31324 solver.cpp:273]     Train net output #0: loss = 2.59532 (* 1 = 2.59532 loss)
I0822 21:20:15.421478 31324 sgd_solver.cpp:790] Iteration 13780, lr = 0.01
I0822 21:20:23.917732 31324 solver.cpp:254] Iteration 13800 (2.35399 iter/s, 8.49621s/20 iters), loss = 2.43544
I0822 21:20:23.917804 31324 solver.cpp:273]     Train net output #0: loss = 2.43544 (* 1 = 2.43544 loss)
I0822 21:20:23.917814 31324 sgd_solver.cpp:790] Iteration 13800, lr = 0.01
I0822 21:20:32.682121 31324 solver.cpp:254] Iteration 13820 (2.282 iter/s, 8.76425s/20 iters), loss = 2.4017
I0822 21:20:32.682273 31324 solver.cpp:273]     Train net output #0: loss = 2.4017 (* 1 = 2.4017 loss)
I0822 21:20:32.682287 31324 sgd_solver.cpp:790] Iteration 13820, lr = 0.01
I0822 21:20:41.882813 31324 solver.cpp:254] Iteration 13840 (2.1738 iter/s, 9.20047s/20 iters), loss = 2.42124
I0822 21:20:41.882908 31324 solver.cpp:273]     Train net output #0: loss = 2.42124 (* 1 = 2.42124 loss)
I0822 21:20:41.882928 31324 sgd_solver.cpp:790] Iteration 13840, lr = 0.01
I0822 21:20:52.620744 31324 solver.cpp:254] Iteration 13860 (1.86259 iter/s, 10.7378s/20 iters), loss = 2.38904
I0822 21:20:52.620843 31324 solver.cpp:273]     Train net output #0: loss = 2.38904 (* 1 = 2.38904 loss)
I0822 21:20:52.620862 31324 sgd_solver.cpp:790] Iteration 13860, lr = 0.01
I0822 21:21:03.277585 31324 solver.cpp:254] Iteration 13880 (1.87676 iter/s, 10.6567s/20 iters), loss = 2.5226
I0822 21:21:03.277812 31324 solver.cpp:273]     Train net output #0: loss = 2.5226 (* 1 = 2.5226 loss)
I0822 21:21:03.277830 31324 sgd_solver.cpp:790] Iteration 13880, lr = 0.01
I0822 21:21:13.623641 31324 solver.cpp:254] Iteration 13900 (1.93316 iter/s, 10.3458s/20 iters), loss = 2.56295
I0822 21:21:13.623711 31324 solver.cpp:273]     Train net output #0: loss = 2.56295 (* 1 = 2.56295 loss)
I0822 21:21:13.623724 31324 sgd_solver.cpp:790] Iteration 13900, lr = 0.01
I0822 21:21:24.166831 31324 solver.cpp:254] Iteration 13920 (1.89699 iter/s, 10.543s/20 iters), loss = 2.63532
I0822 21:21:24.166894 31324 solver.cpp:273]     Train net output #0: loss = 2.63532 (* 1 = 2.63532 loss)
I0822 21:21:24.166908 31324 sgd_solver.cpp:790] Iteration 13920, lr = 0.01
I0822 21:21:34.539376 31324 solver.cpp:254] Iteration 13940 (1.92819 iter/s, 10.3724s/20 iters), loss = 2.53867
I0822 21:21:34.539535 31324 solver.cpp:273]     Train net output #0: loss = 2.53867 (* 1 = 2.53867 loss)
I0822 21:21:34.539548 31324 sgd_solver.cpp:790] Iteration 13940, lr = 0.01
I0822 21:21:44.916208 31324 solver.cpp:254] Iteration 13960 (1.92741 iter/s, 10.3766s/20 iters), loss = 2.58846
I0822 21:21:44.916296 31324 solver.cpp:273]     Train net output #0: loss = 2.58846 (* 1 = 2.58846 loss)
I0822 21:21:44.916312 31324 sgd_solver.cpp:790] Iteration 13960, lr = 0.01
I0822 21:21:55.336289 31324 solver.cpp:254] Iteration 13980 (1.9194 iter/s, 10.4199s/20 iters), loss = 2.6887
I0822 21:21:55.336362 31324 solver.cpp:273]     Train net output #0: loss = 2.6887 (* 1 = 2.6887 loss)
I0822 21:21:55.336378 31324 sgd_solver.cpp:790] Iteration 13980, lr = 0.01
I0822 21:22:05.066493 31324 solver.cpp:366] Iteration 14000, Testing net (#0)
I0822 21:22:09.147434 31324 blocking_queue.cpp:49] Waiting for data
I0822 21:22:30.207434 31336 data_layer.cpp:73] Restarting data prefetching from start.
I0822 21:22:30.223331 31324 solver.cpp:433]     Test net output #0: accuracy = 0.47646
I0822 21:22:30.223368 31324 solver.cpp:433]     Test net output #1: accuracy5 = 0.735139
I0822 21:22:30.223377 31324 solver.cpp:433]     Test net output #2: loss = 2.32852 (* 1 = 2.32852 loss)
I0822 21:22:30.396529 31324 solver.cpp:254] Iteration 14000 (0.570451 iter/s, 35.06s/20 iters), loss = 2.48808
I0822 21:22:30.398977 31324 solver.cpp:273]     Train net output #0: loss = 2.48808 (* 1 = 2.48808 loss)
I0822 21:22:30.399003 31324 sgd_solver.cpp:790] Iteration 14000, lr = 0.01
I0822 21:22:39.729609 31324 solver.cpp:254] Iteration 14020 (2.14349 iter/s, 9.33057s/20 iters), loss = 2.46452
I0822 21:22:39.729779 31324 solver.cpp:273]     Train net output #0: loss = 2.46452 (* 1 = 2.46452 loss)
I0822 21:22:39.729794 31324 sgd_solver.cpp:790] Iteration 14020, lr = 0.01
I0822 21:22:50.101420 31324 solver.cpp:254] Iteration 14040 (1.92835 iter/s, 10.3716s/20 iters), loss = 2.44287
I0822 21:22:50.101501 31324 solver.cpp:273]     Train net output #0: loss = 2.44287 (* 1 = 2.44287 loss)
I0822 21:22:50.101516 31324 sgd_solver.cpp:790] Iteration 14040, lr = 0.01
I0822 21:23:00.677139 31324 solver.cpp:254] Iteration 14060 (1.89115 iter/s, 10.5756s/20 iters), loss = 2.49838
I0822 21:23:00.677202 31324 solver.cpp:273]     Train net output #0: loss = 2.49838 (* 1 = 2.49838 loss)
I0822 21:23:00.677213 31324 sgd_solver.cpp:790] Iteration 14060, lr = 0.01
I0822 21:23:11.323077 31324 solver.cpp:254] Iteration 14080 (1.87868 iter/s, 10.6458s/20 iters), loss = 2.65341
I0822 21:23:11.323228 31324 solver.cpp:273]     Train net output #0: loss = 2.65341 (* 1 = 2.65341 loss)
I0822 21:23:11.323240 31324 sgd_solver.cpp:790] Iteration 14080, lr = 0.01
I0822 21:23:21.835815 31324 solver.cpp:254] Iteration 14100 (1.9025 iter/s, 10.5125s/20 iters), loss = 2.62152
I0822 21:23:21.835886 31324 solver.cpp:273]     Train net output #0: loss = 2.62152 (* 1 = 2.62152 loss)
I0822 21:23:21.835897 31324 sgd_solver.cpp:790] Iteration 14100, lr = 0.01
I0822 21:23:32.143610 31324 solver.cpp:254] Iteration 14120 (1.94031 iter/s, 10.3076s/20 iters), loss = 2.65418
I0822 21:23:32.143687 31324 solver.cpp:273]     Train net output #0: loss = 2.65418 (* 1 = 2.65418 loss)
I0822 21:23:32.143702 31324 sgd_solver.cpp:790] Iteration 14120, lr = 0.01
I0822 21:23:42.812392 31324 solver.cpp:254] Iteration 14140 (1.87466 iter/s, 10.6686s/20 iters), loss = 2.30597
I0822 21:23:42.812549 31324 solver.cpp:273]     Train net output #0: loss = 2.30597 (* 1 = 2.30597 loss)
I0822 21:23:42.812562 31324 sgd_solver.cpp:790] Iteration 14140, lr = 0.01
I0822 21:23:53.431712 31324 solver.cpp:254] Iteration 14160 (1.8834 iter/s, 10.6191s/20 iters), loss = 2.66802
I0822 21:23:53.431783 31324 solver.cpp:273]     Train net output #0: loss = 2.66802 (* 1 = 2.66802 loss)
I0822 21:23:53.431797 31324 sgd_solver.cpp:790] Iteration 14160, lr = 0.01
I0822 21:23:54.886346 31324 blocking_queue.cpp:49] Waiting for data
I0822 21:24:03.639708 31324 solver.cpp:254] Iteration 14180 (1.95928 iter/s, 10.2078s/20 iters), loss = 2.98492
I0822 21:24:03.639786 31324 solver.cpp:273]     Train net output #0: loss = 2.98492 (* 1 = 2.98492 loss)
I0822 21:24:03.639798 31324 sgd_solver.cpp:790] Iteration 14180, lr = 0.01
I0822 21:24:14.140586 31324 solver.cpp:254] Iteration 14200 (1.90463 iter/s, 10.5007s/20 iters), loss = 2.66847
I0822 21:24:14.142891 31324 solver.cpp:273]     Train net output #0: loss = 2.66847 (* 1 = 2.66847 loss)
I0822 21:24:14.142905 31324 sgd_solver.cpp:790] Iteration 14200, lr = 0.01
I0822 21:24:24.688187 31324 solver.cpp:254] Iteration 14220 (1.89659 iter/s, 10.5452s/20 iters), loss = 2.57438
I0822 21:24:24.688274 31324 solver.cpp:273]     Train net output #0: loss = 2.57438 (* 1 = 2.57438 loss)
I0822 21:24:24.688294 31324 sgd_solver.cpp:790] Iteration 14220, lr = 0.01
I0822 21:24:34.957674 31324 solver.cpp:254] Iteration 14240 (1.94755 iter/s, 10.2693s/20 iters), loss = 2.79831
I0822 21:24:34.957734 31324 solver.cpp:273]     Train net output #0: loss = 2.79831 (* 1 = 2.79831 loss)
I0822 21:24:34.957744 31324 sgd_solver.cpp:790] Iteration 14240, lr = 0.01
I0822 21:24:45.575379 31324 solver.cpp:254] Iteration 14260 (1.88367 iter/s, 10.6176s/20 iters), loss = 2.35123
I0822 21:24:45.575534 31324 solver.cpp:273]     Train net output #0: loss = 2.35123 (* 1 = 2.35123 loss)
I0822 21:24:45.575547 31324 sgd_solver.cpp:790] Iteration 14260, lr = 0.01
I0822 21:24:55.825379 31324 solver.cpp:254] Iteration 14280 (1.95126 iter/s, 10.2498s/20 iters), loss = 2.66813
I0822 21:24:55.825487 31324 solver.cpp:273]     Train net output #0: loss = 2.66813 (* 1 = 2.66813 loss)
I0822 21:24:55.825503 31324 sgd_solver.cpp:790] Iteration 14280, lr = 0.01
I0822 21:25:06.294721 31324 solver.cpp:254] Iteration 14300 (1.91037 iter/s, 10.4692s/20 iters), loss = 2.51759
I0822 21:25:06.294780 31324 solver.cpp:273]     Train net output #0: loss = 2.51759 (* 1 = 2.51759 loss)
I0822 21:25:06.294790 31324 sgd_solver.cpp:790] Iteration 14300, lr = 0.01
I0822 21:25:16.585968 31324 solver.cpp:254] Iteration 14320 (1.94342 iter/s, 10.2911s/20 iters), loss = 2.70144
I0822 21:25:16.586098 31324 solver.cpp:273]     Train net output #0: loss = 2.70144 (* 1 = 2.70144 loss)
I0822 21:25:16.586109 31324 sgd_solver.cpp:790] Iteration 14320, lr = 0.01
I0822 21:25:27.212561 31324 solver.cpp:254] Iteration 14340 (1.88211 iter/s, 10.6264s/20 iters), loss = 2.41039
I0822 21:25:27.212623 31324 solver.cpp:273]     Train net output #0: loss = 2.41039 (* 1 = 2.41039 loss)
I0822 21:25:27.212635 31324 sgd_solver.cpp:790] Iteration 14340, lr = 0.01
I0822 21:25:37.828960 31324 solver.cpp:254] Iteration 14360 (1.8839 iter/s, 10.6163s/20 iters), loss = 2.49801
I0822 21:25:37.829027 31324 solver.cpp:273]     Train net output #0: loss = 2.49801 (* 1 = 2.49801 loss)
I0822 21:25:37.829038 31324 sgd_solver.cpp:790] Iteration 14360, lr = 0.01
I0822 21:25:48.384727 31324 solver.cpp:254] Iteration 14380 (1.89473 iter/s, 10.5556s/20 iters), loss = 2.67434
I0822 21:25:48.385422 31324 solver.cpp:273]     Train net output #0: loss = 2.67434 (* 1 = 2.67434 loss)
I0822 21:25:48.385442 31324 sgd_solver.cpp:790] Iteration 14380, lr = 0.01
I0822 21:25:58.958405 31324 solver.cpp:254] Iteration 14400 (1.89163 iter/s, 10.5729s/20 iters), loss = 2.43424
I0822 21:25:58.958482 31324 solver.cpp:273]     Train net output #0: loss = 2.43424 (* 1 = 2.43424 loss)
I0822 21:25:58.958495 31324 sgd_solver.cpp:790] Iteration 14400, lr = 0.01
I0822 21:26:09.286837 31324 solver.cpp:254] Iteration 14420 (1.93643 iter/s, 10.3283s/20 iters), loss = 2.65579
I0822 21:26:09.286916 31324 solver.cpp:273]     Train net output #0: loss = 2.65579 (* 1 = 2.65579 loss)
I0822 21:26:09.286931 31324 sgd_solver.cpp:790] Iteration 14420, lr = 0.01
I0822 21:26:19.541882 31324 solver.cpp:254] Iteration 14440 (1.95029 iter/s, 10.2549s/20 iters), loss = 2.62858
I0822 21:26:19.543295 31324 solver.cpp:273]     Train net output #0: loss = 2.62858 (* 1 = 2.62858 loss)
I0822 21:26:19.543313 31324 sgd_solver.cpp:790] Iteration 14440, lr = 0.01
I0822 21:26:30.221354 31324 solver.cpp:254] Iteration 14460 (1.87301 iter/s, 10.678s/20 iters), loss = 2.45417
I0822 21:26:30.221452 31324 solver.cpp:273]     Train net output #0: loss = 2.45417 (* 1 = 2.45417 loss)
I0822 21:26:30.221472 31324 sgd_solver.cpp:790] Iteration 14460, lr = 0.01
I0822 21:26:40.788983 31324 solver.cpp:254] Iteration 14480 (1.89261 iter/s, 10.5674s/20 iters), loss = 2.25707
I0822 21:26:40.789044 31324 solver.cpp:273]     Train net output #0: loss = 2.25707 (* 1 = 2.25707 loss)
I0822 21:26:40.789057 31324 sgd_solver.cpp:790] Iteration 14480, lr = 0.01
I0822 21:26:51.318126 31324 solver.cpp:254] Iteration 14500 (1.89951 iter/s, 10.529s/20 iters), loss = 2.45878
I0822 21:26:51.320621 31324 solver.cpp:273]     Train net output #0: loss = 2.45878 (* 1 = 2.45878 loss)
I0822 21:26:51.320632 31324 sgd_solver.cpp:790] Iteration 14500, lr = 0.01
I0822 21:27:01.930791 31324 solver.cpp:254] Iteration 14520 (1.885 iter/s, 10.6101s/20 iters), loss = 2.70967
I0822 21:27:01.930852 31324 solver.cpp:273]     Train net output #0: loss = 2.70967 (* 1 = 2.70967 loss)
I0822 21:27:01.930863 31324 sgd_solver.cpp:790] Iteration 14520, lr = 0.01
I0822 21:27:12.619897 31324 solver.cpp:254] Iteration 14540 (1.87109 iter/s, 10.689s/20 iters), loss = 2.49242
I0822 21:27:12.619978 31324 solver.cpp:273]     Train net output #0: loss = 2.49242 (* 1 = 2.49242 loss)
I0822 21:27:12.619994 31324 sgd_solver.cpp:790] Iteration 14540, lr = 0.01
I0822 21:27:23.255213 31324 solver.cpp:254] Iteration 14560 (1.88055 iter/s, 10.6352s/20 iters), loss = 2.71773
I0822 21:27:23.255411 31324 solver.cpp:273]     Train net output #0: loss = 2.71773 (* 1 = 2.71773 loss)
I0822 21:27:23.255427 31324 sgd_solver.cpp:790] Iteration 14560, lr = 0.01
I0822 21:27:33.632944 31324 solver.cpp:254] Iteration 14580 (1.92725 iter/s, 10.3775s/20 iters), loss = 2.53576
I0822 21:27:33.633019 31324 solver.cpp:273]     Train net output #0: loss = 2.53576 (* 1 = 2.53576 loss)
I0822 21:27:33.633034 31324 sgd_solver.cpp:790] Iteration 14580, lr = 0.01
I0822 21:27:42.529806 31324 solver.cpp:254] Iteration 14600 (2.24802 iter/s, 8.89673s/20 iters), loss = 2.58513
I0822 21:27:42.529860 31324 solver.cpp:273]     Train net output #0: loss = 2.58513 (* 1 = 2.58513 loss)
I0822 21:27:42.529870 31324 sgd_solver.cpp:790] Iteration 14600, lr = 0.01
I0822 21:27:51.627228 31324 solver.cpp:254] Iteration 14620 (2.19845 iter/s, 9.0973s/20 iters), loss = 2.44294
I0822 21:27:51.627290 31324 solver.cpp:273]     Train net output #0: loss = 2.44294 (* 1 = 2.44294 loss)
I0822 21:27:51.628051 31324 sgd_solver.cpp:790] Iteration 14620, lr = 0.01
I0822 21:28:01.635190 31324 solver.cpp:254] Iteration 14640 (1.99843 iter/s, 10.0078s/20 iters), loss = 2.28566
I0822 21:28:01.635779 31324 solver.cpp:273]     Train net output #0: loss = 2.28566 (* 1 = 2.28566 loss)
I0822 21:28:01.635794 31324 sgd_solver.cpp:790] Iteration 14640, lr = 0.01
I0822 21:28:12.078755 31324 solver.cpp:254] Iteration 14660 (1.91518 iter/s, 10.4429s/20 iters), loss = 2.63239
I0822 21:28:12.078812 31324 solver.cpp:273]     Train net output #0: loss = 2.63239 (* 1 = 2.63239 loss)
I0822 21:28:12.078822 31324 sgd_solver.cpp:790] Iteration 14660, lr = 0.01
I0822 21:28:22.373543 31324 solver.cpp:254] Iteration 14680 (1.94275 iter/s, 10.2947s/20 iters), loss = 2.52147
I0822 21:28:22.373612 31324 solver.cpp:273]     Train net output #0: loss = 2.52147 (* 1 = 2.52147 loss)
I0822 21:28:22.373630 31324 sgd_solver.cpp:790] Iteration 14680, lr = 0.01
I0822 21:28:32.847221 31324 solver.cpp:254] Iteration 14700 (1.90957 iter/s, 10.4735s/20 iters), loss = 2.65632
I0822 21:28:32.847369 31324 solver.cpp:273]     Train net output #0: loss = 2.65632 (* 1 = 2.65632 loss)
I0822 21:28:32.847381 31324 sgd_solver.cpp:790] Iteration 14700, lr = 0.01
I0822 21:28:42.616928 31324 solver.cpp:254] Iteration 14720 (2.04719 iter/s, 9.7695s/20 iters), loss = 2.7489
I0822 21:28:42.616992 31324 solver.cpp:273]     Train net output #0: loss = 2.7489 (* 1 = 2.7489 loss)
I0822 21:28:42.617003 31324 sgd_solver.cpp:790] Iteration 14720, lr = 0.01
I0822 21:28:52.001929 31324 solver.cpp:254] Iteration 14740 (2.13109 iter/s, 9.38487s/20 iters), loss = 2.15381
I0822 21:28:52.001991 31324 solver.cpp:273]     Train net output #0: loss = 2.15381 (* 1 = 2.15381 loss)
I0822 21:28:52.002004 31324 sgd_solver.cpp:790] Iteration 14740, lr = 0.01
I0822 21:29:00.603992 31324 solver.cpp:254] Iteration 14760 (2.32506 iter/s, 8.60194s/20 iters), loss = 2.76219
I0822 21:29:00.604055 31324 solver.cpp:273]     Train net output #0: loss = 2.76219 (* 1 = 2.76219 loss)
I0822 21:29:00.604069 31324 sgd_solver.cpp:790] Iteration 14760, lr = 0.01
I0822 21:29:09.790488 31324 solver.cpp:254] Iteration 14780 (2.17714 iter/s, 9.18637s/20 iters), loss = 2.47026
I0822 21:29:09.790655 31324 solver.cpp:273]     Train net output #0: loss = 2.47026 (* 1 = 2.47026 loss)
I0822 21:29:09.790670 31324 sgd_solver.cpp:790] Iteration 14780, lr = 0.01
I0822 21:29:18.620898 31324 solver.cpp:254] Iteration 14800 (2.26496 iter/s, 8.83019s/20 iters), loss = 2.47405
I0822 21:29:18.620955 31324 solver.cpp:273]     Train net output #0: loss = 2.47405 (* 1 = 2.47405 loss)
I0822 21:29:18.620965 31324 sgd_solver.cpp:790] Iteration 14800, lr = 0.01
I0822 21:29:27.819790 31324 solver.cpp:254] Iteration 14820 (2.1742 iter/s, 9.19877s/20 iters), loss = 2.18614
I0822 21:29:27.819859 31324 solver.cpp:273]     Train net output #0: loss = 2.18614 (* 1 = 2.18614 loss)
I0822 21:29:27.819875 31324 sgd_solver.cpp:790] Iteration 14820, lr = 0.01
I0822 21:29:37.349740 31324 solver.cpp:254] Iteration 14840 (2.09868 iter/s, 9.52982s/20 iters), loss = 2.60291
I0822 21:29:37.349822 31324 solver.cpp:273]     Train net output #0: loss = 2.60291 (* 1 = 2.60291 loss)
I0822 21:29:37.349831 31324 sgd_solver.cpp:790] Iteration 14840, lr = 0.01
I0822 21:29:47.765242 31324 solver.cpp:254] Iteration 14860 (1.92024 iter/s, 10.4154s/20 iters), loss = 2.3445
I0822 21:29:47.766901 31324 solver.cpp:273]     Train net output #0: loss = 2.3445 (* 1 = 2.3445 loss)
I0822 21:29:47.768576 31324 sgd_solver.cpp:790] Iteration 14860, lr = 0.01
I0822 21:29:58.152920 31324 solver.cpp:254] Iteration 14880 (1.92568 iter/s, 10.386s/20 iters), loss = 2.64283
I0822 21:29:58.152999 31324 solver.cpp:273]     Train net output #0: loss = 2.64283 (* 1 = 2.64283 loss)
I0822 21:29:58.153015 31324 sgd_solver.cpp:790] Iteration 14880, lr = 0.01
I0822 21:30:08.544790 31324 solver.cpp:254] Iteration 14900 (1.92461 iter/s, 10.3917s/20 iters), loss = 2.47775
I0822 21:30:08.544847 31324 solver.cpp:273]     Train net output #0: loss = 2.47775 (* 1 = 2.47775 loss)
I0822 21:30:08.544858 31324 sgd_solver.cpp:790] Iteration 14900, lr = 0.01
I0822 21:30:18.930469 31324 solver.cpp:254] Iteration 14920 (1.92575 iter/s, 10.3856s/20 iters), loss = 2.61006
I0822 21:30:18.930625 31324 solver.cpp:273]     Train net output #0: loss = 2.61006 (* 1 = 2.61006 loss)
I0822 21:30:18.930637 31324 sgd_solver.cpp:790] Iteration 14920, lr = 0.01
I0822 21:30:29.379000 31324 solver.cpp:254] Iteration 14940 (1.91419 iter/s, 10.4483s/20 iters), loss = 2.79293
I0822 21:30:29.379083 31324 solver.cpp:273]     Train net output #0: loss = 2.79293 (* 1 = 2.79293 loss)
I0822 21:30:29.379101 31324 sgd_solver.cpp:790] Iteration 14940, lr = 0.01
I0822 21:30:39.504876 31324 solver.cpp:254] Iteration 14960 (1.97517 iter/s, 10.1257s/20 iters), loss = 2.47387
I0822 21:30:39.504927 31324 solver.cpp:273]     Train net output #0: loss = 2.47387 (* 1 = 2.47387 loss)
I0822 21:30:39.504945 31324 sgd_solver.cpp:790] Iteration 14960, lr = 0.01
I0822 21:30:48.741361 31324 solver.cpp:254] Iteration 14980 (2.16535 iter/s, 9.23637s/20 iters), loss = 2.59707
I0822 21:30:48.741430 31324 solver.cpp:273]     Train net output #0: loss = 2.59707 (* 1 = 2.59707 loss)
I0822 21:30:48.741444 31324 sgd_solver.cpp:790] Iteration 14980, lr = 0.01
I0822 21:30:57.702054 31324 solver.cpp:366] Iteration 15000, Testing net (#0)
I0822 21:31:02.116575 31324 blocking_queue.cpp:49] Waiting for data
I0822 21:31:22.737397 31336 data_layer.cpp:73] Restarting data prefetching from start.
I0822 21:31:22.753408 31324 solver.cpp:433]     Test net output #0: accuracy = 0.47504
I0822 21:31:22.753448 31324 solver.cpp:433]     Test net output #1: accuracy5 = 0.73324
I0822 21:31:22.753458 31324 solver.cpp:433]     Test net output #2: loss = 2.34398 (* 1 = 2.34398 loss)
I0822 21:31:22.920120 31324 solver.cpp:254] Iteration 15000 (0.585163 iter/s, 34.1785s/20 iters), loss = 2.3213
I0822 21:31:22.922519 31324 solver.cpp:273]     Train net output #0: loss = 2.3213 (* 1 = 2.3213 loss)
I0822 21:31:22.922544 31324 sgd_solver.cpp:790] Iteration 15000, lr = 0.01
I0822 21:31:28.552640 31332 data_layer.cpp:73] Restarting data prefetching from start.
I0822 21:31:31.114306 31324 solver.cpp:254] Iteration 15020 (2.44148 iter/s, 8.19174s/20 iters), loss = 2.59451
I0822 21:31:31.114365 31324 solver.cpp:273]     Train net output #0: loss = 2.59451 (* 1 = 2.59451 loss)
I0822 21:31:31.114377 31324 sgd_solver.cpp:790] Iteration 15020, lr = 0.01
I0822 21:31:41.897521 31324 solver.cpp:254] Iteration 15040 (1.85476 iter/s, 10.7831s/20 iters), loss = 2.44499
I0822 21:31:41.897591 31324 solver.cpp:273]     Train net output #0: loss = 2.44499 (* 1 = 2.44499 loss)
I0822 21:31:41.897605 31324 sgd_solver.cpp:790] Iteration 15040, lr = 0.01
I0822 21:31:52.630733 31324 solver.cpp:254] Iteration 15060 (1.8634 iter/s, 10.7331s/20 iters), loss = 2.79851
I0822 21:31:52.630811 31324 solver.cpp:273]     Train net output #0: loss = 2.79851 (* 1 = 2.79851 loss)
I0822 21:31:52.630830 31324 sgd_solver.cpp:790] Iteration 15060, lr = 0.01
I0822 21:32:03.180805 31324 solver.cpp:254] Iteration 15080 (1.89575 iter/s, 10.5499s/20 iters), loss = 2.44225
I0822 21:32:03.180943 31324 solver.cpp:273]     Train net output #0: loss = 2.44225 (* 1 = 2.44225 loss)
I0822 21:32:03.180955 31324 sgd_solver.cpp:790] Iteration 15080, lr = 0.01
I0822 21:32:13.671289 31324 solver.cpp:254] Iteration 15100 (1.90653 iter/s, 10.4903s/20 iters), loss = 2.78535
I0822 21:32:13.671361 31324 solver.cpp:273]     Train net output #0: loss = 2.78535 (* 1 = 2.78535 loss)
I0822 21:32:13.671375 31324 sgd_solver.cpp:790] Iteration 15100, lr = 0.01
I0822 21:32:24.447507 31324 solver.cpp:254] Iteration 15120 (1.85596 iter/s, 10.7761s/20 iters), loss = 2.66482
I0822 21:32:24.447577 31324 solver.cpp:273]     Train net output #0: loss = 2.66482 (* 1 = 2.66482 loss)
I0822 21:32:24.447592 31324 sgd_solver.cpp:790] Iteration 15120, lr = 0.01
I0822 21:32:35.186293 31324 solver.cpp:254] Iteration 15140 (1.86243 iter/s, 10.7386s/20 iters), loss = 2.74422
I0822 21:32:35.186450 31324 solver.cpp:273]     Train net output #0: loss = 2.74422 (* 1 = 2.74422 loss)
I0822 21:32:35.186461 31324 sgd_solver.cpp:790] Iteration 15140, lr = 0.01
I0822 21:32:45.900704 31324 solver.cpp:254] Iteration 15160 (1.86669 iter/s, 10.7142s/20 iters), loss = 2.6371
I0822 21:32:45.900789 31324 solver.cpp:273]     Train net output #0: loss = 2.6371 (* 1 = 2.6371 loss)
I0822 21:32:45.900809 31324 sgd_solver.cpp:790] Iteration 15160, lr = 0.01
I0822 21:32:51.277173 31324 blocking_queue.cpp:49] Waiting for data
I0822 21:32:56.758369 31324 solver.cpp:254] Iteration 15180 (1.84204 iter/s, 10.8575s/20 iters), loss = 2.45343
I0822 21:32:56.758450 31324 solver.cpp:273]     Train net output #0: loss = 2.45343 (* 1 = 2.45343 loss)
I0822 21:32:56.758466 31324 sgd_solver.cpp:790] Iteration 15180, lr = 0.01
I0822 21:33:07.382874 31324 solver.cpp:254] Iteration 15200 (1.88247 iter/s, 10.6244s/20 iters), loss = 2.51093
I0822 21:33:07.383038 31324 solver.cpp:273]     Train net output #0: loss = 2.51093 (* 1 = 2.51093 loss)
I0822 21:33:07.384910 31324 sgd_solver.cpp:790] Iteration 15200, lr = 0.01
I0822 21:33:17.643645 31324 solver.cpp:254] Iteration 15220 (1.94922 iter/s, 10.2605s/20 iters), loss = 2.80203
I0822 21:33:17.643723 31324 solver.cpp:273]     Train net output #0: loss = 2.80203 (* 1 = 2.80203 loss)
I0822 21:33:17.645674 31324 sgd_solver.cpp:790] Iteration 15220, lr = 0.01
I0822 21:33:28.035465 31324 solver.cpp:254] Iteration 15240 (1.92462 iter/s, 10.3917s/20 iters), loss = 2.82447
I0822 21:33:28.035573 31324 solver.cpp:273]     Train net output #0: loss = 2.82447 (* 1 = 2.82447 loss)
I0822 21:33:28.036880 31324 sgd_solver.cpp:790] Iteration 15240, lr = 0.01
I0822 21:33:38.647164 31324 solver.cpp:254] Iteration 15260 (1.88474 iter/s, 10.6115s/20 iters), loss = 2.80195
I0822 21:33:38.647286 31324 solver.cpp:273]     Train net output #0: loss = 2.80195 (* 1 = 2.80195 loss)
I0822 21:33:38.647298 31324 sgd_solver.cpp:790] Iteration 15260, lr = 0.01
I0822 21:33:48.436178 31324 solver.cpp:254] Iteration 15280 (2.04315 iter/s, 9.78881s/20 iters), loss = 2.44374
I0822 21:33:48.436262 31324 solver.cpp:273]     Train net output #0: loss = 2.44374 (* 1 = 2.44374 loss)
I0822 21:33:48.436277 31324 sgd_solver.cpp:790] Iteration 15280, lr = 0.01
I0822 21:33:58.612138 31324 solver.cpp:254] Iteration 15300 (1.96544 iter/s, 10.1758s/20 iters), loss = 2.52873
I0822 21:33:58.612188 31324 solver.cpp:273]     Train net output #0: loss = 2.52873 (* 1 = 2.52873 loss)
I0822 21:33:58.612200 31324 sgd_solver.cpp:790] Iteration 15300, lr = 0.01
I0822 21:34:07.473836 31324 solver.cpp:254] Iteration 15320 (2.25694 iter/s, 8.86157s/20 iters), loss = 2.46512
I0822 21:34:07.473937 31324 solver.cpp:273]     Train net output #0: loss = 2.46512 (* 1 = 2.46512 loss)
I0822 21:34:07.473953 31324 sgd_solver.cpp:790] Iteration 15320, lr = 0.01
I0822 21:34:16.202730 31324 solver.cpp:254] Iteration 15340 (2.29128 iter/s, 8.72873s/20 iters), loss = 2.55415
I0822 21:34:16.202898 31324 solver.cpp:273]     Train net output #0: loss = 2.55415 (* 1 = 2.55415 loss)
I0822 21:34:16.202913 31324 sgd_solver.cpp:790] Iteration 15340, lr = 0.01
I0822 21:34:26.803390 31324 solver.cpp:254] Iteration 15360 (1.88672 iter/s, 10.6004s/20 iters), loss = 2.84736
I0822 21:34:26.803503 31324 solver.cpp:273]     Train net output #0: loss = 2.84736 (* 1 = 2.84736 loss)
I0822 21:34:26.803524 31324 sgd_solver.cpp:790] Iteration 15360, lr = 0.01
I0822 21:34:37.342634 31324 solver.cpp:254] Iteration 15380 (1.8977 iter/s, 10.5391s/20 iters), loss = 2.59038
I0822 21:34:37.342702 31324 solver.cpp:273]     Train net output #0: loss = 2.59038 (* 1 = 2.59038 loss)
I0822 21:34:37.342718 31324 sgd_solver.cpp:790] Iteration 15380, lr = 0.01
I0822 21:34:47.815532 31324 solver.cpp:254] Iteration 15400 (1.90972 iter/s, 10.4728s/20 iters), loss = 2.5664
I0822 21:34:47.815649 31324 solver.cpp:273]     Train net output #0: loss = 2.5664 (* 1 = 2.5664 loss)
I0822 21:34:47.815659 31324 sgd_solver.cpp:790] Iteration 15400, lr = 0.01
I0822 21:34:58.551589 31324 solver.cpp:254] Iteration 15420 (1.86299 iter/s, 10.7354s/20 iters), loss = 2.57081
I0822 21:34:58.551651 31324 solver.cpp:273]     Train net output #0: loss = 2.57081 (* 1 = 2.57081 loss)
I0822 21:34:58.551661 31324 sgd_solver.cpp:790] Iteration 15420, lr = 0.01
I0822 21:35:09.024502 31324 solver.cpp:254] Iteration 15440 (1.90971 iter/s, 10.4728s/20 iters), loss = 2.7736
I0822 21:35:09.024552 31324 solver.cpp:273]     Train net output #0: loss = 2.7736 (* 1 = 2.7736 loss)
I0822 21:35:09.024564 31324 sgd_solver.cpp:790] Iteration 15440, lr = 0.01
I0822 21:35:19.611850 31324 solver.cpp:254] Iteration 15460 (1.88907 iter/s, 10.5872s/20 iters), loss = 2.5961
I0822 21:35:19.612035 31324 solver.cpp:273]     Train net output #0: loss = 2.5961 (* 1 = 2.5961 loss)
I0822 21:35:19.612054 31324 sgd_solver.cpp:790] Iteration 15460, lr = 0.01
I0822 21:35:30.165310 31324 solver.cpp:254] Iteration 15480 (1.89516 iter/s, 10.5532s/20 iters), loss = 2.62188
I0822 21:35:30.165400 31324 solver.cpp:273]     Train net output #0: loss = 2.62188 (* 1 = 2.62188 loss)
I0822 21:35:30.165416 31324 sgd_solver.cpp:790] Iteration 15480, lr = 0.01
I0822 21:35:40.780751 31324 solver.cpp:254] Iteration 15500 (1.88408 iter/s, 10.6153s/20 iters), loss = 2.81654
I0822 21:35:40.780833 31324 solver.cpp:273]     Train net output #0: loss = 2.81654 (* 1 = 2.81654 loss)
I0822 21:35:40.780850 31324 sgd_solver.cpp:790] Iteration 15500, lr = 0.01
I0822 21:35:50.642247 31324 solver.cpp:254] Iteration 15520 (2.02812 iter/s, 9.86135s/20 iters), loss = 2.40895
I0822 21:35:50.642434 31324 solver.cpp:273]     Train net output #0: loss = 2.40895 (* 1 = 2.40895 loss)
I0822 21:35:50.642448 31324 sgd_solver.cpp:790] Iteration 15520, lr = 0.01
I0822 21:35:59.780692 31324 solver.cpp:254] Iteration 15540 (2.18862 iter/s, 9.1382s/20 iters), loss = 2.48785
I0822 21:35:59.780774 31324 solver.cpp:273]     Train net output #0: loss = 2.48785 (* 1 = 2.48785 loss)
I0822 21:35:59.780793 31324 sgd_solver.cpp:790] Iteration 15540, lr = 0.01
I0822 21:36:08.991324 31324 solver.cpp:254] Iteration 15560 (2.17144 iter/s, 9.21049s/20 iters), loss = 2.79242
I0822 21:36:08.991405 31324 solver.cpp:273]     Train net output #0: loss = 2.79242 (* 1 = 2.79242 loss)
I0822 21:36:08.991422 31324 sgd_solver.cpp:790] Iteration 15560, lr = 0.01
I0822 21:36:19.672076 31324 solver.cpp:254] Iteration 15580 (1.87255 iter/s, 10.6806s/20 iters), loss = 2.50936
I0822 21:36:19.672152 31324 solver.cpp:273]     Train net output #0: loss = 2.50936 (* 1 = 2.50936 loss)
I0822 21:36:19.672166 31324 sgd_solver.cpp:790] Iteration 15580, lr = 0.01
I0822 21:36:29.437847 31324 solver.cpp:254] Iteration 15600 (2.048 iter/s, 9.76563s/20 iters), loss = 2.72783
I0822 21:36:29.450023 31324 solver.cpp:273]     Train net output #0: loss = 2.72783 (* 1 = 2.72783 loss)
I0822 21:36:29.450059 31324 sgd_solver.cpp:790] Iteration 15600, lr = 0.01
I0822 21:36:33.225118 31324 solver.cpp:254] Iteration 15620 (5.2979 iter/s, 3.77508s/20 iters), loss = 2.72875
I0822 21:36:33.225194 31324 solver.cpp:273]     Train net output #0: loss = 2.72875 (* 1 = 2.72875 loss)
I0822 21:36:33.225212 31324 sgd_solver.cpp:790] Iteration 15620, lr = 0.01
I0822 21:36:37.058894 31324 solver.cpp:254] Iteration 15640 (5.21695 iter/s, 3.83366s/20 iters), loss = 2.52096
I0822 21:36:37.071086 31324 solver.cpp:273]     Train net output #0: loss = 2.52096 (* 1 = 2.52096 loss)
I0822 21:36:37.071121 31324 sgd_solver.cpp:790] Iteration 15640, lr = 0.01
I0822 21:36:40.767129 31324 solver.cpp:254] Iteration 15660 (5.4112 iter/s, 3.69603s/20 iters), loss = 2.43615
I0822 21:36:40.779278 31324 solver.cpp:273]     Train net output #0: loss = 2.43615 (* 1 = 2.43615 loss)
I0822 21:36:40.779307 31324 sgd_solver.cpp:790] Iteration 15660, lr = 0.01
I0822 21:36:44.445842 31324 solver.cpp:254] Iteration 15680 (5.45472 iter/s, 3.66655s/20 iters), loss = 2.61555
I0822 21:36:44.458189 31324 solver.cpp:273]     Train net output #0: loss = 2.61555 (* 1 = 2.61555 loss)
I0822 21:36:44.458223 31324 sgd_solver.cpp:790] Iteration 15680, lr = 0.01
I0822 21:36:48.111341 31324 solver.cpp:254] Iteration 15700 (5.47474 iter/s, 3.65314s/20 iters), loss = 2.54917
I0822 21:36:48.123507 31324 solver.cpp:273]     Train net output #0: loss = 2.54917 (* 1 = 2.54917 loss)
I0822 21:36:48.123539 31324 sgd_solver.cpp:790] Iteration 15700, lr = 0.01
I0822 21:36:54.388799 31324 solver.cpp:254] Iteration 15720 (3.1922 iter/s, 6.26527s/20 iters), loss = 2.23787
I0822 21:36:54.388885 31324 solver.cpp:273]     Train net output #0: loss = 2.23787 (* 1 = 2.23787 loss)
I0822 21:36:54.388897 31324 sgd_solver.cpp:790] Iteration 15720, lr = 0.01
I0822 21:36:58.590951 31324 solver.cpp:254] Iteration 15740 (4.75959 iter/s, 4.20204s/20 iters), loss = 2.60793
I0822 21:36:58.603116 31324 solver.cpp:273]     Train net output #0: loss = 2.60793 (* 1 = 2.60793 loss)
I0822 21:36:58.603147 31324 sgd_solver.cpp:790] Iteration 15740, lr = 0.01
I0822 21:37:02.220692 31324 solver.cpp:254] Iteration 15760 (5.5286 iter/s, 3.61755s/20 iters), loss = 2.601
I0822 21:37:02.233311 31324 solver.cpp:273]     Train net output #0: loss = 2.601 (* 1 = 2.601 loss)
I0822 21:37:02.233348 31324 sgd_solver.cpp:790] Iteration 15760, lr = 0.01
I0822 21:37:05.864653 31324 solver.cpp:254] Iteration 15780 (5.50763 iter/s, 3.63133s/20 iters), loss = 2.58502
I0822 21:37:05.877228 31324 solver.cpp:273]     Train net output #0: loss = 2.58502 (* 1 = 2.58502 loss)
I0822 21:37:05.877255 31324 sgd_solver.cpp:790] Iteration 15780, lr = 0.01
I0822 21:37:11.820787 31324 solver.cpp:254] Iteration 15800 (3.365 iter/s, 5.94354s/20 iters), loss = 2.54572
I0822 21:37:11.820863 31324 solver.cpp:273]     Train net output #0: loss = 2.54572 (* 1 = 2.54572 loss)
I0822 21:37:11.820876 31324 sgd_solver.cpp:790] Iteration 15800, lr = 0.01
I0822 21:37:22.095393 31324 solver.cpp:254] Iteration 15820 (1.94657 iter/s, 10.2745s/20 iters), loss = 2.5875
I0822 21:37:22.095464 31324 solver.cpp:273]     Train net output #0: loss = 2.5875 (* 1 = 2.5875 loss)
I0822 21:37:22.095479 31324 sgd_solver.cpp:790] Iteration 15820, lr = 0.01
I0822 21:37:32.651566 31324 solver.cpp:254] Iteration 15840 (1.89465 iter/s, 10.556s/20 iters), loss = 2.57303
I0822 21:37:32.653671 31324 solver.cpp:273]     Train net output #0: loss = 2.57303 (* 1 = 2.57303 loss)
I0822 21:37:32.653687 31324 sgd_solver.cpp:790] Iteration 15840, lr = 0.01
I0822 21:37:43.148959 31324 solver.cpp:254] Iteration 15860 (1.90563 iter/s, 10.4952s/20 iters), loss = 2.47857
I0822 21:37:43.149044 31324 solver.cpp:273]     Train net output #0: loss = 2.47857 (* 1 = 2.47857 loss)
I0822 21:37:43.149056 31324 sgd_solver.cpp:790] Iteration 15860, lr = 0.01
I0822 21:37:53.605160 31324 solver.cpp:254] Iteration 15880 (1.91277 iter/s, 10.456s/20 iters), loss = 2.76551
I0822 21:37:53.605248 31324 solver.cpp:273]     Train net output #0: loss = 2.76551 (* 1 = 2.76551 loss)
I0822 21:37:53.605263 31324 sgd_solver.cpp:790] Iteration 15880, lr = 0.01
I0822 21:38:02.911296 31324 solver.cpp:254] Iteration 15900 (2.14915 iter/s, 9.30598s/20 iters), loss = 2.32709
I0822 21:38:02.911437 31324 solver.cpp:273]     Train net output #0: loss = 2.32709 (* 1 = 2.32709 loss)
I0822 21:38:02.911453 31324 sgd_solver.cpp:790] Iteration 15900, lr = 0.01
I0822 21:38:11.952121 31324 solver.cpp:254] Iteration 15920 (2.21224 iter/s, 9.04062s/20 iters), loss = 2.67524
I0822 21:38:11.952179 31324 solver.cpp:273]     Train net output #0: loss = 2.67524 (* 1 = 2.67524 loss)
I0822 21:38:11.952189 31324 sgd_solver.cpp:790] Iteration 15920, lr = 0.01
I0822 21:38:20.852969 31324 solver.cpp:254] Iteration 15940 (2.24701 iter/s, 8.90072s/20 iters), loss = 2.53768
I0822 21:38:20.853044 31324 solver.cpp:273]     Train net output #0: loss = 2.53768 (* 1 = 2.53768 loss)
I0822 21:38:20.853056 31324 sgd_solver.cpp:790] Iteration 15940, lr = 0.01
I0822 21:38:31.105201 31324 solver.cpp:254] Iteration 15960 (1.95083 iter/s, 10.2521s/20 iters), loss = 2.48434
I0822 21:38:31.105286 31324 solver.cpp:273]     Train net output #0: loss = 2.48434 (* 1 = 2.48434 loss)
I0822 21:38:31.105301 31324 sgd_solver.cpp:790] Iteration 15960, lr = 0.01
I0822 21:38:41.408788 31324 solver.cpp:254] Iteration 15980 (1.9411 iter/s, 10.3034s/20 iters), loss = 2.56953
I0822 21:38:41.409245 31324 solver.cpp:273]     Train net output #0: loss = 2.56953 (* 1 = 2.56953 loss)
I0822 21:38:41.409267 31324 sgd_solver.cpp:790] Iteration 15980, lr = 0.01
I0822 21:38:51.124967 31324 solver.cpp:366] Iteration 16000, Testing net (#0)
I0822 21:38:56.121242 31324 blocking_queue.cpp:49] Waiting for data
I0822 21:39:15.680579 31336 data_layer.cpp:73] Restarting data prefetching from start.
I0822 21:39:15.697216 31324 solver.cpp:433]     Test net output #0: accuracy = 0.4716
I0822 21:39:15.697255 31324 solver.cpp:433]     Test net output #1: accuracy5 = 0.7274
I0822 21:39:15.697265 31324 solver.cpp:433]     Test net output #2: loss = 2.35272 (* 1 = 2.35272 loss)
I0822 21:39:15.876503 31324 solver.cpp:254] Iteration 16000 (0.580264 iter/s, 34.4671s/20 iters), loss = 2.53474
I0822 21:39:15.878937 31324 solver.cpp:273]     Train net output #0: loss = 2.53474 (* 1 = 2.53474 loss)
I0822 21:39:15.878969 31324 sgd_solver.cpp:790] Iteration 16000, lr = 0.01
I0822 21:39:23.952801 31324 solver.cpp:254] Iteration 16020 (2.47714 iter/s, 8.07382s/20 iters), loss = 2.64956
I0822 21:39:23.952863 31324 solver.cpp:273]     Train net output #0: loss = 2.64956 (* 1 = 2.64956 loss)
I0822 21:39:23.952875 31324 sgd_solver.cpp:790] Iteration 16020, lr = 0.01
I0822 21:39:32.942163 31324 solver.cpp:254] Iteration 16040 (2.22488 iter/s, 8.98924s/20 iters), loss = 2.79259
I0822 21:39:32.942221 31324 solver.cpp:273]     Train net output #0: loss = 2.79259 (* 1 = 2.79259 loss)
I0822 21:39:32.942232 31324 sgd_solver.cpp:790] Iteration 16040, lr = 0.01
I0822 21:39:42.505020 31324 solver.cpp:254] Iteration 16060 (2.09145 iter/s, 9.56273s/20 iters), loss = 2.44829
I0822 21:39:42.505091 31324 solver.cpp:273]     Train net output #0: loss = 2.44829 (* 1 = 2.44829 loss)
I0822 21:39:42.505105 31324 sgd_solver.cpp:790] Iteration 16060, lr = 0.01
I0822 21:39:52.982666 31324 solver.cpp:254] Iteration 16080 (1.90885 iter/s, 10.4775s/20 iters), loss = 2.57029
I0822 21:39:52.983675 31324 solver.cpp:273]     Train net output #0: loss = 2.57029 (* 1 = 2.57029 loss)
I0822 21:39:52.983690 31324 sgd_solver.cpp:790] Iteration 16080, lr = 0.01
I0822 21:40:03.399982 31324 solver.cpp:254] Iteration 16100 (1.92008 iter/s, 10.4162s/20 iters), loss = 2.46746
I0822 21:40:03.400053 31324 solver.cpp:273]     Train net output #0: loss = 2.46746 (* 1 = 2.46746 loss)
I0822 21:40:03.400068 31324 sgd_solver.cpp:790] Iteration 16100, lr = 0.01
I0822 21:40:14.074601 31324 solver.cpp:254] Iteration 16120 (1.87363 iter/s, 10.6745s/20 iters), loss = 2.65148
I0822 21:40:14.074676 31324 solver.cpp:273]     Train net output #0: loss = 2.65148 (* 1 = 2.65148 loss)
I0822 21:40:14.074687 31324 sgd_solver.cpp:790] Iteration 16120, lr = 0.01
I0822 21:40:24.482468 31324 solver.cpp:254] Iteration 16140 (1.92165 iter/s, 10.4077s/20 iters), loss = 2.39083
I0822 21:40:24.482652 31324 solver.cpp:273]     Train net output #0: loss = 2.39083 (* 1 = 2.39083 loss)
I0822 21:40:24.482671 31324 sgd_solver.cpp:790] Iteration 16140, lr = 0.01
I0822 21:40:35.071768 31324 solver.cpp:254] Iteration 16160 (1.88875 iter/s, 10.589s/20 iters), loss = 2.53923
I0822 21:40:35.071873 31324 solver.cpp:273]     Train net output #0: loss = 2.53923 (* 1 = 2.53923 loss)
I0822 21:40:35.071900 31324 sgd_solver.cpp:790] Iteration 16160, lr = 0.01
I0822 21:40:45.571768 31324 solver.cpp:254] Iteration 16180 (1.90479 iter/s, 10.4998s/20 iters), loss = 2.6639
I0822 21:40:45.571840 31324 solver.cpp:273]     Train net output #0: loss = 2.6639 (* 1 = 2.6639 loss)
I0822 21:40:45.571856 31324 sgd_solver.cpp:790] Iteration 16180, lr = 0.01
I0822 21:40:48.654260 31324 blocking_queue.cpp:49] Waiting for data
I0822 21:40:56.042500 31324 solver.cpp:254] Iteration 16200 (1.91011 iter/s, 10.4706s/20 iters), loss = 2.44632
I0822 21:40:56.042695 31324 solver.cpp:273]     Train net output #0: loss = 2.44632 (* 1 = 2.44632 loss)
I0822 21:40:56.042712 31324 sgd_solver.cpp:790] Iteration 16200, lr = 0.01
I0822 21:41:06.369457 31324 solver.cpp:254] Iteration 16220 (1.93673 iter/s, 10.3267s/20 iters), loss = 2.74126
I0822 21:41:06.369530 31324 solver.cpp:273]     Train net output #0: loss = 2.74126 (* 1 = 2.74126 loss)
I0822 21:41:06.369546 31324 sgd_solver.cpp:790] Iteration 16220, lr = 0.01
I0822 21:41:17.099565 31324 solver.cpp:254] Iteration 16240 (1.86394 iter/s, 10.73s/20 iters), loss = 2.38679
I0822 21:41:17.099647 31324 solver.cpp:273]     Train net output #0: loss = 2.38679 (* 1 = 2.38679 loss)
I0822 21:41:17.099663 31324 sgd_solver.cpp:790] Iteration 16240, lr = 0.01
I0822 21:41:27.727933 31324 solver.cpp:254] Iteration 16260 (1.88178 iter/s, 10.6282s/20 iters), loss = 2.61809
I0822 21:41:27.728116 31324 solver.cpp:273]     Train net output #0: loss = 2.61809 (* 1 = 2.61809 loss)
I0822 21:41:27.728132 31324 sgd_solver.cpp:790] Iteration 16260, lr = 0.01
I0822 21:41:38.293336 31324 solver.cpp:254] Iteration 16280 (1.89302 iter/s, 10.5652s/20 iters), loss = 2.61247
I0822 21:41:38.293401 31324 solver.cpp:273]     Train net output #0: loss = 2.61247 (* 1 = 2.61247 loss)
I0822 21:41:38.293411 31324 sgd_solver.cpp:790] Iteration 16280, lr = 0.01
I0822 21:41:49.181152 31324 solver.cpp:254] Iteration 16300 (1.83694 iter/s, 10.8877s/20 iters), loss = 2.71963
I0822 21:41:49.181221 31324 solver.cpp:273]     Train net output #0: loss = 2.71963 (* 1 = 2.71963 loss)
I0822 21:41:49.181234 31324 sgd_solver.cpp:790] Iteration 16300, lr = 0.01
I0822 21:41:59.641242 31324 solver.cpp:254] Iteration 16320 (1.91205 iter/s, 10.46s/20 iters), loss = 2.52073
I0822 21:41:59.641418 31324 solver.cpp:273]     Train net output #0: loss = 2.52073 (* 1 = 2.52073 loss)
I0822 21:41:59.642122 31324 sgd_solver.cpp:790] Iteration 16320, lr = 0.01
I0822 21:42:10.066864 31324 solver.cpp:254] Iteration 16340 (1.9184 iter/s, 10.4254s/20 iters), loss = 2.24799
I0822 21:42:10.066939 31324 solver.cpp:273]     Train net output #0: loss = 2.24799 (* 1 = 2.24799 loss)
I0822 21:42:10.066951 31324 sgd_solver.cpp:790] Iteration 16340, lr = 0.01
I0822 21:42:20.554808 31324 solver.cpp:254] Iteration 16360 (1.90698 iter/s, 10.4878s/20 iters), loss = 2.46183
I0822 21:42:20.554877 31324 solver.cpp:273]     Train net output #0: loss = 2.46183 (* 1 = 2.46183 loss)
I0822 21:42:20.556089 31324 sgd_solver.cpp:790] Iteration 16360, lr = 0.01
I0822 21:42:31.156178 31324 solver.cpp:254] Iteration 16380 (1.88657 iter/s, 10.6012s/20 iters), loss = 2.69762
I0822 21:42:31.161826 31324 solver.cpp:273]     Train net output #0: loss = 2.69762 (* 1 = 2.69762 loss)
I0822 21:42:31.161844 31324 sgd_solver.cpp:790] Iteration 16380, lr = 0.01
I0822 21:42:41.716348 31324 solver.cpp:254] Iteration 16400 (1.89493 iter/s, 10.5545s/20 iters), loss = 2.43697
I0822 21:42:41.716406 31324 solver.cpp:273]     Train net output #0: loss = 2.43697 (* 1 = 2.43697 loss)
I0822 21:42:41.716416 31324 sgd_solver.cpp:790] Iteration 16400, lr = 0.01
I0822 21:42:52.487579 31324 solver.cpp:254] Iteration 16420 (1.85682 iter/s, 10.7711s/20 iters), loss = 2.62163
I0822 21:42:52.487640 31324 solver.cpp:273]     Train net output #0: loss = 2.62163 (* 1 = 2.62163 loss)
I0822 21:42:52.487651 31324 sgd_solver.cpp:790] Iteration 16420, lr = 0.01
I0822 21:43:03.233430 31324 solver.cpp:254] Iteration 16440 (1.86121 iter/s, 10.7457s/20 iters), loss = 2.64365
I0822 21:43:03.236510 31324 solver.cpp:273]     Train net output #0: loss = 2.64365 (* 1 = 2.64365 loss)
I0822 21:43:03.236524 31324 sgd_solver.cpp:790] Iteration 16440, lr = 0.01
I0822 21:43:13.779655 31324 solver.cpp:254] Iteration 16460 (1.89698 iter/s, 10.5431s/20 iters), loss = 2.56683
I0822 21:43:13.779718 31324 solver.cpp:273]     Train net output #0: loss = 2.56683 (* 1 = 2.56683 loss)
I0822 21:43:13.779728 31324 sgd_solver.cpp:790] Iteration 16460, lr = 0.01
I0822 21:43:24.091926 31324 solver.cpp:254] Iteration 16480 (1.93946 iter/s, 10.3121s/20 iters), loss = 2.7877
I0822 21:43:24.091995 31324 solver.cpp:273]     Train net output #0: loss = 2.7877 (* 1 = 2.7877 loss)
I0822 21:43:24.092007 31324 sgd_solver.cpp:790] Iteration 16480, lr = 0.01
I0822 21:43:33.219074 31324 solver.cpp:254] Iteration 16500 (2.1913 iter/s, 9.12702s/20 iters), loss = 2.49719
I0822 21:43:33.219151 31324 solver.cpp:273]     Train net output #0: loss = 2.49719 (* 1 = 2.49719 loss)
I0822 21:43:33.219164 31324 sgd_solver.cpp:790] Iteration 16500, lr = 0.01
I0822 21:43:42.518249 31324 solver.cpp:254] Iteration 16520 (2.15076 iter/s, 9.29904s/20 iters), loss = 2.41417
I0822 21:43:42.519431 31324 solver.cpp:273]     Train net output #0: loss = 2.41417 (* 1 = 2.41417 loss)
I0822 21:43:42.519448 31324 sgd_solver.cpp:790] Iteration 16520, lr = 0.01
I0822 21:43:52.645092 31324 solver.cpp:254] Iteration 16540 (1.97519 iter/s, 10.1256s/20 iters), loss = 2.68634
I0822 21:43:52.645162 31324 solver.cpp:273]     Train net output #0: loss = 2.68634 (* 1 = 2.68634 loss)
I0822 21:43:52.645175 31324 sgd_solver.cpp:790] Iteration 16540, lr = 0.01
I0822 21:44:02.085777 31324 solver.cpp:254] Iteration 16560 (2.11852 iter/s, 9.44055s/20 iters), loss = 2.57892
I0822 21:44:02.085839 31324 solver.cpp:273]     Train net output #0: loss = 2.57892 (* 1 = 2.57892 loss)
I0822 21:44:02.085852 31324 sgd_solver.cpp:790] Iteration 16560, lr = 0.01
I0822 21:44:12.541793 31324 solver.cpp:254] Iteration 16580 (1.9128 iter/s, 10.4559s/20 iters), loss = 2.64879
I0822 21:44:12.542825 31324 solver.cpp:273]     Train net output #0: loss = 2.64879 (* 1 = 2.64879 loss)
I0822 21:44:12.542843 31324 sgd_solver.cpp:790] Iteration 16580, lr = 0.01
I0822 21:44:23.095037 31324 solver.cpp:254] Iteration 16600 (1.89535 iter/s, 10.5521s/20 iters), loss = 2.66909
I0822 21:44:23.095099 31324 solver.cpp:273]     Train net output #0: loss = 2.66909 (* 1 = 2.66909 loss)
I0822 21:44:23.095111 31324 sgd_solver.cpp:790] Iteration 16600, lr = 0.01
I0822 21:44:33.140555 31324 solver.cpp:254] Iteration 16620 (1.99096 iter/s, 10.0454s/20 iters), loss = 2.66448
I0822 21:44:33.140630 31324 solver.cpp:273]     Train net output #0: loss = 2.66448 (* 1 = 2.66448 loss)
I0822 21:44:33.140643 31324 sgd_solver.cpp:790] Iteration 16620, lr = 0.01
I0822 21:44:41.857344 31324 solver.cpp:254] Iteration 16640 (2.29446 iter/s, 8.71666s/20 iters), loss = 2.64536
I0822 21:44:41.857405 31324 solver.cpp:273]     Train net output #0: loss = 2.64536 (* 1 = 2.64536 loss)
I0822 21:44:41.857417 31324 sgd_solver.cpp:790] Iteration 16640, lr = 0.01
I0822 21:44:50.597786 31324 solver.cpp:254] Iteration 16660 (2.28824 iter/s, 8.74032s/20 iters), loss = 2.61153
I0822 21:44:50.598489 31324 solver.cpp:273]     Train net output #0: loss = 2.61153 (* 1 = 2.61153 loss)
I0822 21:44:50.598505 31324 sgd_solver.cpp:790] Iteration 16660, lr = 0.01
I0822 21:45:00.697021 31324 solver.cpp:254] Iteration 16680 (1.9805 iter/s, 10.0985s/20 iters), loss = 2.42113
I0822 21:45:00.697089 31324 solver.cpp:273]     Train net output #0: loss = 2.42113 (* 1 = 2.42113 loss)
I0822 21:45:00.697103 31324 sgd_solver.cpp:790] Iteration 16680, lr = 0.01
I0822 21:45:11.445365 31324 solver.cpp:254] Iteration 16700 (1.86077 iter/s, 10.7482s/20 iters), loss = 2.85168
I0822 21:45:11.445422 31324 solver.cpp:273]     Train net output #0: loss = 2.85168 (* 1 = 2.85168 loss)
I0822 21:45:11.445437 31324 sgd_solver.cpp:790] Iteration 16700, lr = 0.01
I0822 21:45:22.071250 31324 solver.cpp:254] Iteration 16720 (1.88222 iter/s, 10.6258s/20 iters), loss = 2.44855
I0822 21:45:22.071414 31324 solver.cpp:273]     Train net output #0: loss = 2.44855 (* 1 = 2.44855 loss)
I0822 21:45:22.071437 31324 sgd_solver.cpp:790] Iteration 16720, lr = 0.01
I0822 21:45:32.144125 31324 solver.cpp:254] Iteration 16740 (1.98557 iter/s, 10.0726s/20 iters), loss = 2.76554
I0822 21:45:32.144207 31324 solver.cpp:273]     Train net output #0: loss = 2.76554 (* 1 = 2.76554 loss)
I0822 21:45:32.144222 31324 sgd_solver.cpp:790] Iteration 16740, lr = 0.01
I0822 21:45:42.622520 31324 solver.cpp:254] Iteration 16760 (1.90872 iter/s, 10.4783s/20 iters), loss = 2.42879
I0822 21:45:42.622586 31324 solver.cpp:273]     Train net output #0: loss = 2.42879 (* 1 = 2.42879 loss)
I0822 21:45:42.622597 31324 sgd_solver.cpp:790] Iteration 16760, lr = 0.01
I0822 21:45:52.086767 31324 solver.cpp:254] Iteration 16780 (2.11324 iter/s, 9.46412s/20 iters), loss = 2.5216
I0822 21:45:52.086911 31324 solver.cpp:273]     Train net output #0: loss = 2.5216 (* 1 = 2.5216 loss)
I0822 21:45:52.086922 31324 sgd_solver.cpp:790] Iteration 16780, lr = 0.01
I0822 21:46:00.836895 31324 solver.cpp:254] Iteration 16800 (2.28573 iter/s, 8.74992s/20 iters), loss = 2.64682
I0822 21:46:00.836963 31324 solver.cpp:273]     Train net output #0: loss = 2.64682 (* 1 = 2.64682 loss)
I0822 21:46:00.836977 31324 sgd_solver.cpp:790] Iteration 16800, lr = 0.01
I0822 21:46:09.594369 31324 solver.cpp:254] Iteration 16820 (2.2838 iter/s, 8.75735s/20 iters), loss = 2.28687
I0822 21:46:09.594426 31324 solver.cpp:273]     Train net output #0: loss = 2.28687 (* 1 = 2.28687 loss)
I0822 21:46:09.594437 31324 sgd_solver.cpp:790] Iteration 16820, lr = 0.01
I0822 21:46:20.169867 31324 solver.cpp:254] Iteration 16840 (1.89119 iter/s, 10.5754s/20 iters), loss = 2.32423
I0822 21:46:20.169920 31324 solver.cpp:273]     Train net output #0: loss = 2.32423 (* 1 = 2.32423 loss)
I0822 21:46:20.169931 31324 sgd_solver.cpp:790] Iteration 16840, lr = 0.01
I0822 21:46:30.637449 31324 solver.cpp:254] Iteration 16860 (1.91068 iter/s, 10.4675s/20 iters), loss = 2.47015
I0822 21:46:30.642019 31324 solver.cpp:273]     Train net output #0: loss = 2.47015 (* 1 = 2.47015 loss)
I0822 21:46:30.643008 31324 sgd_solver.cpp:790] Iteration 16860, lr = 0.01
I0822 21:46:41.275328 31324 solver.cpp:254] Iteration 16880 (1.88089 iter/s, 10.6333s/20 iters), loss = 2.57596
I0822 21:46:41.275388 31324 solver.cpp:273]     Train net output #0: loss = 2.57596 (* 1 = 2.57596 loss)
I0822 21:46:41.275398 31324 sgd_solver.cpp:790] Iteration 16880, lr = 0.01
I0822 21:46:51.837888 31324 solver.cpp:254] Iteration 16900 (1.8935 iter/s, 10.5624s/20 iters), loss = 2.63196
I0822 21:46:51.837946 31324 solver.cpp:273]     Train net output #0: loss = 2.63196 (* 1 = 2.63196 loss)
I0822 21:46:51.837957 31324 sgd_solver.cpp:790] Iteration 16900, lr = 0.01
I0822 21:47:02.362220 31324 solver.cpp:254] Iteration 16920 (1.90038 iter/s, 10.5242s/20 iters), loss = 2.61896
I0822 21:47:02.362382 31324 solver.cpp:273]     Train net output #0: loss = 2.61896 (* 1 = 2.61896 loss)
I0822 21:47:02.362395 31324 sgd_solver.cpp:790] Iteration 16920, lr = 0.01
I0822 21:47:12.622843 31324 solver.cpp:254] Iteration 16940 (1.94924 iter/s, 10.2604s/20 iters), loss = 2.50082
I0822 21:47:12.622905 31324 solver.cpp:273]     Train net output #0: loss = 2.50082 (* 1 = 2.50082 loss)
I0822 21:47:12.622916 31324 sgd_solver.cpp:790] Iteration 16940, lr = 0.01
I0822 21:47:23.020491 31324 solver.cpp:254] Iteration 16960 (1.92354 iter/s, 10.3975s/20 iters), loss = 2.32577
I0822 21:47:23.020563 31324 solver.cpp:273]     Train net output #0: loss = 2.32577 (* 1 = 2.32577 loss)
I0822 21:47:23.020576 31324 sgd_solver.cpp:790] Iteration 16960, lr = 0.01
I0822 21:47:33.386759 31324 solver.cpp:254] Iteration 16980 (1.92936 iter/s, 10.3661s/20 iters), loss = 2.56695
I0822 21:47:33.388674 31324 solver.cpp:273]     Train net output #0: loss = 2.56695 (* 1 = 2.56695 loss)
I0822 21:47:33.388687 31324 sgd_solver.cpp:790] Iteration 16980, lr = 0.01
I0822 21:47:43.172328 31324 solver.cpp:366] Iteration 17000, Testing net (#0)
I0822 21:47:47.674800 31324 blocking_queue.cpp:49] Waiting for data
I0822 21:48:07.009719 31336 data_layer.cpp:73] Restarting data prefetching from start.
I0822 21:48:07.026317 31324 solver.cpp:433]     Test net output #0: accuracy = 0.47388
I0822 21:48:07.026371 31324 solver.cpp:433]     Test net output #1: accuracy5 = 0.731619
I0822 21:48:07.026384 31324 solver.cpp:433]     Test net output #2: loss = 2.32585 (* 1 = 2.32585 loss)
I0822 21:48:07.204991 31324 solver.cpp:254] Iteration 17000 (0.591433 iter/s, 33.8162s/20 iters), loss = 2.55579
I0822 21:48:07.207428 31324 solver.cpp:273]     Train net output #0: loss = 2.55579 (* 1 = 2.55579 loss)
I0822 21:48:07.207456 31324 sgd_solver.cpp:790] Iteration 17000, lr = 0.01
I0822 21:48:15.118348 31324 solver.cpp:254] Iteration 17020 (2.52817 iter/s, 7.91087s/20 iters), loss = 2.49799
I0822 21:48:15.118417 31324 solver.cpp:273]     Train net output #0: loss = 2.49799 (* 1 = 2.49799 loss)
I0822 21:48:15.118427 31324 sgd_solver.cpp:790] Iteration 17020, lr = 0.01
I0822 21:48:23.976845 31324 solver.cpp:254] Iteration 17040 (2.25781 iter/s, 8.85816s/20 iters), loss = 2.42449
I0822 21:48:23.976914 31324 solver.cpp:273]     Train net output #0: loss = 2.42449 (* 1 = 2.42449 loss)
I0822 21:48:23.976927 31324 sgd_solver.cpp:790] Iteration 17040, lr = 0.01
I0822 21:48:34.002696 31324 solver.cpp:254] Iteration 17060 (1.99487 iter/s, 10.0257s/20 iters), loss = 2.39239
I0822 21:48:34.002784 31324 solver.cpp:273]     Train net output #0: loss = 2.39239 (* 1 = 2.39239 loss)
I0822 21:48:34.002801 31324 sgd_solver.cpp:790] Iteration 17060, lr = 0.01
I0822 21:48:44.655966 31324 solver.cpp:254] Iteration 17080 (1.87739 iter/s, 10.6531s/20 iters), loss = 2.35542
I0822 21:48:44.656179 31324 solver.cpp:273]     Train net output #0: loss = 2.35542 (* 1 = 2.35542 loss)
I0822 21:48:44.656196 31324 sgd_solver.cpp:790] Iteration 17080, lr = 0.01
I0822 21:48:55.343333 31324 solver.cpp:254] Iteration 17100 (1.87142 iter/s, 10.6871s/20 iters), loss = 2.68054
I0822 21:48:55.343400 31324 solver.cpp:273]     Train net output #0: loss = 2.68054 (* 1 = 2.68054 loss)
I0822 21:48:55.343411 31324 sgd_solver.cpp:790] Iteration 17100, lr = 0.01
I0822 21:49:05.915593 31324 solver.cpp:254] Iteration 17120 (1.89177 iter/s, 10.5721s/20 iters), loss = 2.74818
I0822 21:49:05.915669 31324 solver.cpp:273]     Train net output #0: loss = 2.74818 (* 1 = 2.74818 loss)
I0822 21:49:05.915683 31324 sgd_solver.cpp:790] Iteration 17120, lr = 0.01
I0822 21:49:16.523437 31324 solver.cpp:254] Iteration 17140 (1.88542 iter/s, 10.6077s/20 iters), loss = 2.4996
I0822 21:49:16.523640 31324 solver.cpp:273]     Train net output #0: loss = 2.4996 (* 1 = 2.4996 loss)
I0822 21:49:16.523665 31324 sgd_solver.cpp:790] Iteration 17140, lr = 0.01
I0822 21:49:26.893221 31324 solver.cpp:254] Iteration 17160 (1.92873 iter/s, 10.3695s/20 iters), loss = 2.67403
I0822 21:49:26.893304 31324 solver.cpp:273]     Train net output #0: loss = 2.67403 (* 1 = 2.67403 loss)
I0822 21:49:26.893329 31324 sgd_solver.cpp:790] Iteration 17160, lr = 0.01
I0822 21:49:37.445354 31324 solver.cpp:254] Iteration 17180 (1.89538 iter/s, 10.552s/20 iters), loss = 2.4488
I0822 21:49:37.445420 31324 solver.cpp:273]     Train net output #0: loss = 2.4488 (* 1 = 2.4488 loss)
I0822 21:49:37.445432 31324 sgd_solver.cpp:790] Iteration 17180, lr = 0.01
I0822 21:49:44.744336 31324 blocking_queue.cpp:49] Waiting for data
I0822 21:49:47.971418 31324 solver.cpp:254] Iteration 17200 (1.90007 iter/s, 10.5259s/20 iters), loss = 2.25743
I0822 21:49:47.977254 31324 solver.cpp:273]     Train net output #0: loss = 2.25743 (* 1 = 2.25743 loss)
I0822 21:49:47.977270 31324 sgd_solver.cpp:790] Iteration 17200, lr = 0.01
I0822 21:49:58.497649 31324 solver.cpp:254] Iteration 17220 (1.90108 iter/s, 10.5203s/20 iters), loss = 2.57127
I0822 21:49:58.497732 31324 solver.cpp:273]     Train net output #0: loss = 2.57127 (* 1 = 2.57127 loss)
I0822 21:49:58.497771 31324 sgd_solver.cpp:790] Iteration 17220, lr = 0.01
I0822 21:50:06.591516 31324 solver.cpp:254] Iteration 17240 (2.47106 iter/s, 8.09371s/20 iters), loss = 2.69925
I0822 21:50:06.591589 31324 solver.cpp:273]     Train net output #0: loss = 2.69925 (* 1 = 2.69925 loss)
I0822 21:50:06.591611 31324 sgd_solver.cpp:790] Iteration 17240, lr = 0.01
I0822 21:50:16.826711 31324 solver.cpp:254] Iteration 17260 (1.95407 iter/s, 10.235s/20 iters), loss = 2.50246
I0822 21:50:16.826774 31324 solver.cpp:273]     Train net output #0: loss = 2.50246 (* 1 = 2.50246 loss)
I0822 21:50:16.826786 31324 sgd_solver.cpp:790] Iteration 17260, lr = 0.01
I0822 21:50:27.621801 31324 solver.cpp:254] Iteration 17280 (1.85272 iter/s, 10.7949s/20 iters), loss = 2.34322
I0822 21:50:27.623014 31324 solver.cpp:273]     Train net output #0: loss = 2.34322 (* 1 = 2.34322 loss)
I0822 21:50:27.624292 31324 sgd_solver.cpp:790] Iteration 17280, lr = 0.01
I0822 21:50:38.212471 31324 solver.cpp:254] Iteration 17300 (1.88869 iter/s, 10.5894s/20 iters), loss = 2.48152
I0822 21:50:38.212586 31324 solver.cpp:273]     Train net output #0: loss = 2.48152 (* 1 = 2.48152 loss)
I0822 21:50:38.212607 31324 sgd_solver.cpp:790] Iteration 17300, lr = 0.01
I0822 21:50:48.694203 31324 solver.cpp:254] Iteration 17320 (1.90812 iter/s, 10.4815s/20 iters), loss = 2.61879
I0822 21:50:48.694272 31324 solver.cpp:273]     Train net output #0: loss = 2.61879 (* 1 = 2.61879 loss)
I0822 21:50:48.694283 31324 sgd_solver.cpp:790] Iteration 17320, lr = 0.01
I0822 21:50:59.466578 31324 solver.cpp:254] Iteration 17340 (1.85663 iter/s, 10.7722s/20 iters), loss = 2.71875
I0822 21:50:59.466753 31324 solver.cpp:273]     Train net output #0: loss = 2.71875 (* 1 = 2.71875 loss)
I0822 21:50:59.466766 31324 sgd_solver.cpp:790] Iteration 17340, lr = 0.01
I0822 21:51:10.170274 31324 solver.cpp:254] Iteration 17360 (1.86856 iter/s, 10.7034s/20 iters), loss = 2.4265
I0822 21:51:10.170351 31324 solver.cpp:273]     Train net output #0: loss = 2.4265 (* 1 = 2.4265 loss)
I0822 21:51:10.170366 31324 sgd_solver.cpp:790] Iteration 17360, lr = 0.01
I0822 21:51:20.824934 31324 solver.cpp:254] Iteration 17380 (1.87714 iter/s, 10.6545s/20 iters), loss = 2.47604
I0822 21:51:20.825003 31324 solver.cpp:273]     Train net output #0: loss = 2.47604 (* 1 = 2.47604 loss)
I0822 21:51:20.825016 31324 sgd_solver.cpp:790] Iteration 17380, lr = 0.01
I0822 21:51:31.612345 31324 solver.cpp:254] Iteration 17400 (1.85404 iter/s, 10.7872s/20 iters), loss = 2.54751
I0822 21:51:31.612561 31324 solver.cpp:273]     Train net output #0: loss = 2.54751 (* 1 = 2.54751 loss)
I0822 21:51:31.612581 31324 sgd_solver.cpp:790] Iteration 17400, lr = 0.01
I0822 21:51:42.102178 31324 solver.cpp:254] Iteration 17420 (1.90666 iter/s, 10.4895s/20 iters), loss = 2.63989
I0822 21:51:42.102238 31324 solver.cpp:273]     Train net output #0: loss = 2.63989 (* 1 = 2.63989 loss)
I0822 21:51:42.102249 31324 sgd_solver.cpp:790] Iteration 17420, lr = 0.01
I0822 21:51:52.384930 31324 solver.cpp:254] Iteration 17440 (1.94503 iter/s, 10.2826s/20 iters), loss = 2.43405
I0822 21:51:52.384997 31324 solver.cpp:273]     Train net output #0: loss = 2.43405 (* 1 = 2.43405 loss)
I0822 21:51:52.385023 31324 sgd_solver.cpp:790] Iteration 17440, lr = 0.01
I0822 21:52:02.912467 31324 solver.cpp:254] Iteration 17460 (1.89981 iter/s, 10.5274s/20 iters), loss = 2.33478
I0822 21:52:02.914125 31324 solver.cpp:273]     Train net output #0: loss = 2.33478 (* 1 = 2.33478 loss)
I0822 21:52:02.914140 31324 sgd_solver.cpp:790] Iteration 17460, lr = 0.01
I0822 21:52:13.571763 31324 solver.cpp:254] Iteration 17480 (1.8766 iter/s, 10.6576s/20 iters), loss = 2.46801
I0822 21:52:13.571831 31324 solver.cpp:273]     Train net output #0: loss = 2.46801 (* 1 = 2.46801 loss)
I0822 21:52:13.571844 31324 sgd_solver.cpp:790] Iteration 17480, lr = 0.01
I0822 21:52:23.944559 31324 solver.cpp:254] Iteration 17500 (1.92815 iter/s, 10.3726s/20 iters), loss = 2.57708
I0822 21:52:23.944613 31324 solver.cpp:273]     Train net output #0: loss = 2.57708 (* 1 = 2.57708 loss)
I0822 21:52:23.944624 31324 sgd_solver.cpp:790] Iteration 17500, lr = 0.01
I0822 21:52:34.284652 31324 solver.cpp:254] Iteration 17520 (1.93424 iter/s, 10.34s/20 iters), loss = 2.36799
I0822 21:52:34.284799 31324 solver.cpp:273]     Train net output #0: loss = 2.36799 (* 1 = 2.36799 loss)
I0822 21:52:34.284823 31324 sgd_solver.cpp:790] Iteration 17520, lr = 0.01
I0822 21:52:44.605201 31324 solver.cpp:254] Iteration 17540 (1.93793 iter/s, 10.3203s/20 iters), loss = 2.57989
I0822 21:52:44.605274 31324 solver.cpp:273]     Train net output #0: loss = 2.57989 (* 1 = 2.57989 loss)
I0822 21:52:44.605288 31324 sgd_solver.cpp:790] Iteration 17540, lr = 0.01
I0822 21:52:55.405782 31324 solver.cpp:254] Iteration 17560 (1.85178 iter/s, 10.8004s/20 iters), loss = 2.27229
I0822 21:52:55.405855 31324 solver.cpp:273]     Train net output #0: loss = 2.27229 (* 1 = 2.27229 loss)
I0822 21:52:55.405872 31324 sgd_solver.cpp:790] Iteration 17560, lr = 0.01
I0822 21:53:05.883007 31324 solver.cpp:254] Iteration 17580 (1.90893 iter/s, 10.4771s/20 iters), loss = 2.40055
I0822 21:53:05.883150 31324 solver.cpp:273]     Train net output #0: loss = 2.40055 (* 1 = 2.40055 loss)
I0822 21:53:05.883162 31324 sgd_solver.cpp:790] Iteration 17580, lr = 0.01
I0822 21:53:16.552486 31324 solver.cpp:254] Iteration 17600 (1.87455 iter/s, 10.6693s/20 iters), loss = 2.51883
I0822 21:53:16.552546 31324 solver.cpp:273]     Train net output #0: loss = 2.51883 (* 1 = 2.51883 loss)
I0822 21:53:16.552557 31324 sgd_solver.cpp:790] Iteration 17600, lr = 0.01
I0822 21:53:27.127516 31324 solver.cpp:254] Iteration 17620 (1.89127 iter/s, 10.5749s/20 iters), loss = 2.45497
I0822 21:53:27.127575 31324 solver.cpp:273]     Train net output #0: loss = 2.45497 (* 1 = 2.45497 loss)
I0822 21:53:27.127585 31324 sgd_solver.cpp:790] Iteration 17620, lr = 0.01
I0822 21:53:36.139170 31324 solver.cpp:254] Iteration 17640 (2.21938 iter/s, 9.01152s/20 iters), loss = 2.37449
I0822 21:53:36.139374 31324 solver.cpp:273]     Train net output #0: loss = 2.37449 (* 1 = 2.37449 loss)
I0822 21:53:36.139392 31324 sgd_solver.cpp:790] Iteration 17640, lr = 0.01
I0822 21:53:43.268347 31324 solver.cpp:254] Iteration 17660 (2.80548 iter/s, 7.12892s/20 iters), loss = 2.57797
I0822 21:53:43.268407 31324 solver.cpp:273]     Train net output #0: loss = 2.57797 (* 1 = 2.57797 loss)
I0822 21:53:43.268419 31324 sgd_solver.cpp:790] Iteration 17660, lr = 0.01
I0822 21:53:49.985693 31324 solver.cpp:254] Iteration 17680 (2.97742 iter/s, 6.71723s/20 iters), loss = 2.47743
I0822 21:53:49.985756 31324 solver.cpp:273]     Train net output #0: loss = 2.47743 (* 1 = 2.47743 loss)
I0822 21:53:49.985769 31324 sgd_solver.cpp:790] Iteration 17680, lr = 0.01
I0822 21:53:58.951484 31324 solver.cpp:254] Iteration 17700 (2.23073 iter/s, 8.96567s/20 iters), loss = 2.56242
I0822 21:53:58.951542 31324 solver.cpp:273]     Train net output #0: loss = 2.56242 (* 1 = 2.56242 loss)
I0822 21:53:58.951556 31324 sgd_solver.cpp:790] Iteration 17700, lr = 0.01
I0822 21:54:10.246086 31324 solver.cpp:254] Iteration 17720 (1.77078 iter/s, 11.2945s/20 iters), loss = 2.75084
I0822 21:54:10.246258 31324 solver.cpp:273]     Train net output #0: loss = 2.75084 (* 1 = 2.75084 loss)
I0822 21:54:10.246284 31324 sgd_solver.cpp:790] Iteration 17720, lr = 0.01
I0822 21:54:15.420037 31324 solver.cpp:254] Iteration 17740 (3.86568 iter/s, 5.17374s/20 iters), loss = 2.29666
I0822 21:54:15.432159 31324 solver.cpp:273]     Train net output #0: loss = 2.29666 (* 1 = 2.29666 loss)
I0822 21:54:15.432193 31324 sgd_solver.cpp:790] Iteration 17740, lr = 0.01
I0822 21:54:19.041626 31324 solver.cpp:254] Iteration 17760 (5.54102 iter/s, 3.60945s/20 iters), loss = 2.63733
I0822 21:54:19.053714 31324 solver.cpp:273]     Train net output #0: loss = 2.63733 (* 1 = 2.63733 loss)
I0822 21:54:19.053762 31324 sgd_solver.cpp:790] Iteration 17760, lr = 0.01
I0822 21:54:22.645453 31324 solver.cpp:254] Iteration 17780 (5.56837 iter/s, 3.59171s/20 iters), loss = 2.68753
I0822 21:54:22.658123 31324 solver.cpp:273]     Train net output #0: loss = 2.68753 (* 1 = 2.68753 loss)
I0822 21:54:22.658154 31324 sgd_solver.cpp:790] Iteration 17780, lr = 0.01
I0822 21:54:26.306651 31324 solver.cpp:254] Iteration 17800 (5.48169 iter/s, 3.64851s/20 iters), loss = 2.73631
I0822 21:54:26.321792 31324 solver.cpp:273]     Train net output #0: loss = 2.73631 (* 1 = 2.73631 loss)
I0822 21:54:26.321832 31324 sgd_solver.cpp:790] Iteration 17800, lr = 0.01
I0822 21:54:29.970875 31324 solver.cpp:254] Iteration 17820 (5.48082 iter/s, 3.64909s/20 iters), loss = 2.78613
I0822 21:54:29.983189 31324 solver.cpp:273]     Train net output #0: loss = 2.78613 (* 1 = 2.78613 loss)
I0822 21:54:29.983223 31324 sgd_solver.cpp:790] Iteration 17820, lr = 0.01
I0822 21:54:35.544951 31324 solver.cpp:254] Iteration 17840 (3.596 iter/s, 5.56174s/20 iters), loss = 2.42958
I0822 21:54:35.545006 31324 solver.cpp:273]     Train net output #0: loss = 2.42958 (* 1 = 2.42958 loss)
I0822 21:54:35.545017 31324 sgd_solver.cpp:790] Iteration 17840, lr = 0.01
I0822 21:54:44.832352 31324 solver.cpp:254] Iteration 17860 (2.15348 iter/s, 9.28728s/20 iters), loss = 2.66169
I0822 21:54:44.832516 31324 solver.cpp:273]     Train net output #0: loss = 2.66169 (* 1 = 2.66169 loss)
I0822 21:54:44.832527 31324 sgd_solver.cpp:790] Iteration 17860, lr = 0.01
I0822 21:54:54.494213 31324 solver.cpp:254] Iteration 17880 (2.07004 iter/s, 9.66163s/20 iters), loss = 2.34831
I0822 21:54:54.494271 31324 solver.cpp:273]     Train net output #0: loss = 2.34831 (* 1 = 2.34831 loss)
I0822 21:54:54.494284 31324 sgd_solver.cpp:790] Iteration 17880, lr = 0.01
I0822 21:55:05.233510 31324 solver.cpp:254] Iteration 17900 (1.86234 iter/s, 10.7392s/20 iters), loss = 2.57903
I0822 21:55:05.233574 31324 solver.cpp:273]     Train net output #0: loss = 2.57903 (* 1 = 2.57903 loss)
I0822 21:55:05.233587 31324 sgd_solver.cpp:790] Iteration 17900, lr = 0.01
I0822 21:55:15.895179 31324 solver.cpp:254] Iteration 17920 (1.87591 iter/s, 10.6615s/20 iters), loss = 2.5088
I0822 21:55:15.895362 31324 solver.cpp:273]     Train net output #0: loss = 2.5088 (* 1 = 2.5088 loss)
I0822 21:55:15.895375 31324 sgd_solver.cpp:790] Iteration 17920, lr = 0.01
I0822 21:55:26.548008 31324 solver.cpp:254] Iteration 17940 (1.87748 iter/s, 10.6526s/20 iters), loss = 2.67677
I0822 21:55:26.548071 31324 solver.cpp:273]     Train net output #0: loss = 2.67677 (* 1 = 2.67677 loss)
I0822 21:55:26.548084 31324 sgd_solver.cpp:790] Iteration 17940, lr = 0.01
I0822 21:55:37.128285 31324 solver.cpp:254] Iteration 17960 (1.89034 iter/s, 10.5801s/20 iters), loss = 2.61009
I0822 21:55:37.128376 31324 solver.cpp:273]     Train net output #0: loss = 2.61009 (* 1 = 2.61009 loss)
I0822 21:55:37.128391 31324 sgd_solver.cpp:790] Iteration 17960, lr = 0.01
I0822 21:55:47.724831 31324 solver.cpp:254] Iteration 17980 (1.88744 iter/s, 10.5964s/20 iters), loss = 2.67492
I0822 21:55:47.725940 31324 solver.cpp:273]     Train net output #0: loss = 2.67492 (* 1 = 2.67492 loss)
I0822 21:55:47.725953 31324 sgd_solver.cpp:790] Iteration 17980, lr = 0.01
I0822 21:55:57.495136 31324 solver.cpp:366] Iteration 18000, Testing net (#0)
I0822 21:56:02.537542 31324 blocking_queue.cpp:49] Waiting for data
I0822 21:56:21.746222 31336 data_layer.cpp:73] Restarting data prefetching from start.
I0822 21:56:21.762846 31324 solver.cpp:433]     Test net output #0: accuracy = 0.46864
I0822 21:56:21.762897 31324 solver.cpp:433]     Test net output #1: accuracy5 = 0.73058
I0822 21:56:21.762907 31324 solver.cpp:433]     Test net output #2: loss = 2.35326 (* 1 = 2.35326 loss)
I0822 21:56:21.934103 31324 solver.cpp:254] Iteration 18000 (0.58466 iter/s, 34.2079s/20 iters), loss = 2.38657
I0822 21:56:21.936486 31324 solver.cpp:273]     Train net output #0: loss = 2.38657 (* 1 = 2.38657 loss)
I0822 21:56:21.936508 31324 sgd_solver.cpp:790] Iteration 18000, lr = 0.01
I0822 21:56:31.297487 31324 solver.cpp:254] Iteration 18020 (2.13654 iter/s, 9.36093s/20 iters), loss = 2.18989
I0822 21:56:31.297545 31324 solver.cpp:273]     Train net output #0: loss = 2.18989 (* 1 = 2.18989 loss)
I0822 21:56:31.297556 31324 sgd_solver.cpp:790] Iteration 18020, lr = 0.01
I0822 21:56:41.420872 31324 solver.cpp:254] Iteration 18040 (1.97565 iter/s, 10.1232s/20 iters), loss = 2.27522
I0822 21:56:41.420938 31324 solver.cpp:273]     Train net output #0: loss = 2.27522 (* 1 = 2.27522 loss)
I0822 21:56:41.420949 31324 sgd_solver.cpp:790] Iteration 18040, lr = 0.01
I0822 21:56:51.786742 31324 solver.cpp:254] Iteration 18060 (1.92944 iter/s, 10.3657s/20 iters), loss = 2.7384
I0822 21:56:51.787293 31324 solver.cpp:273]     Train net output #0: loss = 2.7384 (* 1 = 2.7384 loss)
I0822 21:56:51.787308 31324 sgd_solver.cpp:790] Iteration 18060, lr = 0.01
I0822 21:57:02.393776 31324 solver.cpp:254] Iteration 18080 (1.88565 iter/s, 10.6064s/20 iters), loss = 2.56052
I0822 21:57:02.393839 31324 solver.cpp:273]     Train net output #0: loss = 2.56052 (* 1 = 2.56052 loss)
I0822 21:57:02.393851 31324 sgd_solver.cpp:790] Iteration 18080, lr = 0.01
I0822 21:57:12.776967 31324 solver.cpp:254] Iteration 18100 (1.92622 iter/s, 10.383s/20 iters), loss = 2.61428
I0822 21:57:12.777022 31324 solver.cpp:273]     Train net output #0: loss = 2.61428 (* 1 = 2.61428 loss)
I0822 21:57:12.777032 31324 sgd_solver.cpp:790] Iteration 18100, lr = 0.01
I0822 21:57:23.451840 31324 solver.cpp:254] Iteration 18120 (1.87359 iter/s, 10.6747s/20 iters), loss = 2.70132
I0822 21:57:23.452041 31324 solver.cpp:273]     Train net output #0: loss = 2.70132 (* 1 = 2.70132 loss)
I0822 21:57:23.452064 31324 sgd_solver.cpp:790] Iteration 18120, lr = 0.01
I0822 21:57:34.044059 31324 solver.cpp:254] Iteration 18140 (1.88823 iter/s, 10.5919s/20 iters), loss = 2.33672
I0822 21:57:34.044160 31324 solver.cpp:273]     Train net output #0: loss = 2.33672 (* 1 = 2.33672 loss)
I0822 21:57:34.044180 31324 sgd_solver.cpp:790] Iteration 18140, lr = 0.01
I0822 21:57:44.522881 31324 solver.cpp:254] Iteration 18160 (1.90864 iter/s, 10.4786s/20 iters), loss = 2.76661
I0822 21:57:44.522945 31324 solver.cpp:273]     Train net output #0: loss = 2.76661 (* 1 = 2.76661 loss)
I0822 21:57:44.522958 31324 sgd_solver.cpp:790] Iteration 18160, lr = 0.01
I0822 21:57:55.010769 31324 solver.cpp:254] Iteration 18180 (1.90699 iter/s, 10.4877s/20 iters), loss = 2.60074
I0822 21:57:55.012732 31324 solver.cpp:273]     Train net output #0: loss = 2.60074 (* 1 = 2.60074 loss)
I0822 21:57:55.012748 31324 sgd_solver.cpp:790] Iteration 18180, lr = 0.01
I0822 21:58:05.431246 31324 solver.cpp:254] Iteration 18200 (1.91967 iter/s, 10.4184s/20 iters), loss = 2.62307
I0822 21:58:05.431310 31324 solver.cpp:273]     Train net output #0: loss = 2.62307 (* 1 = 2.62307 loss)
I0822 21:58:05.431322 31324 sgd_solver.cpp:790] Iteration 18200, lr = 0.01
I0822 21:58:08.465626 31324 blocking_queue.cpp:49] Waiting for data
I0822 21:58:16.048682 31324 solver.cpp:254] Iteration 18220 (1.88372 iter/s, 10.6173s/20 iters), loss = 2.47721
I0822 21:58:16.048772 31324 solver.cpp:273]     Train net output #0: loss = 2.47721 (* 1 = 2.47721 loss)
I0822 21:58:16.048794 31324 sgd_solver.cpp:790] Iteration 18220, lr = 0.01
I0822 21:58:26.499686 31324 solver.cpp:254] Iteration 18240 (1.91372 iter/s, 10.4508s/20 iters), loss = 2.6167
I0822 21:58:26.499861 31324 solver.cpp:273]     Train net output #0: loss = 2.6167 (* 1 = 2.6167 loss)
I0822 21:58:26.499876 31324 sgd_solver.cpp:790] Iteration 18240, lr = 0.01
I0822 21:58:37.083499 31324 solver.cpp:254] Iteration 18260 (1.88973 iter/s, 10.5835s/20 iters), loss = 2.53901
I0822 21:58:37.083591 31324 solver.cpp:273]     Train net output #0: loss = 2.53901 (* 1 = 2.53901 loss)
I0822 21:58:37.083609 31324 sgd_solver.cpp:790] Iteration 18260, lr = 0.01
I0822 21:58:46.533691 31324 solver.cpp:254] Iteration 18280 (2.1164 iter/s, 9.45003s/20 iters), loss = 2.51611
I0822 21:58:46.533800 31324 solver.cpp:273]     Train net output #0: loss = 2.51611 (* 1 = 2.51611 loss)
I0822 21:58:46.533823 31324 sgd_solver.cpp:790] Iteration 18280, lr = 0.01
I0822 21:58:55.371999 31324 solver.cpp:254] Iteration 18300 (2.26292 iter/s, 8.83813s/20 iters), loss = 2.6985
I0822 21:58:55.372059 31324 solver.cpp:273]     Train net output #0: loss = 2.6985 (* 1 = 2.6985 loss)
I0822 21:58:55.372071 31324 sgd_solver.cpp:790] Iteration 18300, lr = 0.01
I0822 21:59:05.014365 31324 solver.cpp:254] Iteration 18320 (2.07421 iter/s, 9.64223s/20 iters), loss = 2.55469
I0822 21:59:05.014535 31324 solver.cpp:273]     Train net output #0: loss = 2.55469 (* 1 = 2.55469 loss)
I0822 21:59:05.014559 31324 sgd_solver.cpp:790] Iteration 18320, lr = 0.01
I0822 21:59:14.243402 31324 solver.cpp:254] Iteration 18340 (2.16713 iter/s, 9.2288s/20 iters), loss = 2.64321
I0822 21:59:14.243459 31324 solver.cpp:273]     Train net output #0: loss = 2.64321 (* 1 = 2.64321 loss)
I0822 21:59:14.243470 31324 sgd_solver.cpp:790] Iteration 18340, lr = 0.01
I0822 21:59:24.697727 31324 solver.cpp:254] Iteration 18360 (1.91311 iter/s, 10.4542s/20 iters), loss = 2.52644
I0822 21:59:24.697837 31324 solver.cpp:273]     Train net output #0: loss = 2.52644 (* 1 = 2.52644 loss)
I0822 21:59:24.697856 31324 sgd_solver.cpp:790] Iteration 18360, lr = 0.01
I0822 21:59:35.088487 31324 solver.cpp:254] Iteration 18380 (1.92482 iter/s, 10.3906s/20 iters), loss = 2.79908
I0822 21:59:35.088693 31324 solver.cpp:273]     Train net output #0: loss = 2.79908 (* 1 = 2.79908 loss)
I0822 21:59:35.088709 31324 sgd_solver.cpp:790] Iteration 18380, lr = 0.01
I0822 21:59:45.836817 31324 solver.cpp:254] Iteration 18400 (1.8608 iter/s, 10.7481s/20 iters), loss = 2.38078
I0822 21:59:45.836884 31324 solver.cpp:273]     Train net output #0: loss = 2.38078 (* 1 = 2.38078 loss)
I0822 21:59:45.836894 31324 sgd_solver.cpp:790] Iteration 18400, lr = 0.01
I0822 21:59:56.367558 31324 solver.cpp:254] Iteration 18420 (1.89923 iter/s, 10.5306s/20 iters), loss = 2.61531
I0822 21:59:56.367630 31324 solver.cpp:273]     Train net output #0: loss = 2.61531 (* 1 = 2.61531 loss)
I0822 21:59:56.367645 31324 sgd_solver.cpp:790] Iteration 18420, lr = 0.01
I0822 22:00:06.803406 31324 solver.cpp:254] Iteration 18440 (1.9165 iter/s, 10.4357s/20 iters), loss = 2.47985
I0822 22:00:06.803550 31324 solver.cpp:273]     Train net output #0: loss = 2.47985 (* 1 = 2.47985 loss)
I0822 22:00:06.803561 31324 sgd_solver.cpp:790] Iteration 18440, lr = 0.01
I0822 22:00:17.347295 31324 solver.cpp:254] Iteration 18460 (1.89687 iter/s, 10.5437s/20 iters), loss = 2.40272
I0822 22:00:17.347369 31324 solver.cpp:273]     Train net output #0: loss = 2.40272 (* 1 = 2.40272 loss)
I0822 22:00:17.347381 31324 sgd_solver.cpp:790] Iteration 18460, lr = 0.01
I0822 22:00:28.019105 31324 solver.cpp:254] Iteration 18480 (1.87412 iter/s, 10.6717s/20 iters), loss = 2.58419
I0822 22:00:28.019173 31324 solver.cpp:273]     Train net output #0: loss = 2.58419 (* 1 = 2.58419 loss)
I0822 22:00:28.019186 31324 sgd_solver.cpp:790] Iteration 18480, lr = 0.01
I0822 22:00:38.658406 31324 solver.cpp:254] Iteration 18500 (1.87985 iter/s, 10.6392s/20 iters), loss = 2.7013
I0822 22:00:38.658560 31324 solver.cpp:273]     Train net output #0: loss = 2.7013 (* 1 = 2.7013 loss)
I0822 22:00:38.658574 31324 sgd_solver.cpp:790] Iteration 18500, lr = 0.01
I0822 22:00:48.408293 31324 solver.cpp:254] Iteration 18520 (2.05135 iter/s, 9.74967s/20 iters), loss = 2.33852
I0822 22:00:48.408355 31324 solver.cpp:273]     Train net output #0: loss = 2.33852 (* 1 = 2.33852 loss)
I0822 22:00:48.408366 31324 sgd_solver.cpp:790] Iteration 18520, lr = 0.01
I0822 22:00:58.373214 31324 solver.cpp:254] Iteration 18540 (2.00707 iter/s, 9.96479s/20 iters), loss = 2.50347
I0822 22:00:58.373268 31324 solver.cpp:273]     Train net output #0: loss = 2.50347 (* 1 = 2.50347 loss)
I0822 22:00:58.373278 31324 sgd_solver.cpp:790] Iteration 18540, lr = 0.01
I0822 22:01:05.648160 31324 solver.cpp:254] Iteration 18560 (2.7492 iter/s, 7.27483s/20 iters), loss = 2.37305
I0822 22:01:05.648221 31324 solver.cpp:273]     Train net output #0: loss = 2.37305 (* 1 = 2.37305 loss)
I0822 22:01:05.648233 31324 sgd_solver.cpp:790] Iteration 18560, lr = 0.01
I0822 22:01:12.409831 31324 solver.cpp:254] Iteration 18580 (2.9579 iter/s, 6.76155s/20 iters), loss = 2.35828
I0822 22:01:12.410989 31324 solver.cpp:273]     Train net output #0: loss = 2.35828 (* 1 = 2.35828 loss)
I0822 22:01:12.411005 31324 sgd_solver.cpp:790] Iteration 18580, lr = 0.01
I0822 22:01:20.721181 31324 solver.cpp:254] Iteration 18600 (2.4067 iter/s, 8.31015s/20 iters), loss = 2.4337
I0822 22:01:20.721238 31324 solver.cpp:273]     Train net output #0: loss = 2.4337 (* 1 = 2.4337 loss)
I0822 22:01:20.721251 31324 sgd_solver.cpp:790] Iteration 18600, lr = 0.01
I0822 22:01:30.624191 31324 solver.cpp:254] Iteration 18620 (2.01961 iter/s, 9.90288s/20 iters), loss = 2.57217
I0822 22:01:30.624264 31324 solver.cpp:273]     Train net output #0: loss = 2.57217 (* 1 = 2.57217 loss)
I0822 22:01:30.624275 31324 sgd_solver.cpp:790] Iteration 18620, lr = 0.01
I0822 22:01:41.324262 31324 solver.cpp:254] Iteration 18640 (1.86917 iter/s, 10.6999s/20 iters), loss = 2.67743
I0822 22:01:41.324362 31324 solver.cpp:273]     Train net output #0: loss = 2.67743 (* 1 = 2.67743 loss)
I0822 22:01:41.324380 31324 sgd_solver.cpp:790] Iteration 18640, lr = 0.01
I0822 22:01:51.844923 31324 solver.cpp:254] Iteration 18660 (1.90105 iter/s, 10.5205s/20 iters), loss = 2.45426
I0822 22:01:51.845086 31324 solver.cpp:273]     Train net output #0: loss = 2.45426 (* 1 = 2.45426 loss)
I0822 22:01:51.845100 31324 sgd_solver.cpp:790] Iteration 18660, lr = 0.01
I0822 22:02:02.430191 31324 solver.cpp:254] Iteration 18680 (1.88946 iter/s, 10.585s/20 iters), loss = 2.64069
I0822 22:02:02.430268 31324 solver.cpp:273]     Train net output #0: loss = 2.64069 (* 1 = 2.64069 loss)
I0822 22:02:02.430282 31324 sgd_solver.cpp:790] Iteration 18680, lr = 0.01
I0822 22:02:13.122119 31324 solver.cpp:254] Iteration 18700 (1.8706 iter/s, 10.6918s/20 iters), loss = 2.31842
I0822 22:02:13.122197 31324 solver.cpp:273]     Train net output #0: loss = 2.31842 (* 1 = 2.31842 loss)
I0822 22:02:13.122212 31324 sgd_solver.cpp:790] Iteration 18700, lr = 0.01
I0822 22:02:23.686327 31324 solver.cpp:254] Iteration 18720 (1.89321 iter/s, 10.5641s/20 iters), loss = 2.6135
I0822 22:02:23.686516 31324 solver.cpp:273]     Train net output #0: loss = 2.6135 (* 1 = 2.6135 loss)
I0822 22:02:23.686528 31324 sgd_solver.cpp:790] Iteration 18720, lr = 0.01
I0822 22:02:34.307303 31324 solver.cpp:254] Iteration 18740 (1.88311 iter/s, 10.6207s/20 iters), loss = 2.38186
I0822 22:02:34.307375 31324 solver.cpp:273]     Train net output #0: loss = 2.38186 (* 1 = 2.38186 loss)
I0822 22:02:34.307386 31324 sgd_solver.cpp:790] Iteration 18740, lr = 0.01
I0822 22:02:44.296162 31324 solver.cpp:254] Iteration 18760 (2.00226 iter/s, 9.98872s/20 iters), loss = 2.33689
I0822 22:02:44.296212 31324 solver.cpp:273]     Train net output #0: loss = 2.33689 (* 1 = 2.33689 loss)
I0822 22:02:44.296222 31324 sgd_solver.cpp:790] Iteration 18760, lr = 0.01
I0822 22:02:53.502774 31324 solver.cpp:254] Iteration 18780 (2.17238 iter/s, 9.20649s/20 iters), loss = 2.53278
I0822 22:02:53.502838 31324 solver.cpp:273]     Train net output #0: loss = 2.53278 (* 1 = 2.53278 loss)
I0822 22:02:53.502851 31324 sgd_solver.cpp:790] Iteration 18780, lr = 0.01
I0822 22:03:02.502895 31324 solver.cpp:254] Iteration 18800 (2.22222 iter/s, 8.99999s/20 iters), loss = 2.62252
I0822 22:03:02.504119 31324 solver.cpp:273]     Train net output #0: loss = 2.62252 (* 1 = 2.62252 loss)
I0822 22:03:02.504140 31324 sgd_solver.cpp:790] Iteration 18800, lr = 0.01
I0822 22:03:12.639185 31324 solver.cpp:254] Iteration 18820 (1.97336 iter/s, 10.135s/20 iters), loss = 2.43065
I0822 22:03:12.639251 31324 solver.cpp:273]     Train net output #0: loss = 2.43065 (* 1 = 2.43065 loss)
I0822 22:03:12.639262 31324 sgd_solver.cpp:790] Iteration 18820, lr = 0.01
I0822 22:03:23.255364 31324 solver.cpp:254] Iteration 18840 (1.88394 iter/s, 10.616s/20 iters), loss = 2.50803
I0822 22:03:23.255420 31324 solver.cpp:273]     Train net output #0: loss = 2.50803 (* 1 = 2.50803 loss)
I0822 22:03:23.255431 31324 sgd_solver.cpp:790] Iteration 18840, lr = 0.01
I0822 22:03:33.873284 31324 solver.cpp:254] Iteration 18860 (1.88363 iter/s, 10.6178s/20 iters), loss = 2.50109
I0822 22:03:33.873471 31324 solver.cpp:273]     Train net output #0: loss = 2.50109 (* 1 = 2.50109 loss)
I0822 22:03:33.873493 31324 sgd_solver.cpp:790] Iteration 18860, lr = 0.01
I0822 22:03:44.376361 31324 solver.cpp:254] Iteration 18880 (1.90425 iter/s, 10.5028s/20 iters), loss = 2.76846
I0822 22:03:44.376437 31324 solver.cpp:273]     Train net output #0: loss = 2.76846 (* 1 = 2.76846 loss)
I0822 22:03:44.376451 31324 sgd_solver.cpp:790] Iteration 18880, lr = 0.01
I0822 22:03:55.097579 31324 solver.cpp:254] Iteration 18900 (1.86549 iter/s, 10.7211s/20 iters), loss = 2.47658
I0822 22:03:55.097662 31324 solver.cpp:273]     Train net output #0: loss = 2.47658 (* 1 = 2.47658 loss)
I0822 22:03:55.097676 31324 sgd_solver.cpp:790] Iteration 18900, lr = 0.01
I0822 22:04:05.892622 31324 solver.cpp:254] Iteration 18920 (1.85273 iter/s, 10.7949s/20 iters), loss = 2.46429
I0822 22:04:05.893383 31324 solver.cpp:273]     Train net output #0: loss = 2.46429 (* 1 = 2.46429 loss)
I0822 22:04:05.893394 31324 sgd_solver.cpp:790] Iteration 18920, lr = 0.01
I0822 22:04:16.554452 31324 solver.cpp:254] Iteration 18940 (1.876 iter/s, 10.661s/20 iters), loss = 2.52682
I0822 22:04:16.554533 31324 solver.cpp:273]     Train net output #0: loss = 2.52682 (* 1 = 2.52682 loss)
I0822 22:04:16.554546 31324 sgd_solver.cpp:790] Iteration 18940, lr = 0.01
I0822 22:04:27.321257 31324 solver.cpp:254] Iteration 18960 (1.85759 iter/s, 10.7667s/20 iters), loss = 2.66428
I0822 22:04:27.321322 31324 solver.cpp:273]     Train net output #0: loss = 2.66428 (* 1 = 2.66428 loss)
I0822 22:04:27.321349 31324 sgd_solver.cpp:790] Iteration 18960, lr = 0.01
I0822 22:04:37.801780 31324 solver.cpp:254] Iteration 18980 (1.90833 iter/s, 10.4804s/20 iters), loss = 2.79195
I0822 22:04:37.801991 31324 solver.cpp:273]     Train net output #0: loss = 2.79195 (* 1 = 2.79195 loss)
I0822 22:04:37.802008 31324 sgd_solver.cpp:790] Iteration 18980, lr = 0.01
I0822 22:04:47.131533 31324 solver.cpp:366] Iteration 19000, Testing net (#0)
I0822 22:04:52.626390 31324 blocking_queue.cpp:49] Waiting for data
I0822 22:05:12.127498 31336 data_layer.cpp:73] Restarting data prefetching from start.
I0822 22:05:12.144317 31324 solver.cpp:433]     Test net output #0: accuracy = 0.47558
I0822 22:05:12.144374 31324 solver.cpp:433]     Test net output #1: accuracy5 = 0.73632
I0822 22:05:12.144393 31324 solver.cpp:433]     Test net output #2: loss = 2.32705 (* 1 = 2.32705 loss)
I0822 22:05:12.319432 31324 solver.cpp:254] Iteration 19000 (0.57942 iter/s, 34.5173s/20 iters), loss = 2.11144
I0822 22:05:12.321851 31324 solver.cpp:273]     Train net output #0: loss = 2.11144 (* 1 = 2.11144 loss)
I0822 22:05:12.321871 31324 sgd_solver.cpp:790] Iteration 19000, lr = 0.01
I0822 22:05:21.652055 31324 solver.cpp:254] Iteration 19020 (2.14359 iter/s, 9.33014s/20 iters), loss = 2.44148
I0822 22:05:21.652127 31324 solver.cpp:273]     Train net output #0: loss = 2.44148 (* 1 = 2.44148 loss)
I0822 22:05:21.652140 31324 sgd_solver.cpp:790] Iteration 19020, lr = 0.01
I0822 22:05:32.048532 31324 solver.cpp:254] Iteration 19040 (1.92375 iter/s, 10.3963s/20 iters), loss = 2.88694
I0822 22:05:32.048627 31324 solver.cpp:273]     Train net output #0: loss = 2.88694 (* 1 = 2.88694 loss)
I0822 22:05:32.048642 31324 sgd_solver.cpp:790] Iteration 19040, lr = 0.01
I0822 22:05:42.216675 31324 solver.cpp:254] Iteration 19060 (1.96696 iter/s, 10.168s/20 iters), loss = 2.6085
I0822 22:05:42.216847 31324 solver.cpp:273]     Train net output #0: loss = 2.6085 (* 1 = 2.6085 loss)
I0822 22:05:42.216864 31324 sgd_solver.cpp:790] Iteration 19060, lr = 0.01
I0822 22:05:52.953853 31324 solver.cpp:254] Iteration 19080 (1.8629 iter/s, 10.736s/20 iters), loss = 2.81096
I0822 22:05:52.953941 31324 solver.cpp:273]     Train net output #0: loss = 2.81096 (* 1 = 2.81096 loss)
I0822 22:05:52.953959 31324 sgd_solver.cpp:790] Iteration 19080, lr = 0.01
I0822 22:06:03.518841 31324 solver.cpp:254] Iteration 19100 (1.89307 iter/s, 10.5648s/20 iters), loss = 2.42147
I0822 22:06:03.518916 31324 solver.cpp:273]     Train net output #0: loss = 2.42147 (* 1 = 2.42147 loss)
I0822 22:06:03.518939 31324 sgd_solver.cpp:790] Iteration 19100, lr = 0.01
I0822 22:06:14.037191 31324 solver.cpp:254] Iteration 19120 (1.90147 iter/s, 10.5182s/20 iters), loss = 2.40811
I0822 22:06:14.037353 31324 solver.cpp:273]     Train net output #0: loss = 2.40811 (* 1 = 2.40811 loss)
I0822 22:06:14.037369 31324 sgd_solver.cpp:790] Iteration 19120, lr = 0.01
I0822 22:06:24.676064 31324 solver.cpp:254] Iteration 19140 (1.87994 iter/s, 10.6386s/20 iters), loss = 2.61139
I0822 22:06:24.676156 31324 solver.cpp:273]     Train net output #0: loss = 2.61139 (* 1 = 2.61139 loss)
I0822 22:06:24.676858 31324 sgd_solver.cpp:790] Iteration 19140, lr = 0.01
I0822 22:06:34.964942 31324 solver.cpp:254] Iteration 19160 (1.94388 iter/s, 10.2887s/20 iters), loss = 2.60077
I0822 22:06:34.965004 31324 solver.cpp:273]     Train net output #0: loss = 2.60077 (* 1 = 2.60077 loss)
I0822 22:06:34.965014 31324 sgd_solver.cpp:790] Iteration 19160, lr = 0.01
I0822 22:06:45.603902 31324 solver.cpp:254] Iteration 19180 (1.87991 iter/s, 10.6388s/20 iters), loss = 2.35081
I0822 22:06:45.604058 31324 solver.cpp:273]     Train net output #0: loss = 2.35081 (* 1 = 2.35081 loss)
I0822 22:06:45.604068 31324 sgd_solver.cpp:790] Iteration 19180, lr = 0.01
I0822 22:06:56.248765 31324 solver.cpp:254] Iteration 19200 (1.87888 iter/s, 10.6446s/20 iters), loss = 2.81067
I0822 22:06:56.248827 31324 solver.cpp:273]     Train net output #0: loss = 2.81067 (* 1 = 2.81067 loss)
I0822 22:06:56.248837 31324 sgd_solver.cpp:790] Iteration 19200, lr = 0.01
I0822 22:07:03.063587 31324 blocking_queue.cpp:49] Waiting for data
I0822 22:07:06.707083 31324 solver.cpp:254] Iteration 19220 (1.91238 iter/s, 10.4582s/20 iters), loss = 2.58063
I0822 22:07:06.707170 31324 solver.cpp:273]     Train net output #0: loss = 2.58063 (* 1 = 2.58063 loss)
I0822 22:07:06.707186 31324 sgd_solver.cpp:790] Iteration 19220, lr = 0.01
I0822 22:07:17.452474 31324 solver.cpp:254] Iteration 19240 (1.86129 iter/s, 10.7452s/20 iters), loss = 2.33737
I0822 22:07:17.452646 31324 solver.cpp:273]     Train net output #0: loss = 2.33737 (* 1 = 2.33737 loss)
I0822 22:07:17.452659 31324 sgd_solver.cpp:790] Iteration 19240, lr = 0.01
I0822 22:07:28.207164 31324 solver.cpp:254] Iteration 19260 (1.8597 iter/s, 10.7544s/20 iters), loss = 2.69635
I0822 22:07:28.207240 31324 solver.cpp:273]     Train net output #0: loss = 2.69635 (* 1 = 2.69635 loss)
I0822 22:07:28.207254 31324 sgd_solver.cpp:790] Iteration 19260, lr = 0.01
I0822 22:07:38.253192 31324 solver.cpp:254] Iteration 19280 (1.99087 iter/s, 10.0459s/20 iters), loss = 2.58005
I0822 22:07:38.253262 31324 solver.cpp:273]     Train net output #0: loss = 2.58005 (* 1 = 2.58005 loss)
I0822 22:07:38.253278 31324 sgd_solver.cpp:790] Iteration 19280, lr = 0.01
I0822 22:07:48.513182 31324 solver.cpp:254] Iteration 19300 (1.94935 iter/s, 10.2598s/20 iters), loss = 2.24728
I0822 22:07:48.513342 31324 solver.cpp:273]     Train net output #0: loss = 2.24728 (* 1 = 2.24728 loss)
I0822 22:07:48.513355 31324 sgd_solver.cpp:790] Iteration 19300, lr = 0.01
I0822 22:07:59.002229 31324 solver.cpp:254] Iteration 19320 (1.90679 iter/s, 10.4888s/20 iters), loss = 2.67539
I0822 22:07:59.002313 31324 solver.cpp:273]     Train net output #0: loss = 2.67539 (* 1 = 2.67539 loss)
I0822 22:07:59.002331 31324 sgd_solver.cpp:790] Iteration 19320, lr = 0.01
I0822 22:08:09.558003 31324 solver.cpp:254] Iteration 19340 (1.89473 iter/s, 10.5556s/20 iters), loss = 2.4079
I0822 22:08:09.558079 31324 solver.cpp:273]     Train net output #0: loss = 2.4079 (* 1 = 2.4079 loss)
I0822 22:08:09.558095 31324 sgd_solver.cpp:790] Iteration 19340, lr = 0.01
I0822 22:08:20.175007 31324 solver.cpp:254] Iteration 19360 (1.8838 iter/s, 10.6169s/20 iters), loss = 2.75507
I0822 22:08:20.175177 31324 solver.cpp:273]     Train net output #0: loss = 2.75507 (* 1 = 2.75507 loss)
I0822 22:08:20.175190 31324 sgd_solver.cpp:790] Iteration 19360, lr = 0.01
I0822 22:08:30.798787 31324 solver.cpp:254] Iteration 19380 (1.88261 iter/s, 10.6235s/20 iters), loss = 2.21792
I0822 22:08:30.798848 31324 solver.cpp:273]     Train net output #0: loss = 2.21792 (* 1 = 2.21792 loss)
I0822 22:08:30.798861 31324 sgd_solver.cpp:790] Iteration 19380, lr = 0.01
I0822 22:08:41.059962 31324 solver.cpp:254] Iteration 19400 (1.94912 iter/s, 10.261s/20 iters), loss = 2.54016
I0822 22:08:41.060024 31324 solver.cpp:273]     Train net output #0: loss = 2.54016 (* 1 = 2.54016 loss)
I0822 22:08:41.060037 31324 sgd_solver.cpp:790] Iteration 19400, lr = 0.01
I0822 22:08:51.573580 31324 solver.cpp:254] Iteration 19420 (1.90232 iter/s, 10.5135s/20 iters), loss = 2.57804
I0822 22:08:51.573719 31324 solver.cpp:273]     Train net output #0: loss = 2.57804 (* 1 = 2.57804 loss)
I0822 22:08:51.573735 31324 sgd_solver.cpp:790] Iteration 19420, lr = 0.01
I0822 22:09:02.245796 31324 solver.cpp:254] Iteration 19440 (1.87406 iter/s, 10.672s/20 iters), loss = 2.26875
I0822 22:09:02.245853 31324 solver.cpp:273]     Train net output #0: loss = 2.26875 (* 1 = 2.26875 loss)
I0822 22:09:02.245863 31324 sgd_solver.cpp:790] Iteration 19440, lr = 0.01
I0822 22:09:12.497843 31324 solver.cpp:254] Iteration 19460 (1.95107 iter/s, 10.2508s/20 iters), loss = 2.56553
I0822 22:09:12.497917 31324 solver.cpp:273]     Train net output #0: loss = 2.56553 (* 1 = 2.56553 loss)
I0822 22:09:12.497932 31324 sgd_solver.cpp:790] Iteration 19460, lr = 0.01
I0822 22:09:22.958539 31324 solver.cpp:254] Iteration 19480 (1.91194 iter/s, 10.4606s/20 iters), loss = 2.44812
I0822 22:09:22.958679 31324 solver.cpp:273]     Train net output #0: loss = 2.44812 (* 1 = 2.44812 loss)
I0822 22:09:22.958694 31324 sgd_solver.cpp:790] Iteration 19480, lr = 0.01
I0822 22:09:33.239532 31324 solver.cpp:254] Iteration 19500 (1.94538 iter/s, 10.2808s/20 iters), loss = 2.58719
I0822 22:09:33.239616 31324 solver.cpp:273]     Train net output #0: loss = 2.58719 (* 1 = 2.58719 loss)
I0822 22:09:33.239630 31324 sgd_solver.cpp:790] Iteration 19500, lr = 0.01
I0822 22:09:43.921231 31324 solver.cpp:254] Iteration 19520 (1.87239 iter/s, 10.6815s/20 iters), loss = 2.45324
I0822 22:09:43.921308 31324 solver.cpp:273]     Train net output #0: loss = 2.45324 (* 1 = 2.45324 loss)
I0822 22:09:43.921324 31324 sgd_solver.cpp:790] Iteration 19520, lr = 0.01
I0822 22:09:54.476626 31324 solver.cpp:254] Iteration 19540 (1.89479 iter/s, 10.5553s/20 iters), loss = 2.5736
I0822 22:09:54.476785 31324 solver.cpp:273]     Train net output #0: loss = 2.5736 (* 1 = 2.5736 loss)
I0822 22:09:54.476796 31324 sgd_solver.cpp:790] Iteration 19540, lr = 0.01
I0822 22:10:03.684975 31324 solver.cpp:254] Iteration 19560 (2.17199 iter/s, 9.20813s/20 iters), loss = 2.514
I0822 22:10:03.685034 31324 solver.cpp:273]     Train net output #0: loss = 2.514 (* 1 = 2.514 loss)
I0822 22:10:03.685043 31324 sgd_solver.cpp:790] Iteration 19560, lr = 0.01
I0822 22:10:13.007694 31324 solver.cpp:254] Iteration 19580 (2.14532 iter/s, 9.3226s/20 iters), loss = 2.71839
I0822 22:10:13.007745 31324 solver.cpp:273]     Train net output #0: loss = 2.71839 (* 1 = 2.71839 loss)
I0822 22:10:13.007755 31324 sgd_solver.cpp:790] Iteration 19580, lr = 0.01
I0822 22:10:23.113310 31324 solver.cpp:254] Iteration 19600 (1.97912 iter/s, 10.1055s/20 iters), loss = 2.48353
I0822 22:10:23.113369 31324 solver.cpp:273]     Train net output #0: loss = 2.48353 (* 1 = 2.48353 loss)
I0822 22:10:23.113379 31324 sgd_solver.cpp:790] Iteration 19600, lr = 0.01
I0822 22:10:33.798655 31324 solver.cpp:254] Iteration 19620 (1.87175 iter/s, 10.6852s/20 iters), loss = 2.82322
I0822 22:10:33.798812 31324 solver.cpp:273]     Train net output #0: loss = 2.82322 (* 1 = 2.82322 loss)
I0822 22:10:33.798825 31324 sgd_solver.cpp:790] Iteration 19620, lr = 0.01
I0822 22:10:44.208120 31324 solver.cpp:254] Iteration 19640 (1.92137 iter/s, 10.4092s/20 iters), loss = 2.74715
I0822 22:10:44.208212 31324 solver.cpp:273]     Train net output #0: loss = 2.74715 (* 1 = 2.74715 loss)
I0822 22:10:44.208230 31324 sgd_solver.cpp:790] Iteration 19640, lr = 0.01
I0822 22:10:54.731580 31324 solver.cpp:254] Iteration 19660 (1.90054 iter/s, 10.5233s/20 iters), loss = 2.67791
I0822 22:10:54.731642 31324 solver.cpp:273]     Train net output #0: loss = 2.67791 (* 1 = 2.67791 loss)
I0822 22:10:54.731652 31324 sgd_solver.cpp:790] Iteration 19660, lr = 0.01
I0822 22:11:05.128726 31324 solver.cpp:254] Iteration 19680 (1.92363 iter/s, 10.397s/20 iters), loss = 2.81658
I0822 22:11:05.128899 31324 solver.cpp:273]     Train net output #0: loss = 2.81658 (* 1 = 2.81658 loss)
I0822 22:11:05.128914 31324 sgd_solver.cpp:790] Iteration 19680, lr = 0.01
I0822 22:11:15.187857 31324 solver.cpp:254] Iteration 19700 (1.98829 iter/s, 10.0589s/20 iters), loss = 2.63757
I0822 22:11:15.187948 31324 solver.cpp:273]     Train net output #0: loss = 2.63757 (* 1 = 2.63757 loss)
I0822 22:11:15.187970 31324 sgd_solver.cpp:790] Iteration 19700, lr = 0.01
I0822 22:11:25.421861 31324 solver.cpp:254] Iteration 19720 (1.9543 iter/s, 10.2338s/20 iters), loss = 2.28848
I0822 22:11:25.421917 31324 solver.cpp:273]     Train net output #0: loss = 2.28848 (* 1 = 2.28848 loss)
I0822 22:11:25.421927 31324 sgd_solver.cpp:790] Iteration 19720, lr = 0.01
I0822 22:11:34.365109 31324 solver.cpp:254] Iteration 19740 (2.23635 iter/s, 8.94313s/20 iters), loss = 2.50974
I0822 22:11:34.365164 31324 solver.cpp:273]     Train net output #0: loss = 2.50974 (* 1 = 2.50974 loss)
I0822 22:11:34.365175 31324 sgd_solver.cpp:790] Iteration 19740, lr = 0.01
I0822 22:11:40.711241 31324 solver.cpp:254] Iteration 19760 (3.15158 iter/s, 6.34602s/20 iters), loss = 2.37332
I0822 22:11:40.711405 31324 solver.cpp:273]     Train net output #0: loss = 2.37332 (* 1 = 2.37332 loss)
I0822 22:11:40.711419 31324 sgd_solver.cpp:790] Iteration 19760, lr = 0.01
I0822 22:11:48.843509 31324 solver.cpp:254] Iteration 19780 (2.4594 iter/s, 8.13205s/20 iters), loss = 2.59891
I0822 22:11:48.843595 31324 solver.cpp:273]     Train net output #0: loss = 2.59891 (* 1 = 2.59891 loss)
I0822 22:11:48.843613 31324 sgd_solver.cpp:790] Iteration 19780, lr = 0.01
I0822 22:11:58.296675 31324 solver.cpp:254] Iteration 19800 (2.11573 iter/s, 9.45302s/20 iters), loss = 2.44262
I0822 22:11:58.296733 31324 solver.cpp:273]     Train net output #0: loss = 2.44262 (* 1 = 2.44262 loss)
I0822 22:11:58.296744 31324 sgd_solver.cpp:790] Iteration 19800, lr = 0.01
I0822 22:12:08.563741 31324 solver.cpp:254] Iteration 19820 (1.948 iter/s, 10.2669s/20 iters), loss = 2.70467
I0822 22:12:08.563810 31324 solver.cpp:273]     Train net output #0: loss = 2.70467 (* 1 = 2.70467 loss)
I0822 22:12:08.563823 31324 sgd_solver.cpp:790] Iteration 19820, lr = 0.01
I0822 22:12:19.130816 31324 solver.cpp:254] Iteration 19840 (1.8927 iter/s, 10.5669s/20 iters), loss = 2.58112
I0822 22:12:19.130988 31324 solver.cpp:273]     Train net output #0: loss = 2.58112 (* 1 = 2.58112 loss)
I0822 22:12:19.131005 31324 sgd_solver.cpp:790] Iteration 19840, lr = 0.01
I0822 22:12:29.771638 31324 solver.cpp:254] Iteration 19860 (1.8796 iter/s, 10.6406s/20 iters), loss = 2.51525
I0822 22:12:29.771697 31324 solver.cpp:273]     Train net output #0: loss = 2.51525 (* 1 = 2.51525 loss)
I0822 22:12:29.771708 31324 sgd_solver.cpp:790] Iteration 19860, lr = 0.01
I0822 22:12:40.054607 31324 solver.cpp:254] Iteration 19880 (1.94499 iter/s, 10.2828s/20 iters), loss = 2.79644
I0822 22:12:40.054667 31324 solver.cpp:273]     Train net output #0: loss = 2.79644 (* 1 = 2.79644 loss)
I0822 22:12:40.054679 31324 sgd_solver.cpp:790] Iteration 19880, lr = 0.01
I0822 22:12:50.327495 31324 solver.cpp:254] Iteration 19900 (1.9469 iter/s, 10.2728s/20 iters), loss = 2.75331
I0822 22:12:50.327641 31324 solver.cpp:273]     Train net output #0: loss = 2.75331 (* 1 = 2.75331 loss)
I0822 22:12:50.327651 31324 sgd_solver.cpp:790] Iteration 19900, lr = 0.01
I0822 22:13:01.104156 31324 solver.cpp:254] Iteration 19920 (1.8559 iter/s, 10.7764s/20 iters), loss = 2.48096
I0822 22:13:01.104248 31324 solver.cpp:273]     Train net output #0: loss = 2.48096 (* 1 = 2.48096 loss)
I0822 22:13:01.104267 31324 sgd_solver.cpp:790] Iteration 19920, lr = 0.01
I0822 22:13:10.950742 31324 solver.cpp:254] Iteration 19940 (2.03119 iter/s, 9.84643s/20 iters), loss = 2.47104
I0822 22:13:10.950804 31324 solver.cpp:273]     Train net output #0: loss = 2.47104 (* 1 = 2.47104 loss)
I0822 22:13:10.950819 31324 sgd_solver.cpp:790] Iteration 19940, lr = 0.01
I0822 22:13:20.075291 31324 solver.cpp:254] Iteration 19960 (2.19192 iter/s, 9.12442s/20 iters), loss = 2.53843
I0822 22:13:20.075351 31324 solver.cpp:273]     Train net output #0: loss = 2.53843 (* 1 = 2.53843 loss)
I0822 22:13:20.075363 31324 sgd_solver.cpp:790] Iteration 19960, lr = 0.01
I0822 22:13:29.161195 31324 solver.cpp:254] Iteration 19980 (2.20124 iter/s, 9.08578s/20 iters), loss = 2.55471
I0822 22:13:29.161343 31324 solver.cpp:273]     Train net output #0: loss = 2.55471 (* 1 = 2.55471 loss)
I0822 22:13:29.161357 31324 sgd_solver.cpp:790] Iteration 19980, lr = 0.01
I0822 22:13:38.747400 31324 solver.cpp:483] Snapshotting to binary proto file /data/kaiqi/24_prune_quantization01/caffe_alexnet_1st_retrain_iter_20000.caffemodel
I0822 22:13:39.870793 31324 sgd_solver.cpp:1201] Snapshotting solver state to binary proto file /data/kaiqi/24_prune_quantization01/caffe_alexnet_1st_retrain_iter_20000.solverstate
I0822 22:13:40.204303 31324 solver.cpp:366] Iteration 20000, Testing net (#0)
I0822 22:13:45.480021 31324 blocking_queue.cpp:49] Waiting for data
I0822 22:14:04.255822 31336 data_layer.cpp:73] Restarting data prefetching from start.
I0822 22:14:04.272042 31324 solver.cpp:433]     Test net output #0: accuracy = 0.47538
I0822 22:14:04.272090 31324 solver.cpp:433]     Test net output #1: accuracy5 = 0.73232
I0822 22:14:04.272104 31324 solver.cpp:433]     Test net output #2: loss = 2.33011 (* 1 = 2.33011 loss)
I0822 22:14:04.443213 31324 solver.cpp:254] Iteration 20000 (0.566866 iter/s, 35.2817s/20 iters), loss = 2.62985
I0822 22:14:04.445710 31324 solver.cpp:273]     Train net output #0: loss = 2.62985 (* 1 = 2.62985 loss)
I0822 22:14:04.445737 31324 sgd_solver.cpp:790] Iteration 20000, lr = 0.01
I0822 22:14:12.350405 31332 data_layer.cpp:73] Restarting data prefetching from start.
I0822 22:14:13.001562 31324 solver.cpp:254] Iteration 20020 (2.33759 iter/s, 8.5558s/20 iters), loss = 2.65272
I0822 22:14:13.014196 31324 solver.cpp:273]     Train net output #0: loss = 2.65272 (* 1 = 2.65272 loss)
I0822 22:14:13.014230 31324 sgd_solver.cpp:790] Iteration 20020, lr = 0.01
I0822 22:14:22.781242 31324 solver.cpp:254] Iteration 20040 (2.04771 iter/s, 9.767s/20 iters), loss = 2.34955
I0822 22:14:22.781317 31324 solver.cpp:273]     Train net output #0: loss = 2.34955 (* 1 = 2.34955 loss)
I0822 22:14:22.781330 31324 sgd_solver.cpp:790] Iteration 20040, lr = 0.01
I0822 22:14:33.364089 31324 solver.cpp:254] Iteration 20060 (1.88988 iter/s, 10.5827s/20 iters), loss = 2.58016
I0822 22:14:33.364153 31324 solver.cpp:273]     Train net output #0: loss = 2.58016 (* 1 = 2.58016 loss)
I0822 22:14:33.364166 31324 sgd_solver.cpp:790] Iteration 20060, lr = 0.01
I0822 22:14:44.116508 31324 solver.cpp:254] Iteration 20080 (1.86007 iter/s, 10.7523s/20 iters), loss = 2.52032
I0822 22:14:44.118235 31324 solver.cpp:273]     Train net output #0: loss = 2.52032 (* 1 = 2.52032 loss)
I0822 22:14:44.118249 31324 sgd_solver.cpp:790] Iteration 20080, lr = 0.01
I0822 22:14:54.707993 31324 solver.cpp:254] Iteration 20100 (1.88863 iter/s, 10.5897s/20 iters), loss = 2.47988
I0822 22:14:54.708060 31324 solver.cpp:273]     Train net output #0: loss = 2.47988 (* 1 = 2.47988 loss)
I0822 22:14:54.708070 31324 sgd_solver.cpp:790] Iteration 20100, lr = 0.01
I0822 22:15:04.864189 31324 solver.cpp:254] Iteration 20120 (1.96927 iter/s, 10.1561s/20 iters), loss = 2.56272
I0822 22:15:04.864264 31324 solver.cpp:273]     Train net output #0: loss = 2.56272 (* 1 = 2.56272 loss)
I0822 22:15:04.864277 31324 sgd_solver.cpp:790] Iteration 20120, lr = 0.01
I0822 22:15:15.420541 31324 solver.cpp:254] Iteration 20140 (1.89462 iter/s, 10.5562s/20 iters), loss = 2.61284
I0822 22:15:15.420696 31324 solver.cpp:273]     Train net output #0: loss = 2.61284 (* 1 = 2.61284 loss)
I0822 22:15:15.421897 31324 sgd_solver.cpp:790] Iteration 20140, lr = 0.01
I0822 22:15:25.837584 31324 solver.cpp:254] Iteration 20160 (1.91997 iter/s, 10.4168s/20 iters), loss = 2.39105
I0822 22:15:25.837669 31324 solver.cpp:273]     Train net output #0: loss = 2.39105 (* 1 = 2.39105 loss)
I0822 22:15:25.837683 31324 sgd_solver.cpp:790] Iteration 20160, lr = 0.01
I0822 22:15:36.483201 31324 solver.cpp:254] Iteration 20180 (1.87874 iter/s, 10.6455s/20 iters), loss = 2.5548
I0822 22:15:36.483273 31324 solver.cpp:273]     Train net output #0: loss = 2.5548 (* 1 = 2.5548 loss)
I0822 22:15:36.483292 31324 sgd_solver.cpp:790] Iteration 20180, lr = 0.01
I0822 22:15:47.031091 31324 solver.cpp:254] Iteration 20200 (1.89614 iter/s, 10.5477s/20 iters), loss = 2.51861
I0822 22:15:47.031250 31324 solver.cpp:273]     Train net output #0: loss = 2.51861 (* 1 = 2.51861 loss)
I0822 22:15:47.031263 31324 sgd_solver.cpp:790] Iteration 20200, lr = 0.01
I0822 22:15:57.578480 31324 solver.cpp:254] Iteration 20220 (1.89625 iter/s, 10.5471s/20 iters), loss = 2.37707
I0822 22:15:57.578579 31324 solver.cpp:273]     Train net output #0: loss = 2.37707 (* 1 = 2.37707 loss)
I0822 22:15:57.578600 31324 sgd_solver.cpp:790] Iteration 20220, lr = 0.01
I0822 22:15:57.985687 31324 blocking_queue.cpp:49] Waiting for data
I0822 22:16:07.414707 31324 solver.cpp:254] Iteration 20240 (2.03333 iter/s, 9.83606s/20 iters), loss = 2.65676
I0822 22:16:07.414777 31324 solver.cpp:273]     Train net output #0: loss = 2.65676 (* 1 = 2.65676 loss)
I0822 22:16:07.414790 31324 sgd_solver.cpp:790] Iteration 20240, lr = 0.01
I0822 22:16:17.081779 31324 solver.cpp:254] Iteration 20260 (2.06891 iter/s, 9.66692s/20 iters), loss = 2.46343
I0822 22:16:17.082360 31324 solver.cpp:273]     Train net output #0: loss = 2.46343 (* 1 = 2.46343 loss)
I0822 22:16:17.082373 31324 sgd_solver.cpp:790] Iteration 20260, lr = 0.01
I0822 22:16:26.396533 31324 solver.cpp:254] Iteration 20280 (2.14728 iter/s, 9.31411s/20 iters), loss = 2.63502
I0822 22:16:26.396589 31324 solver.cpp:273]     Train net output #0: loss = 2.63502 (* 1 = 2.63502 loss)
I0822 22:16:26.396600 31324 sgd_solver.cpp:790] Iteration 20280, lr = 0.01
I0822 22:16:35.690867 31324 solver.cpp:254] Iteration 20300 (2.15188 iter/s, 9.29421s/20 iters), loss = 2.76851
I0822 22:16:35.690930 31324 solver.cpp:273]     Train net output #0: loss = 2.76851 (* 1 = 2.76851 loss)
I0822 22:16:35.690944 31324 sgd_solver.cpp:790] Iteration 20300, lr = 0.01
I0822 22:16:46.107362 31324 solver.cpp:254] Iteration 20320 (1.92006 iter/s, 10.4164s/20 iters), loss = 2.7181
I0822 22:16:46.107452 31324 solver.cpp:273]     Train net output #0: loss = 2.7181 (* 1 = 2.7181 loss)
I0822 22:16:46.107470 31324 sgd_solver.cpp:790] Iteration 20320, lr = 0.01
I0822 22:16:56.730837 31324 solver.cpp:254] Iteration 20340 (1.88265 iter/s, 10.6233s/20 iters), loss = 2.75662
I0822 22:16:56.731005 31324 solver.cpp:273]     Train net output #0: loss = 2.75662 (* 1 = 2.75662 loss)
I0822 22:16:56.731017 31324 sgd_solver.cpp:790] Iteration 20340, lr = 0.01
I0822 22:17:07.298377 31324 solver.cpp:254] Iteration 20360 (1.89263 iter/s, 10.5673s/20 iters), loss = 2.45776
I0822 22:17:07.298441 31324 solver.cpp:273]     Train net output #0: loss = 2.45776 (* 1 = 2.45776 loss)
I0822 22:17:07.298452 31324 sgd_solver.cpp:790] Iteration 20360, lr = 0.01
I0822 22:17:17.874197 31324 solver.cpp:254] Iteration 20380 (1.89113 iter/s, 10.5757s/20 iters), loss = 2.45621
I0822 22:17:17.874269 31324 solver.cpp:273]     Train net output #0: loss = 2.45621 (* 1 = 2.45621 loss)
I0822 22:17:17.874279 31324 sgd_solver.cpp:790] Iteration 20380, lr = 0.01
I0822 22:17:28.193680 31324 solver.cpp:254] Iteration 20400 (1.93811 iter/s, 10.3193s/20 iters), loss = 2.51275
I0822 22:17:28.193850 31324 solver.cpp:273]     Train net output #0: loss = 2.51275 (* 1 = 2.51275 loss)
I0822 22:17:28.195510 31324 sgd_solver.cpp:790] Iteration 20400, lr = 0.01
I0822 22:17:38.421983 31324 solver.cpp:254] Iteration 20420 (1.9554 iter/s, 10.2281s/20 iters), loss = 2.49365
I0822 22:17:38.422049 31324 solver.cpp:273]     Train net output #0: loss = 2.49365 (* 1 = 2.49365 loss)
I0822 22:17:38.422060 31324 sgd_solver.cpp:790] Iteration 20420, lr = 0.01
I0822 22:17:49.155221 31324 solver.cpp:254] Iteration 20440 (1.8634 iter/s, 10.7331s/20 iters), loss = 2.52183
I0822 22:17:49.155285 31324 solver.cpp:273]     Train net output #0: loss = 2.52183 (* 1 = 2.52183 loss)
I0822 22:17:49.155295 31324 sgd_solver.cpp:790] Iteration 20440, lr = 0.01
I0822 22:17:59.910462 31324 solver.cpp:254] Iteration 20460 (1.85958 iter/s, 10.7551s/20 iters), loss = 2.49349
I0822 22:17:59.913996 31324 solver.cpp:273]     Train net output #0: loss = 2.49349 (* 1 = 2.49349 loss)
I0822 22:17:59.914021 31324 sgd_solver.cpp:790] Iteration 20460, lr = 0.01
I0822 22:18:09.423221 31324 solver.cpp:254] Iteration 20480 (2.10323 iter/s, 9.50917s/20 iters), loss = 2.81142
I0822 22:18:09.423274 31324 solver.cpp:273]     Train net output #0: loss = 2.81142 (* 1 = 2.81142 loss)
I0822 22:18:09.423285 31324 sgd_solver.cpp:790] Iteration 20480, lr = 0.01
I0822 22:18:18.425338 31324 solver.cpp:254] Iteration 20500 (2.22173 iter/s, 9.002s/20 iters), loss = 2.54658
I0822 22:18:18.425410 31324 solver.cpp:273]     Train net output #0: loss = 2.54658 (* 1 = 2.54658 loss)
I0822 22:18:18.425424 31324 sgd_solver.cpp:790] Iteration 20500, lr = 0.01
I0822 22:18:28.098260 31324 solver.cpp:254] Iteration 20520 (2.06766 iter/s, 9.67278s/20 iters), loss = 2.69643
I0822 22:18:28.098328 31324 solver.cpp:273]     Train net output #0: loss = 2.69643 (* 1 = 2.69643 loss)
I0822 22:18:28.098340 31324 sgd_solver.cpp:790] Iteration 20520, lr = 0.01
I0822 22:18:38.954219 31324 solver.cpp:254] Iteration 20540 (1.84233 iter/s, 10.8558s/20 iters), loss = 2.49866
I0822 22:18:38.954366 31324 solver.cpp:273]     Train net output #0: loss = 2.49866 (* 1 = 2.49866 loss)
I0822 22:18:38.954383 31324 sgd_solver.cpp:790] Iteration 20540, lr = 0.01
I0822 22:18:49.715219 31324 solver.cpp:254] Iteration 20560 (1.8586 iter/s, 10.7608s/20 iters), loss = 2.22303
I0822 22:18:49.715276 31324 solver.cpp:273]     Train net output #0: loss = 2.22303 (* 1 = 2.22303 loss)
I0822 22:18:49.715287 31324 sgd_solver.cpp:790] Iteration 20560, lr = 0.01
I0822 22:19:00.006528 31324 solver.cpp:254] Iteration 20580 (1.94341 iter/s, 10.2912s/20 iters), loss = 2.43936
I0822 22:19:00.006606 31324 solver.cpp:273]     Train net output #0: loss = 2.43936 (* 1 = 2.43936 loss)
I0822 22:19:00.006620 31324 sgd_solver.cpp:790] Iteration 20580, lr = 0.01
I0822 22:19:10.496307 31324 solver.cpp:254] Iteration 20600 (1.90664 iter/s, 10.4896s/20 iters), loss = 2.5512
I0822 22:19:10.496461 31324 solver.cpp:273]     Train net output #0: loss = 2.5512 (* 1 = 2.5512 loss)
I0822 22:19:10.496472 31324 sgd_solver.cpp:790] Iteration 20600, lr = 0.01
I0822 22:19:15.027482 31324 solver.cpp:254] Iteration 20620 (4.41405 iter/s, 4.53098s/20 iters), loss = 2.63734
I0822 22:19:15.039646 31324 solver.cpp:273]     Train net output #0: loss = 2.63734 (* 1 = 2.63734 loss)
I0822 22:19:15.039680 31324 sgd_solver.cpp:790] Iteration 20620, lr = 0.01
I0822 22:19:18.714226 31324 solver.cpp:254] Iteration 20640 (5.44284 iter/s, 3.67455s/20 iters), loss = 2.57415
I0822 22:19:18.726435 31324 solver.cpp:273]     Train net output #0: loss = 2.57415 (* 1 = 2.57415 loss)
I0822 22:19:18.726466 31324 sgd_solver.cpp:790] Iteration 20640, lr = 0.01
I0822 22:19:22.424932 31324 solver.cpp:254] Iteration 20660 (5.40763 iter/s, 3.69848s/20 iters), loss = 2.5847
I0822 22:19:22.437045 31324 solver.cpp:273]     Train net output #0: loss = 2.5847 (* 1 = 2.5847 loss)
I0822 22:19:22.437075 31324 sgd_solver.cpp:790] Iteration 20660, lr = 0.01
I0822 22:19:26.119513 31324 solver.cpp:254] Iteration 20680 (5.43117 iter/s, 3.68245s/20 iters), loss = 2.67703
I0822 22:19:26.131644 31324 solver.cpp:273]     Train net output #0: loss = 2.67703 (* 1 = 2.67703 loss)
I0822 22:19:26.131672 31324 sgd_solver.cpp:790] Iteration 20680, lr = 0.01
I0822 22:19:29.778147 31324 solver.cpp:254] Iteration 20700 (5.48474 iter/s, 3.64648s/20 iters), loss = 2.43679
I0822 22:19:29.790863 31324 solver.cpp:273]     Train net output #0: loss = 2.43679 (* 1 = 2.43679 loss)
I0822 22:19:29.790895 31324 sgd_solver.cpp:790] Iteration 20700, lr = 0.01
I0822 22:19:34.637224 31324 solver.cpp:254] Iteration 20720 (4.12682 iter/s, 4.84635s/20 iters), loss = 2.59349
I0822 22:19:34.637296 31324 solver.cpp:273]     Train net output #0: loss = 2.59349 (* 1 = 2.59349 loss)
I0822 22:19:34.637310 31324 sgd_solver.cpp:790] Iteration 20720, lr = 0.01
I0822 22:19:40.325234 31324 solver.cpp:254] Iteration 20740 (3.51624 iter/s, 5.6879s/20 iters), loss = 2.42475
I0822 22:19:40.337673 31324 solver.cpp:273]     Train net output #0: loss = 2.42475 (* 1 = 2.42475 loss)
I0822 22:19:40.337704 31324 sgd_solver.cpp:790] Iteration 20740, lr = 0.01
I0822 22:19:43.902899 31324 solver.cpp:254] Iteration 20760 (5.60978 iter/s, 3.5652s/20 iters), loss = 2.66606
I0822 22:19:43.915036 31324 solver.cpp:273]     Train net output #0: loss = 2.66606 (* 1 = 2.66606 loss)
I0822 22:19:43.915063 31324 sgd_solver.cpp:790] Iteration 20760, lr = 0.01
I0822 22:19:47.512601 31324 solver.cpp:254] Iteration 20780 (5.55935 iter/s, 3.59754s/20 iters), loss = 2.5141
I0822 22:19:47.524708 31324 solver.cpp:273]     Train net output #0: loss = 2.5141 (* 1 = 2.5141 loss)
I0822 22:19:47.524736 31324 sgd_solver.cpp:790] Iteration 20780, lr = 0.01
I0822 22:19:51.946614 31324 solver.cpp:254] Iteration 20800 (4.52295 iter/s, 4.42189s/20 iters), loss = 2.68192
I0822 22:19:51.946668 31324 solver.cpp:273]     Train net output #0: loss = 2.68192 (* 1 = 2.68192 loss)
I0822 22:19:51.946679 31324 sgd_solver.cpp:790] Iteration 20800, lr = 0.01
I0822 22:20:01.902000 31324 solver.cpp:254] Iteration 20820 (2.00899 iter/s, 9.95527s/20 iters), loss = 2.64599
I0822 22:20:01.902070 31324 solver.cpp:273]     Train net output #0: loss = 2.64599 (* 1 = 2.64599 loss)
I0822 22:20:01.902083 31324 sgd_solver.cpp:790] Iteration 20820, lr = 0.01
I0822 22:20:11.992357 31324 solver.cpp:254] Iteration 20840 (1.98212 iter/s, 10.0902s/20 iters), loss = 2.58941
I0822 22:20:11.992447 31324 solver.cpp:273]     Train net output #0: loss = 2.58941 (* 1 = 2.58941 loss)
I0822 22:20:11.992465 31324 sgd_solver.cpp:790] Iteration 20840, lr = 0.01
I0822 22:20:22.347918 31324 solver.cpp:254] Iteration 20860 (1.93136 iter/s, 10.3554s/20 iters), loss = 2.53877
I0822 22:20:22.348086 31324 solver.cpp:273]     Train net output #0: loss = 2.53877 (* 1 = 2.53877 loss)
I0822 22:20:22.348096 31324 sgd_solver.cpp:790] Iteration 20860, lr = 0.01
I0822 22:20:31.520125 31324 solver.cpp:254] Iteration 20880 (2.18056 iter/s, 9.17197s/20 iters), loss = 2.31927
I0822 22:20:31.520196 31324 solver.cpp:273]     Train net output #0: loss = 2.31927 (* 1 = 2.31927 loss)
I0822 22:20:31.520210 31324 sgd_solver.cpp:790] Iteration 20880, lr = 0.01
I0822 22:20:40.510942 31324 solver.cpp:254] Iteration 20900 (2.22453 iter/s, 8.99067s/20 iters), loss = 2.60887
I0822 22:20:40.511006 31324 solver.cpp:273]     Train net output #0: loss = 2.60887 (* 1 = 2.60887 loss)
I0822 22:20:40.511018 31324 sgd_solver.cpp:790] Iteration 20900, lr = 0.01
I0822 22:20:50.041249 31324 solver.cpp:254] Iteration 20920 (2.0986 iter/s, 9.53017s/20 iters), loss = 2.48366
I0822 22:20:50.041316 31324 solver.cpp:273]     Train net output #0: loss = 2.48366 (* 1 = 2.48366 loss)
I0822 22:20:50.041332 31324 sgd_solver.cpp:790] Iteration 20920, lr = 0.01
I0822 22:21:00.478297 31324 solver.cpp:254] Iteration 20940 (1.91628 iter/s, 10.4369s/20 iters), loss = 2.2786
I0822 22:21:00.479591 31324 solver.cpp:273]     Train net output #0: loss = 2.2786 (* 1 = 2.2786 loss)
I0822 22:21:00.479609 31324 sgd_solver.cpp:790] Iteration 20940, lr = 0.01
I0822 22:21:11.035776 31324 solver.cpp:254] Iteration 20960 (1.89464 iter/s, 10.5561s/20 iters), loss = 2.3309
I0822 22:21:11.035861 31324 solver.cpp:273]     Train net output #0: loss = 2.3309 (* 1 = 2.3309 loss)
I0822 22:21:11.035878 31324 sgd_solver.cpp:790] Iteration 20960, lr = 0.01
I0822 22:21:21.944547 31324 solver.cpp:254] Iteration 20980 (1.83342 iter/s, 10.9086s/20 iters), loss = 2.72837
I0822 22:21:21.944622 31324 solver.cpp:273]     Train net output #0: loss = 2.72837 (* 1 = 2.72837 loss)
I0822 22:21:21.944633 31324 sgd_solver.cpp:790] Iteration 20980, lr = 0.01
I0822 22:21:31.896303 31324 solver.cpp:366] Iteration 21000, Testing net (#0)
I0822 22:21:37.376945 31324 blocking_queue.cpp:49] Waiting for data
I0822 22:21:54.933106 31336 data_layer.cpp:73] Restarting data prefetching from start.
I0822 22:21:54.949483 31324 solver.cpp:433]     Test net output #0: accuracy = 0.47266
I0822 22:21:54.949519 31324 solver.cpp:433]     Test net output #1: accuracy5 = 0.730659
I0822 22:21:54.949528 31324 solver.cpp:433]     Test net output #2: loss = 2.34752 (* 1 = 2.34752 loss)
I0822 22:21:55.124976 31324 solver.cpp:254] Iteration 21000 (0.60277 iter/s, 33.1801s/20 iters), loss = 2.43135
I0822 22:21:55.127524 31324 solver.cpp:273]     Train net output #0: loss = 2.43135 (* 1 = 2.43135 loss)
I0822 22:21:55.127555 31324 sgd_solver.cpp:790] Iteration 21000, lr = 0.01
I0822 22:22:03.783305 31324 solver.cpp:254] Iteration 21020 (2.31061 iter/s, 8.65574s/20 iters), loss = 2.48785
I0822 22:22:03.783427 31324 solver.cpp:273]     Train net output #0: loss = 2.48785 (* 1 = 2.48785 loss)
I0822 22:22:03.783442 31324 sgd_solver.cpp:790] Iteration 21020, lr = 0.01
I0822 22:22:12.543156 31324 solver.cpp:254] Iteration 21040 (2.28319 iter/s, 8.75967s/20 iters), loss = 2.76302
I0822 22:22:12.543222 31324 solver.cpp:273]     Train net output #0: loss = 2.76302 (* 1 = 2.76302 loss)
I0822 22:22:12.543238 31324 sgd_solver.cpp:790] Iteration 21040, lr = 0.01
I0822 22:22:22.058853 31324 solver.cpp:254] Iteration 21060 (2.10182 iter/s, 9.51556s/20 iters), loss = 2.49695
I0822 22:22:22.058912 31324 solver.cpp:273]     Train net output #0: loss = 2.49695 (* 1 = 2.49695 loss)
I0822 22:22:22.058923 31324 sgd_solver.cpp:790] Iteration 21060, lr = 0.01
I0822 22:22:32.571072 31324 solver.cpp:254] Iteration 21080 (1.90257 iter/s, 10.5121s/20 iters), loss = 2.68093
I0822 22:22:32.571146 31324 solver.cpp:273]     Train net output #0: loss = 2.68093 (* 1 = 2.68093 loss)
I0822 22:22:32.571161 31324 sgd_solver.cpp:790] Iteration 21080, lr = 0.01
I0822 22:22:43.082792 31324 solver.cpp:254] Iteration 21100 (1.90267 iter/s, 10.5116s/20 iters), loss = 2.68809
I0822 22:22:43.082988 31324 solver.cpp:273]     Train net output #0: loss = 2.68809 (* 1 = 2.68809 loss)
I0822 22:22:43.083004 31324 sgd_solver.cpp:790] Iteration 21100, lr = 0.01
I0822 22:22:53.355343 31324 solver.cpp:254] Iteration 21120 (1.94699 iter/s, 10.2723s/20 iters), loss = 2.51019
I0822 22:22:53.355407 31324 solver.cpp:273]     Train net output #0: loss = 2.51019 (* 1 = 2.51019 loss)
I0822 22:22:53.355420 31324 sgd_solver.cpp:790] Iteration 21120, lr = 0.01
I0822 22:23:03.616214 31324 solver.cpp:254] Iteration 21140 (1.94918 iter/s, 10.2607s/20 iters), loss = 2.39113
I0822 22:23:03.616281 31324 solver.cpp:273]     Train net output #0: loss = 2.39113 (* 1 = 2.39113 loss)
I0822 22:23:03.618193 31324 sgd_solver.cpp:790] Iteration 21140, lr = 0.01
I0822 22:23:14.135237 31324 solver.cpp:254] Iteration 21160 (1.90135 iter/s, 10.5189s/20 iters), loss = 2.50664
I0822 22:23:14.135438 31324 solver.cpp:273]     Train net output #0: loss = 2.50664 (* 1 = 2.50664 loss)
I0822 22:23:14.136503 31324 sgd_solver.cpp:790] Iteration 21160, lr = 0.01
I0822 22:23:24.645934 31324 solver.cpp:254] Iteration 21180 (1.90287 iter/s, 10.5104s/20 iters), loss = 2.71189
I0822 22:23:24.645997 31324 solver.cpp:273]     Train net output #0: loss = 2.71189 (* 1 = 2.71189 loss)
I0822 22:23:24.646735 31324 sgd_solver.cpp:790] Iteration 21180, lr = 0.01
I0822 22:23:35.098094 31324 solver.cpp:254] Iteration 21200 (1.91351 iter/s, 10.452s/20 iters), loss = 2.39104
I0822 22:23:35.098173 31324 solver.cpp:273]     Train net output #0: loss = 2.39104 (* 1 = 2.39104 loss)
I0822 22:23:35.098193 31324 sgd_solver.cpp:790] Iteration 21200, lr = 0.01
I0822 22:23:45.664626 31324 solver.cpp:254] Iteration 21220 (1.8928 iter/s, 10.5664s/20 iters), loss = 2.78284
I0822 22:23:45.664816 31324 solver.cpp:273]     Train net output #0: loss = 2.78284 (* 1 = 2.78284 loss)
I0822 22:23:45.665969 31324 sgd_solver.cpp:790] Iteration 21220, lr = 0.01
I0822 22:23:54.366513 31324 blocking_queue.cpp:49] Waiting for data
I0822 22:23:56.056293 31324 solver.cpp:254] Iteration 21240 (1.92467 iter/s, 10.3914s/20 iters), loss = 2.67548
I0822 22:23:56.056351 31324 solver.cpp:273]     Train net output #0: loss = 2.67548 (* 1 = 2.67548 loss)
I0822 22:23:56.056362 31324 sgd_solver.cpp:790] Iteration 21240, lr = 0.01
I0822 22:24:06.518183 31324 solver.cpp:254] Iteration 21260 (1.91172 iter/s, 10.4618s/20 iters), loss = 2.70179
I0822 22:24:06.518260 31324 solver.cpp:273]     Train net output #0: loss = 2.70179 (* 1 = 2.70179 loss)
I0822 22:24:06.518280 31324 sgd_solver.cpp:790] Iteration 21260, lr = 0.01
I0822 22:24:17.190233 31324 solver.cpp:254] Iteration 21280 (1.87408 iter/s, 10.6719s/20 iters), loss = 2.61992
I0822 22:24:17.190398 31324 solver.cpp:273]     Train net output #0: loss = 2.61992 (* 1 = 2.61992 loss)
I0822 22:24:17.190415 31324 sgd_solver.cpp:790] Iteration 21280, lr = 0.01
I0822 22:24:27.749836 31324 solver.cpp:254] Iteration 21300 (1.89405 iter/s, 10.5594s/20 iters), loss = 2.37397
I0822 22:24:27.749899 31324 solver.cpp:273]     Train net output #0: loss = 2.37397 (* 1 = 2.37397 loss)
I0822 22:24:27.749910 31324 sgd_solver.cpp:790] Iteration 21300, lr = 0.01
I0822 22:24:38.168787 31324 solver.cpp:254] Iteration 21320 (1.9196 iter/s, 10.4188s/20 iters), loss = 2.73254
I0822 22:24:38.168866 31324 solver.cpp:273]     Train net output #0: loss = 2.73254 (* 1 = 2.73254 loss)
I0822 22:24:38.168881 31324 sgd_solver.cpp:790] Iteration 21320, lr = 0.01
I0822 22:24:48.405913 31324 solver.cpp:254] Iteration 21340 (1.9537 iter/s, 10.237s/20 iters), loss = 2.5437
I0822 22:24:48.406129 31324 solver.cpp:273]     Train net output #0: loss = 2.5437 (* 1 = 2.5437 loss)
I0822 22:24:48.406147 31324 sgd_solver.cpp:790] Iteration 21340, lr = 0.01
I0822 22:24:58.941247 31324 solver.cpp:254] Iteration 21360 (1.89842 iter/s, 10.5351s/20 iters), loss = 2.61493
I0822 22:24:58.941316 31324 solver.cpp:273]     Train net output #0: loss = 2.61493 (* 1 = 2.61493 loss)
I0822 22:24:58.941329 31324 sgd_solver.cpp:790] Iteration 21360, lr = 0.01
I0822 22:25:09.495398 31324 solver.cpp:254] Iteration 21380 (1.89501 iter/s, 10.554s/20 iters), loss = 2.60691
I0822 22:25:09.495483 31324 solver.cpp:273]     Train net output #0: loss = 2.60691 (* 1 = 2.60691 loss)
I0822 22:25:09.495507 31324 sgd_solver.cpp:790] Iteration 21380, lr = 0.01
I0822 22:25:19.855298 31324 solver.cpp:254] Iteration 21400 (1.93055 iter/s, 10.3598s/20 iters), loss = 2.27933
I0822 22:25:19.855510 31324 solver.cpp:273]     Train net output #0: loss = 2.27933 (* 1 = 2.27933 loss)
I0822 22:25:19.855525 31324 sgd_solver.cpp:790] Iteration 21400, lr = 0.01
I0822 22:25:30.472698 31324 solver.cpp:254] Iteration 21420 (1.88375 iter/s, 10.6171s/20 iters), loss = 2.5237
I0822 22:25:30.472780 31324 solver.cpp:273]     Train net output #0: loss = 2.5237 (* 1 = 2.5237 loss)
I0822 22:25:30.472795 31324 sgd_solver.cpp:790] Iteration 21420, lr = 0.01
I0822 22:25:40.942760 31324 solver.cpp:254] Iteration 21440 (1.91023 iter/s, 10.4699s/20 iters), loss = 2.78347
I0822 22:25:40.942817 31324 solver.cpp:273]     Train net output #0: loss = 2.78347 (* 1 = 2.78347 loss)
I0822 22:25:40.942829 31324 sgd_solver.cpp:790] Iteration 21440, lr = 0.01
I0822 22:25:51.493921 31324 solver.cpp:254] Iteration 21460 (1.89554 iter/s, 10.5511s/20 iters), loss = 2.45529
I0822 22:25:51.494061 31324 solver.cpp:273]     Train net output #0: loss = 2.45529 (* 1 = 2.45529 loss)
I0822 22:25:51.494076 31324 sgd_solver.cpp:790] Iteration 21460, lr = 0.01
I0822 22:26:00.653060 31324 solver.cpp:254] Iteration 21480 (2.18365 iter/s, 9.15896s/20 iters), loss = 2.55047
I0822 22:26:00.653116 31324 solver.cpp:273]     Train net output #0: loss = 2.55047 (* 1 = 2.55047 loss)
I0822 22:26:00.653127 31324 sgd_solver.cpp:790] Iteration 21480, lr = 0.01
I0822 22:26:09.618927 31324 solver.cpp:254] Iteration 21500 (2.23071 iter/s, 8.96577s/20 iters), loss = 2.52283
I0822 22:26:09.619005 31324 solver.cpp:273]     Train net output #0: loss = 2.52283 (* 1 = 2.52283 loss)
I0822 22:26:09.619020 31324 sgd_solver.cpp:790] Iteration 21500, lr = 0.01
I0822 22:26:19.077945 31324 solver.cpp:254] Iteration 21520 (2.11441 iter/s, 9.4589s/20 iters), loss = 2.42137
I0822 22:26:19.078017 31324 solver.cpp:273]     Train net output #0: loss = 2.42137 (* 1 = 2.42137 loss)
I0822 22:26:19.078032 31324 sgd_solver.cpp:790] Iteration 21520, lr = 0.01
I0822 22:26:28.339010 31324 solver.cpp:254] Iteration 21540 (2.1596 iter/s, 9.26096s/20 iters), loss = 2.57614
I0822 22:26:28.339174 31324 solver.cpp:273]     Train net output #0: loss = 2.57614 (* 1 = 2.57614 loss)
I0822 22:26:28.339187 31324 sgd_solver.cpp:790] Iteration 21540, lr = 0.01
I0822 22:26:37.980388 31324 solver.cpp:254] Iteration 21560 (2.07444 iter/s, 9.64118s/20 iters), loss = 2.56141
I0822 22:26:37.980443 31324 solver.cpp:273]     Train net output #0: loss = 2.56141 (* 1 = 2.56141 loss)
I0822 22:26:37.980453 31324 sgd_solver.cpp:790] Iteration 21560, lr = 0.01
I0822 22:26:47.961781 31324 solver.cpp:254] Iteration 21580 (2.00375 iter/s, 9.98128s/20 iters), loss = 2.49125
I0822 22:26:47.961841 31324 solver.cpp:273]     Train net output #0: loss = 2.49125 (* 1 = 2.49125 loss)
I0822 22:26:47.961851 31324 sgd_solver.cpp:790] Iteration 21580, lr = 0.01
I0822 22:26:57.255307 31324 solver.cpp:254] Iteration 21600 (2.15206 iter/s, 9.29341s/20 iters), loss = 2.72746
I0822 22:26:57.255395 31324 solver.cpp:273]     Train net output #0: loss = 2.72746 (* 1 = 2.72746 loss)
I0822 22:26:57.256359 31324 sgd_solver.cpp:790] Iteration 21600, lr = 0.01
I0822 22:27:06.539165 31324 solver.cpp:254] Iteration 21620 (2.15431 iter/s, 9.28373s/20 iters), loss = 2.43839
I0822 22:27:06.539321 31324 solver.cpp:273]     Train net output #0: loss = 2.43839 (* 1 = 2.43839 loss)
I0822 22:27:06.539335 31324 sgd_solver.cpp:790] Iteration 21620, lr = 0.01
I0822 22:27:16.738751 31324 solver.cpp:254] Iteration 21640 (1.9609 iter/s, 10.1994s/20 iters), loss = 2.86835
I0822 22:27:16.738816 31324 solver.cpp:273]     Train net output #0: loss = 2.86835 (* 1 = 2.86835 loss)
I0822 22:27:16.738826 31324 sgd_solver.cpp:790] Iteration 21640, lr = 0.01
I0822 22:27:27.232074 31324 solver.cpp:254] Iteration 21660 (1.90599 iter/s, 10.4932s/20 iters), loss = 2.62582
I0822 22:27:27.232151 31324 solver.cpp:273]     Train net output #0: loss = 2.62582 (* 1 = 2.62582 loss)
I0822 22:27:27.233884 31324 sgd_solver.cpp:790] Iteration 21660, lr = 0.01
I0822 22:27:37.805244 31324 solver.cpp:254] Iteration 21680 (1.8916 iter/s, 10.573s/20 iters), loss = 2.39804
I0822 22:27:37.805943 31324 solver.cpp:273]     Train net output #0: loss = 2.39804 (* 1 = 2.39804 loss)
I0822 22:27:37.805959 31324 sgd_solver.cpp:790] Iteration 21680, lr = 0.01
I0822 22:27:48.478813 31324 solver.cpp:254] Iteration 21700 (1.87392 iter/s, 10.6728s/20 iters), loss = 2.43523
I0822 22:27:48.478888 31324 solver.cpp:273]     Train net output #0: loss = 2.43523 (* 1 = 2.43523 loss)
I0822 22:27:48.478900 31324 sgd_solver.cpp:790] Iteration 21700, lr = 0.01
I0822 22:27:59.259671 31324 solver.cpp:254] Iteration 21720 (1.85516 iter/s, 10.7807s/20 iters), loss = 2.70579
I0822 22:27:59.259744 31324 solver.cpp:273]     Train net output #0: loss = 2.70579 (* 1 = 2.70579 loss)
I0822 22:27:59.259757 31324 sgd_solver.cpp:790] Iteration 21720, lr = 0.01
I0822 22:28:09.513870 31324 solver.cpp:254] Iteration 21740 (1.95044 iter/s, 10.2541s/20 iters), loss = 2.63767
I0822 22:28:09.516290 31324 solver.cpp:273]     Train net output #0: loss = 2.63767 (* 1 = 2.63767 loss)
I0822 22:28:09.516304 31324 sgd_solver.cpp:790] Iteration 21740, lr = 0.01
I0822 22:28:19.486167 31324 solver.cpp:254] Iteration 21760 (2.00605 iter/s, 9.96982s/20 iters), loss = 2.416
I0822 22:28:19.486248 31324 solver.cpp:273]     Train net output #0: loss = 2.416 (* 1 = 2.416 loss)
I0822 22:28:19.486264 31324 sgd_solver.cpp:790] Iteration 21760, lr = 0.01
I0822 22:28:28.700067 31324 solver.cpp:254] Iteration 21780 (2.17066 iter/s, 9.21378s/20 iters), loss = 2.31427
I0822 22:28:28.700129 31324 solver.cpp:273]     Train net output #0: loss = 2.31427 (* 1 = 2.31427 loss)
I0822 22:28:28.700140 31324 sgd_solver.cpp:790] Iteration 21780, lr = 0.01
I0822 22:28:37.841675 31324 solver.cpp:254] Iteration 21800 (2.18783 iter/s, 9.1415s/20 iters), loss = 2.4229
I0822 22:28:37.841758 31324 solver.cpp:273]     Train net output #0: loss = 2.4229 (* 1 = 2.4229 loss)
I0822 22:28:37.841773 31324 sgd_solver.cpp:790] Iteration 21800, lr = 0.01
I0822 22:28:48.170495 31324 solver.cpp:254] Iteration 21820 (1.93635 iter/s, 10.3287s/20 iters), loss = 2.36018
I0822 22:28:48.170646 31324 solver.cpp:273]     Train net output #0: loss = 2.36018 (* 1 = 2.36018 loss)
I0822 22:28:48.170660 31324 sgd_solver.cpp:790] Iteration 21820, lr = 0.01
I0822 22:28:58.756983 31324 solver.cpp:254] Iteration 21840 (1.88924 iter/s, 10.5863s/20 iters), loss = 2.54885
I0822 22:28:58.757045 31324 solver.cpp:273]     Train net output #0: loss = 2.54885 (* 1 = 2.54885 loss)
I0822 22:28:58.757056 31324 sgd_solver.cpp:790] Iteration 21840, lr = 0.01
I0822 22:29:09.291240 31324 solver.cpp:254] Iteration 21860 (1.89859 iter/s, 10.5341s/20 iters), loss = 2.41852
I0822 22:29:09.291302 31324 solver.cpp:273]     Train net output #0: loss = 2.41852 (* 1 = 2.41852 loss)
I0822 22:29:09.291316 31324 sgd_solver.cpp:790] Iteration 21860, lr = 0.01
I0822 22:29:19.791275 31324 solver.cpp:254] Iteration 21880 (1.90478 iter/s, 10.4999s/20 iters), loss = 2.72219
I0822 22:29:19.791427 31324 solver.cpp:273]     Train net output #0: loss = 2.72219 (* 1 = 2.72219 loss)
I0822 22:29:19.791440 31324 sgd_solver.cpp:790] Iteration 21880, lr = 0.01
I0822 22:29:30.082995 31324 solver.cpp:254] Iteration 21900 (1.94335 iter/s, 10.2915s/20 iters), loss = 2.69954
I0822 22:29:30.083075 31324 solver.cpp:273]     Train net output #0: loss = 2.69954 (* 1 = 2.69954 loss)
I0822 22:29:30.083091 31324 sgd_solver.cpp:790] Iteration 21900, lr = 0.01
I0822 22:29:40.749439 31324 solver.cpp:254] Iteration 21920 (1.87506 iter/s, 10.6663s/20 iters), loss = 2.28843
I0822 22:29:40.749501 31324 solver.cpp:273]     Train net output #0: loss = 2.28843 (* 1 = 2.28843 loss)
I0822 22:29:40.749511 31324 sgd_solver.cpp:790] Iteration 21920, lr = 0.01
I0822 22:29:51.200358 31324 solver.cpp:254] Iteration 21940 (1.91373 iter/s, 10.4508s/20 iters), loss = 2.44837
I0822 22:29:51.200515 31324 solver.cpp:273]     Train net output #0: loss = 2.44837 (* 1 = 2.44837 loss)
I0822 22:29:51.200526 31324 sgd_solver.cpp:790] Iteration 21940, lr = 0.01
I0822 22:30:01.733108 31324 solver.cpp:254] Iteration 21960 (1.89888 iter/s, 10.5325s/20 iters), loss = 2.42498
I0822 22:30:01.733172 31324 solver.cpp:273]     Train net output #0: loss = 2.42498 (* 1 = 2.42498 loss)
I0822 22:30:01.733183 31324 sgd_solver.cpp:790] Iteration 21960, lr = 0.01
I0822 22:30:12.100437 31324 solver.cpp:254] Iteration 21980 (1.92916 iter/s, 10.3672s/20 iters), loss = 2.3475
I0822 22:30:12.100508 31324 solver.cpp:273]     Train net output #0: loss = 2.3475 (* 1 = 2.3475 loss)
I0822 22:30:12.100522 31324 sgd_solver.cpp:790] Iteration 21980, lr = 0.01
I0822 22:30:22.183403 31324 solver.cpp:366] Iteration 22000, Testing net (#0)
I0822 22:30:27.875270 31324 blocking_queue.cpp:49] Waiting for data
I0822 22:30:45.244917 31336 data_layer.cpp:73] Restarting data prefetching from start.
I0822 22:30:45.260967 31324 solver.cpp:433]     Test net output #0: accuracy = 0.4681
I0822 22:30:45.261019 31324 solver.cpp:433]     Test net output #1: accuracy5 = 0.727519
I0822 22:30:45.261035 31324 solver.cpp:433]     Test net output #2: loss = 2.36254 (* 1 = 2.36254 loss)
I0822 22:30:45.428912 31324 solver.cpp:254] Iteration 22000 (0.600091 iter/s, 33.3283s/20 iters), loss = 2.4562
I0822 22:30:45.431288 31324 solver.cpp:273]     Train net output #0: loss = 2.4562 (* 1 = 2.4562 loss)
I0822 22:30:45.431308 31324 sgd_solver.cpp:790] Iteration 22000, lr = 0.01
I0822 22:30:53.764824 31324 solver.cpp:254] Iteration 22020 (2.39995 iter/s, 8.3335s/20 iters), loss = 2.63705
I0822 22:30:53.766326 31324 solver.cpp:273]     Train net output #0: loss = 2.63705 (* 1 = 2.63705 loss)
I0822 22:30:53.766342 31324 sgd_solver.cpp:790] Iteration 22020, lr = 0.01
I0822 22:31:02.860229 31324 solver.cpp:254] Iteration 22040 (2.19928 iter/s, 9.09388s/20 iters), loss = 2.59461
I0822 22:31:02.860283 31324 solver.cpp:273]     Train net output #0: loss = 2.59461 (* 1 = 2.59461 loss)
I0822 22:31:02.860293 31324 sgd_solver.cpp:790] Iteration 22040, lr = 0.01
I0822 22:31:11.985316 31324 solver.cpp:254] Iteration 22060 (2.19178 iter/s, 9.12499s/20 iters), loss = 2.8087
I0822 22:31:11.985368 31324 solver.cpp:273]     Train net output #0: loss = 2.8087 (* 1 = 2.8087 loss)
I0822 22:31:11.985378 31324 sgd_solver.cpp:790] Iteration 22060, lr = 0.01
I0822 22:31:22.363224 31324 solver.cpp:254] Iteration 22080 (1.92719 iter/s, 10.3778s/20 iters), loss = 2.62941
I0822 22:31:22.363314 31324 solver.cpp:273]     Train net output #0: loss = 2.62941 (* 1 = 2.62941 loss)
I0822 22:31:22.363328 31324 sgd_solver.cpp:790] Iteration 22080, lr = 0.01
I0822 22:31:33.142115 31324 solver.cpp:254] Iteration 22100 (1.8555 iter/s, 10.7787s/20 iters), loss = 2.54275
I0822 22:31:33.142284 31324 solver.cpp:273]     Train net output #0: loss = 2.54275 (* 1 = 2.54275 loss)
I0822 22:31:33.142300 31324 sgd_solver.cpp:790] Iteration 22100, lr = 0.01
I0822 22:31:43.553831 31324 solver.cpp:254] Iteration 22120 (1.92095 iter/s, 10.4115s/20 iters), loss = 2.53462
I0822 22:31:43.553905 31324 solver.cpp:273]     Train net output #0: loss = 2.53462 (* 1 = 2.53462 loss)
I0822 22:31:43.553925 31324 sgd_solver.cpp:790] Iteration 22120, lr = 0.01
I0822 22:31:54.117333 31324 solver.cpp:254] Iteration 22140 (1.89334 iter/s, 10.5634s/20 iters), loss = 2.47029
I0822 22:31:54.117404 31324 solver.cpp:273]     Train net output #0: loss = 2.47029 (* 1 = 2.47029 loss)
I0822 22:31:54.117419 31324 sgd_solver.cpp:790] Iteration 22140, lr = 0.01
I0822 22:32:04.529129 31324 solver.cpp:254] Iteration 22160 (1.92092 iter/s, 10.4117s/20 iters), loss = 2.34112
I0822 22:32:04.529275 31324 solver.cpp:273]     Train net output #0: loss = 2.34112 (* 1 = 2.34112 loss)
I0822 22:32:04.529287 31324 sgd_solver.cpp:790] Iteration 22160, lr = 0.01
I0822 22:32:14.758968 31324 solver.cpp:254] Iteration 22180 (1.95511 iter/s, 10.2296s/20 iters), loss = 2.7928
I0822 22:32:14.759037 31324 solver.cpp:273]     Train net output #0: loss = 2.7928 (* 1 = 2.7928 loss)
I0822 22:32:14.759050 31324 sgd_solver.cpp:790] Iteration 22180, lr = 0.01
I0822 22:32:25.092730 31324 solver.cpp:254] Iteration 22200 (1.93543 iter/s, 10.3336s/20 iters), loss = 2.50927
I0822 22:32:25.092787 31324 solver.cpp:273]     Train net output #0: loss = 2.50927 (* 1 = 2.50927 loss)
I0822 22:32:25.092797 31324 sgd_solver.cpp:790] Iteration 22200, lr = 0.01
I0822 22:32:35.508810 31324 solver.cpp:254] Iteration 22220 (1.92013 iter/s, 10.416s/20 iters), loss = 2.75682
I0822 22:32:35.508998 31324 solver.cpp:273]     Train net output #0: loss = 2.75682 (* 1 = 2.75682 loss)
I0822 22:32:35.509012 31324 sgd_solver.cpp:790] Iteration 22220, lr = 0.01
I0822 22:32:43.768513 31324 solver.cpp:254] Iteration 22240 (2.42147 iter/s, 8.25946s/20 iters), loss = 2.58536
I0822 22:32:43.780691 31324 solver.cpp:273]     Train net output #0: loss = 2.58536 (* 1 = 2.58536 loss)
I0822 22:32:43.780730 31324 sgd_solver.cpp:790] Iteration 22240, lr = 0.01
I0822 22:32:45.751163 31324 blocking_queue.cpp:49] Waiting for data
I0822 22:32:53.468677 31324 solver.cpp:254] Iteration 22260 (2.06442 iter/s, 9.68795s/20 iters), loss = 2.6773
I0822 22:32:53.468752 31324 solver.cpp:273]     Train net output #0: loss = 2.6773 (* 1 = 2.6773 loss)
I0822 22:32:53.468768 31324 sgd_solver.cpp:790] Iteration 22260, lr = 0.01
I0822 22:33:03.765830 31324 solver.cpp:254] Iteration 22280 (1.94231 iter/s, 10.297s/20 iters), loss = 2.49345
I0822 22:33:03.765902 31324 solver.cpp:273]     Train net output #0: loss = 2.49345 (* 1 = 2.49345 loss)
I0822 22:33:03.765914 31324 sgd_solver.cpp:790] Iteration 22280, lr = 0.01
I0822 22:33:14.527746 31324 solver.cpp:254] Iteration 22300 (1.85843 iter/s, 10.7618s/20 iters), loss = 2.78386
I0822 22:33:14.527896 31324 solver.cpp:273]     Train net output #0: loss = 2.78386 (* 1 = 2.78386 loss)
I0822 22:33:14.527909 31324 sgd_solver.cpp:790] Iteration 22300, lr = 0.01
I0822 22:33:24.892750 31324 solver.cpp:254] Iteration 22320 (1.92961 iter/s, 10.3648s/20 iters), loss = 2.56088
I0822 22:33:24.892808 31324 solver.cpp:273]     Train net output #0: loss = 2.56088 (* 1 = 2.56088 loss)
I0822 22:33:24.892820 31324 sgd_solver.cpp:790] Iteration 22320, lr = 0.01
I0822 22:33:35.372761 31324 solver.cpp:254] Iteration 22340 (1.90842 iter/s, 10.4799s/20 iters), loss = 2.44055
I0822 22:33:35.372836 31324 solver.cpp:273]     Train net output #0: loss = 2.44055 (* 1 = 2.44055 loss)
I0822 22:33:35.372850 31324 sgd_solver.cpp:790] Iteration 22340, lr = 0.01
I0822 22:33:45.687439 31324 solver.cpp:254] Iteration 22360 (1.93901 iter/s, 10.3145s/20 iters), loss = 2.70726
I0822 22:33:45.687585 31324 solver.cpp:273]     Train net output #0: loss = 2.70726 (* 1 = 2.70726 loss)
I0822 22:33:45.687597 31324 sgd_solver.cpp:790] Iteration 22360, lr = 0.01
I0822 22:33:55.866470 31324 solver.cpp:254] Iteration 22380 (1.96486 iter/s, 10.1788s/20 iters), loss = 2.17295
I0822 22:33:55.866529 31324 solver.cpp:273]     Train net output #0: loss = 2.17295 (* 1 = 2.17295 loss)
I0822 22:33:55.866540 31324 sgd_solver.cpp:790] Iteration 22380, lr = 0.01
I0822 22:34:06.307847 31324 solver.cpp:254] Iteration 22400 (1.91548 iter/s, 10.4413s/20 iters), loss = 2.62251
I0822 22:34:06.307909 31324 solver.cpp:273]     Train net output #0: loss = 2.62251 (* 1 = 2.62251 loss)
I0822 22:34:06.307917 31324 sgd_solver.cpp:790] Iteration 22400, lr = 0.01
I0822 22:34:16.610613 31324 solver.cpp:254] Iteration 22420 (1.94125 iter/s, 10.3026s/20 iters), loss = 2.38744
I0822 22:34:16.610785 31324 solver.cpp:273]     Train net output #0: loss = 2.38744 (* 1 = 2.38744 loss)
I0822 22:34:16.610800 31324 sgd_solver.cpp:790] Iteration 22420, lr = 0.01
I0822 22:34:26.953897 31324 solver.cpp:254] Iteration 22440 (1.93367 iter/s, 10.3431s/20 iters), loss = 2.42685
I0822 22:34:26.953969 31324 solver.cpp:273]     Train net output #0: loss = 2.42685 (* 1 = 2.42685 loss)
I0822 22:34:26.953982 31324 sgd_solver.cpp:790] Iteration 22440, lr = 0.01
I0822 22:34:37.342701 31324 solver.cpp:254] Iteration 22460 (1.92517 iter/s, 10.3887s/20 iters), loss = 2.4361
I0822 22:34:37.342763 31324 solver.cpp:273]     Train net output #0: loss = 2.4361 (* 1 = 2.4361 loss)
I0822 22:34:37.342774 31324 sgd_solver.cpp:790] Iteration 22460, lr = 0.01
I0822 22:34:47.338944 31324 solver.cpp:254] Iteration 22480 (2.00078 iter/s, 9.99611s/20 iters), loss = 2.55184
I0822 22:34:47.339128 31324 solver.cpp:273]     Train net output #0: loss = 2.55184 (* 1 = 2.55184 loss)
I0822 22:34:47.339141 31324 sgd_solver.cpp:790] Iteration 22480, lr = 0.01
I0822 22:34:57.535883 31324 solver.cpp:254] Iteration 22500 (1.96142 iter/s, 10.1967s/20 iters), loss = 2.52846
I0822 22:34:57.535944 31324 solver.cpp:273]     Train net output #0: loss = 2.52846 (* 1 = 2.52846 loss)
I0822 22:34:57.535957 31324 sgd_solver.cpp:790] Iteration 22500, lr = 0.01
I0822 22:35:07.724180 31324 solver.cpp:254] Iteration 22520 (1.96306 iter/s, 10.1882s/20 iters), loss = 2.47283
I0822 22:35:07.724253 31324 solver.cpp:273]     Train net output #0: loss = 2.47283 (* 1 = 2.47283 loss)
I0822 22:35:07.724267 31324 sgd_solver.cpp:790] Iteration 22520, lr = 0.01
I0822 22:35:18.053248 31324 solver.cpp:254] Iteration 22540 (1.93631 iter/s, 10.3289s/20 iters), loss = 2.41746
I0822 22:35:18.057013 31324 solver.cpp:273]     Train net output #0: loss = 2.41746 (* 1 = 2.41746 loss)
I0822 22:35:18.057035 31324 sgd_solver.cpp:790] Iteration 22540, lr = 0.01
I0822 22:35:28.680938 31324 solver.cpp:254] Iteration 22560 (1.88255 iter/s, 10.6239s/20 iters), loss = 2.30894
I0822 22:35:28.680999 31324 solver.cpp:273]     Train net output #0: loss = 2.30894 (* 1 = 2.30894 loss)
I0822 22:35:28.681010 31324 sgd_solver.cpp:790] Iteration 22560, lr = 0.01
I0822 22:35:38.442070 31324 solver.cpp:254] Iteration 22580 (2.04897 iter/s, 9.76102s/20 iters), loss = 2.6407
I0822 22:35:38.442126 31324 solver.cpp:273]     Train net output #0: loss = 2.6407 (* 1 = 2.6407 loss)
I0822 22:35:38.442136 31324 sgd_solver.cpp:790] Iteration 22580, lr = 0.01
I0822 22:35:47.706491 31324 solver.cpp:254] Iteration 22600 (2.15882 iter/s, 9.26431s/20 iters), loss = 2.77506
I0822 22:35:47.706548 31324 solver.cpp:273]     Train net output #0: loss = 2.77506 (* 1 = 2.77506 loss)
I0822 22:35:47.706560 31324 sgd_solver.cpp:790] Iteration 22600, lr = 0.01
I0822 22:35:56.578382 31324 solver.cpp:254] Iteration 22620 (2.25434 iter/s, 8.87178s/20 iters), loss = 2.41719
I0822 22:35:56.579962 31324 solver.cpp:273]     Train net output #0: loss = 2.41719 (* 1 = 2.41719 loss)
I0822 22:35:56.579977 31324 sgd_solver.cpp:790] Iteration 22620, lr = 0.01
I0822 22:36:06.732045 31324 solver.cpp:254] Iteration 22640 (1.97005 iter/s, 10.152s/20 iters), loss = 2.71106
I0822 22:36:06.732120 31324 solver.cpp:273]     Train net output #0: loss = 2.71106 (* 1 = 2.71106 loss)
I0822 22:36:06.732131 31324 sgd_solver.cpp:790] Iteration 22640, lr = 0.01
I0822 22:36:17.279943 31324 solver.cpp:254] Iteration 22660 (1.89614 iter/s, 10.5478s/20 iters), loss = 2.54283
I0822 22:36:17.280010 31324 solver.cpp:273]     Train net output #0: loss = 2.54283 (* 1 = 2.54283 loss)
I0822 22:36:17.280023 31324 sgd_solver.cpp:790] Iteration 22660, lr = 0.01
I0822 22:36:26.981945 31324 solver.cpp:254] Iteration 22680 (2.06146 iter/s, 9.70188s/20 iters), loss = 2.48031
I0822 22:36:26.982167 31324 solver.cpp:273]     Train net output #0: loss = 2.48031 (* 1 = 2.48031 loss)
I0822 22:36:26.982183 31324 sgd_solver.cpp:790] Iteration 22680, lr = 0.01
I0822 22:36:36.301070 31324 solver.cpp:254] Iteration 22700 (2.14619 iter/s, 9.31886s/20 iters), loss = 2.34959
I0822 22:36:36.301126 31324 solver.cpp:273]     Train net output #0: loss = 2.34959 (* 1 = 2.34959 loss)
I0822 22:36:36.301136 31324 sgd_solver.cpp:790] Iteration 22700, lr = 0.01
I0822 22:36:47.206982 31324 solver.cpp:254] Iteration 22720 (1.83389 iter/s, 10.9058s/20 iters), loss = 2.46228
I0822 22:36:47.207043 31324 solver.cpp:273]     Train net output #0: loss = 2.46228 (* 1 = 2.46228 loss)
I0822 22:36:47.207054 31324 sgd_solver.cpp:790] Iteration 22720, lr = 0.01
I0822 22:36:53.605676 31324 solver.cpp:254] Iteration 22740 (3.12569 iter/s, 6.39859s/20 iters), loss = 2.57064
I0822 22:36:53.617797 31324 solver.cpp:273]     Train net output #0: loss = 2.57064 (* 1 = 2.57064 loss)
I0822 22:36:53.617830 31324 sgd_solver.cpp:790] Iteration 22740, lr = 0.01
I0822 22:36:57.262882 31324 solver.cpp:254] Iteration 22760 (5.48687 iter/s, 3.64507s/20 iters), loss = 2.60567
I0822 22:36:57.285583 31324 solver.cpp:273]     Train net output #0: loss = 2.60567 (* 1 = 2.60567 loss)
I0822 22:36:57.285604 31324 sgd_solver.cpp:790] Iteration 22760, lr = 0.01
I0822 22:37:00.933467 31324 solver.cpp:254] Iteration 22780 (5.48266 iter/s, 3.64786s/20 iters), loss = 2.3558
I0822 22:37:00.945647 31324 solver.cpp:273]     Train net output #0: loss = 2.3558 (* 1 = 2.3558 loss)
I0822 22:37:00.945691 31324 sgd_solver.cpp:790] Iteration 22780, lr = 0.01
I0822 22:37:04.582590 31324 solver.cpp:254] Iteration 22800 (5.49913 iter/s, 3.63694s/20 iters), loss = 2.51751
I0822 22:37:04.594648 31324 solver.cpp:273]     Train net output #0: loss = 2.51751 (* 1 = 2.51751 loss)
I0822 22:37:04.594681 31324 sgd_solver.cpp:790] Iteration 22800, lr = 0.01
I0822 22:37:08.245997 31324 solver.cpp:254] Iteration 22820 (5.47746 iter/s, 3.65133s/20 iters), loss = 2.34255
I0822 22:37:08.258157 31324 solver.cpp:273]     Train net output #0: loss = 2.34255 (* 1 = 2.34255 loss)
I0822 22:37:08.258204 31324 sgd_solver.cpp:790] Iteration 22820, lr = 0.01
I0822 22:37:12.603523 31324 solver.cpp:254] Iteration 22840 (4.6026 iter/s, 4.34537s/20 iters), loss = 2.65002
I0822 22:37:12.603579 31324 solver.cpp:273]     Train net output #0: loss = 2.65002 (* 1 = 2.65002 loss)
I0822 22:37:12.603590 31324 sgd_solver.cpp:790] Iteration 22840, lr = 0.01
I0822 22:37:21.597281 31324 solver.cpp:254] Iteration 22860 (2.22379 iter/s, 8.99366s/20 iters), loss = 2.54107
I0822 22:37:21.597342 31324 solver.cpp:273]     Train net output #0: loss = 2.54107 (* 1 = 2.54107 loss)
I0822 22:37:21.597354 31324 sgd_solver.cpp:790] Iteration 22860, lr = 0.01
I0822 22:37:31.075754 31324 solver.cpp:254] Iteration 22880 (2.11007 iter/s, 9.47836s/20 iters), loss = 2.70276
I0822 22:37:31.077903 31324 solver.cpp:273]     Train net output #0: loss = 2.70276 (* 1 = 2.70276 loss)
I0822 22:37:31.077920 31324 sgd_solver.cpp:790] Iteration 22880, lr = 0.01
I0822 22:37:41.628695 31324 solver.cpp:254] Iteration 22900 (1.8956 iter/s, 10.5507s/20 iters), loss = 2.61253
I0822 22:37:41.628756 31324 solver.cpp:273]     Train net output #0: loss = 2.61253 (* 1 = 2.61253 loss)
I0822 22:37:41.628767 31324 sgd_solver.cpp:790] Iteration 22900, lr = 0.01
I0822 22:37:52.302057 31324 solver.cpp:254] Iteration 22920 (1.87385 iter/s, 10.6732s/20 iters), loss = 2.59552
I0822 22:37:52.302150 31324 solver.cpp:273]     Train net output #0: loss = 2.59552 (* 1 = 2.59552 loss)
I0822 22:37:52.302167 31324 sgd_solver.cpp:790] Iteration 22920, lr = 0.01
I0822 22:38:02.790043 31324 solver.cpp:254] Iteration 22940 (1.90697 iter/s, 10.4878s/20 iters), loss = 2.38984
I0822 22:38:02.790200 31324 solver.cpp:273]     Train net output #0: loss = 2.38984 (* 1 = 2.38984 loss)
I0822 22:38:02.790211 31324 sgd_solver.cpp:790] Iteration 22940, lr = 0.01
I0822 22:38:13.253861 31324 solver.cpp:254] Iteration 22960 (1.91139 iter/s, 10.4636s/20 iters), loss = 2.26809
I0822 22:38:13.253921 31324 solver.cpp:273]     Train net output #0: loss = 2.26809 (* 1 = 2.26809 loss)
I0822 22:38:13.253932 31324 sgd_solver.cpp:790] Iteration 22960, lr = 0.01
I0822 22:38:23.648082 31324 solver.cpp:254] Iteration 22980 (1.92417 iter/s, 10.3941s/20 iters), loss = 2.80624
I0822 22:38:23.648172 31324 solver.cpp:273]     Train net output #0: loss = 2.80624 (* 1 = 2.80624 loss)
I0822 22:38:23.648195 31324 sgd_solver.cpp:790] Iteration 22980, lr = 0.01
I0822 22:38:33.290940 31324 solver.cpp:366] Iteration 23000, Testing net (#0)
I0822 22:38:39.465000 31324 blocking_queue.cpp:49] Waiting for data
I0822 22:38:57.249444 31336 data_layer.cpp:73] Restarting data prefetching from start.
I0822 22:38:57.265964 31324 solver.cpp:433]     Test net output #0: accuracy = 0.4609
I0822 22:38:57.266018 31324 solver.cpp:433]     Test net output #1: accuracy5 = 0.722379
I0822 22:38:57.266033 31324 solver.cpp:433]     Test net output #2: loss = 2.39976 (* 1 = 2.39976 loss)
I0822 22:38:57.442976 31324 solver.cpp:254] Iteration 23000 (0.59181 iter/s, 33.7946s/20 iters), loss = 2.45939
I0822 22:38:57.445483 31324 solver.cpp:273]     Train net output #0: loss = 2.45939 (* 1 = 2.45939 loss)
I0822 22:38:57.445505 31324 sgd_solver.cpp:790] Iteration 23000, lr = 0.01
I0822 22:39:06.597554 31324 solver.cpp:254] Iteration 23020 (2.18531 iter/s, 9.15202s/20 iters), loss = 2.47623
I0822 22:39:06.601240 31324 solver.cpp:273]     Train net output #0: loss = 2.47623 (* 1 = 2.47623 loss)
I0822 22:39:06.601254 31324 sgd_solver.cpp:790] Iteration 23020, lr = 0.01
I0822 22:39:17.065778 31324 solver.cpp:254] Iteration 23040 (1.91123 iter/s, 10.4645s/20 iters), loss = 2.73397
I0822 22:39:17.065845 31324 solver.cpp:273]     Train net output #0: loss = 2.73397 (* 1 = 2.73397 loss)
I0822 22:39:17.065856 31324 sgd_solver.cpp:790] Iteration 23040, lr = 0.01
I0822 22:39:27.724632 31324 solver.cpp:254] Iteration 23060 (1.8764 iter/s, 10.6587s/20 iters), loss = 2.38939
I0822 22:39:27.724694 31324 solver.cpp:273]     Train net output #0: loss = 2.38939 (* 1 = 2.38939 loss)
I0822 22:39:27.724704 31324 sgd_solver.cpp:790] Iteration 23060, lr = 0.01
I0822 22:39:38.329448 31324 solver.cpp:254] Iteration 23080 (1.88596 iter/s, 10.6047s/20 iters), loss = 2.77157
I0822 22:39:38.329720 31324 solver.cpp:273]     Train net output #0: loss = 2.77157 (* 1 = 2.77157 loss)
I0822 22:39:38.329731 31324 sgd_solver.cpp:790] Iteration 23080, lr = 0.01
I0822 22:39:49.132513 31324 solver.cpp:254] Iteration 23100 (1.85139 iter/s, 10.8027s/20 iters), loss = 2.6963
I0822 22:39:49.132602 31324 solver.cpp:273]     Train net output #0: loss = 2.6963 (* 1 = 2.6963 loss)
I0822 22:39:49.132622 31324 sgd_solver.cpp:790] Iteration 23100, lr = 0.01
I0822 22:39:59.782377 31324 solver.cpp:254] Iteration 23120 (1.87799 iter/s, 10.6497s/20 iters), loss = 2.58689
I0822 22:39:59.782447 31324 solver.cpp:273]     Train net output #0: loss = 2.58689 (* 1 = 2.58689 loss)
I0822 22:39:59.782460 31324 sgd_solver.cpp:790] Iteration 23120, lr = 0.01
I0822 22:40:10.356633 31324 solver.cpp:254] Iteration 23140 (1.89141 iter/s, 10.5741s/20 iters), loss = 2.42855
I0822 22:40:10.356777 31324 solver.cpp:273]     Train net output #0: loss = 2.42855 (* 1 = 2.42855 loss)
I0822 22:40:10.356789 31324 sgd_solver.cpp:790] Iteration 23140, lr = 0.01
I0822 22:40:20.890334 31324 solver.cpp:254] Iteration 23160 (1.8987 iter/s, 10.5335s/20 iters), loss = 2.47628
I0822 22:40:20.890396 31324 solver.cpp:273]     Train net output #0: loss = 2.47628 (* 1 = 2.47628 loss)
I0822 22:40:20.890414 31324 sgd_solver.cpp:790] Iteration 23160, lr = 0.01
I0822 22:40:31.483315 31324 solver.cpp:254] Iteration 23180 (1.88807 iter/s, 10.5929s/20 iters), loss = 3.0258
I0822 22:40:31.483388 31324 solver.cpp:273]     Train net output #0: loss = 3.0258 (* 1 = 3.0258 loss)
I0822 22:40:31.483403 31324 sgd_solver.cpp:790] Iteration 23180, lr = 0.01
I0822 22:40:41.581662 31324 solver.cpp:254] Iteration 23200 (1.98055 iter/s, 10.0982s/20 iters), loss = 2.32091
I0822 22:40:41.581823 31324 solver.cpp:273]     Train net output #0: loss = 2.32091 (* 1 = 2.32091 loss)
I0822 22:40:41.581836 31324 sgd_solver.cpp:790] Iteration 23200, lr = 0.01
I0822 22:40:50.978273 31324 solver.cpp:254] Iteration 23220 (2.12848 iter/s, 9.39639s/20 iters), loss = 2.2237
I0822 22:40:50.978358 31324 solver.cpp:273]     Train net output #0: loss = 2.2237 (* 1 = 2.2237 loss)
I0822 22:40:50.978374 31324 sgd_solver.cpp:790] Iteration 23220, lr = 0.01
I0822 22:41:00.218422 31324 solver.cpp:254] Iteration 23240 (2.1645 iter/s, 9.24002s/20 iters), loss = 2.50949
I0822 22:41:00.218479 31324 solver.cpp:273]     Train net output #0: loss = 2.50949 (* 1 = 2.50949 loss)
I0822 22:41:00.218489 31324 sgd_solver.cpp:790] Iteration 23240, lr = 0.01
I0822 22:41:09.299458 31324 blocking_queue.cpp:49] Waiting for data
I0822 22:41:09.853404 31324 solver.cpp:254] Iteration 23260 (2.0758 iter/s, 9.63486s/20 iters), loss = 2.60797
I0822 22:41:09.853477 31324 solver.cpp:273]     Train net output #0: loss = 2.60797 (* 1 = 2.60797 loss)
I0822 22:41:09.853490 31324 sgd_solver.cpp:790] Iteration 23260, lr = 0.01
I0822 22:41:19.042197 31324 solver.cpp:254] Iteration 23280 (2.1766 iter/s, 9.18866s/20 iters), loss = 2.67506
I0822 22:41:19.042366 31324 solver.cpp:273]     Train net output #0: loss = 2.67506 (* 1 = 2.67506 loss)
I0822 22:41:19.042381 31324 sgd_solver.cpp:790] Iteration 23280, lr = 0.01
I0822 22:41:29.635066 31324 solver.cpp:254] Iteration 23300 (1.8881 iter/s, 10.5926s/20 iters), loss = 2.56067
I0822 22:41:29.635126 31324 solver.cpp:273]     Train net output #0: loss = 2.56067 (* 1 = 2.56067 loss)
I0822 22:41:29.635136 31324 sgd_solver.cpp:790] Iteration 23300, lr = 0.01
I0822 22:41:40.109794 31324 solver.cpp:254] Iteration 23320 (1.90938 iter/s, 10.4746s/20 iters), loss = 2.42874
I0822 22:41:40.109846 31324 solver.cpp:273]     Train net output #0: loss = 2.42874 (* 1 = 2.42874 loss)
I0822 22:41:40.109856 31324 sgd_solver.cpp:790] Iteration 23320, lr = 0.01
I0822 22:41:50.777431 31324 solver.cpp:254] Iteration 23340 (1.87485 iter/s, 10.6675s/20 iters), loss = 2.40128
I0822 22:41:50.777591 31324 solver.cpp:273]     Train net output #0: loss = 2.40128 (* 1 = 2.40128 loss)
I0822 22:41:50.777604 31324 sgd_solver.cpp:790] Iteration 23340, lr = 0.01
I0822 22:42:01.198297 31324 solver.cpp:254] Iteration 23360 (1.91927 iter/s, 10.4206s/20 iters), loss = 2.64464
I0822 22:42:01.198360 31324 solver.cpp:273]     Train net output #0: loss = 2.64464 (* 1 = 2.64464 loss)
I0822 22:42:01.198374 31324 sgd_solver.cpp:790] Iteration 23360, lr = 0.01
I0822 22:42:11.818289 31324 solver.cpp:254] Iteration 23380 (1.88326 iter/s, 10.6199s/20 iters), loss = 2.6375
I0822 22:42:11.818361 31324 solver.cpp:273]     Train net output #0: loss = 2.6375 (* 1 = 2.6375 loss)
I0822 22:42:11.818372 31324 sgd_solver.cpp:790] Iteration 23380, lr = 0.01
I0822 22:42:22.559221 31324 solver.cpp:254] Iteration 23400 (1.86206 iter/s, 10.7408s/20 iters), loss = 2.40012
I0822 22:42:22.560111 31324 solver.cpp:273]     Train net output #0: loss = 2.40012 (* 1 = 2.40012 loss)
I0822 22:42:22.560122 31324 sgd_solver.cpp:790] Iteration 23400, lr = 0.01
I0822 22:42:33.119195 31324 solver.cpp:254] Iteration 23420 (1.89412 iter/s, 10.559s/20 iters), loss = 2.66417
I0822 22:42:33.119276 31324 solver.cpp:273]     Train net output #0: loss = 2.66417 (* 1 = 2.66417 loss)
I0822 22:42:33.119292 31324 sgd_solver.cpp:790] Iteration 23420, lr = 0.01
I0822 22:42:43.802574 31324 solver.cpp:254] Iteration 23440 (1.87209 iter/s, 10.6832s/20 iters), loss = 2.56319
I0822 22:42:43.802634 31324 solver.cpp:273]     Train net output #0: loss = 2.56319 (* 1 = 2.56319 loss)
I0822 22:42:43.802655 31324 sgd_solver.cpp:790] Iteration 23440, lr = 0.01
I0822 22:42:54.092990 31324 solver.cpp:254] Iteration 23460 (1.94358 iter/s, 10.2903s/20 iters), loss = 2.72466
I0822 22:42:54.093302 31324 solver.cpp:273]     Train net output #0: loss = 2.72466 (* 1 = 2.72466 loss)
I0822 22:42:54.093319 31324 sgd_solver.cpp:790] Iteration 23460, lr = 0.01
I0822 22:43:04.836331 31324 solver.cpp:254] Iteration 23480 (1.86168 iter/s, 10.743s/20 iters), loss = 2.65722
I0822 22:43:04.836421 31324 solver.cpp:273]     Train net output #0: loss = 2.65722 (* 1 = 2.65722 loss)
I0822 22:43:04.836441 31324 sgd_solver.cpp:790] Iteration 23480, lr = 0.01
I0822 22:43:14.199517 31324 solver.cpp:254] Iteration 23500 (2.13606 iter/s, 9.36305s/20 iters), loss = 2.26053
I0822 22:43:14.199568 31324 solver.cpp:273]     Train net output #0: loss = 2.26053 (* 1 = 2.26053 loss)
I0822 22:43:14.199579 31324 sgd_solver.cpp:790] Iteration 23500, lr = 0.01
I0822 22:43:22.461313 31324 solver.cpp:254] Iteration 23520 (2.42082 iter/s, 8.26168s/20 iters), loss = 2.71811
I0822 22:43:22.461377 31324 solver.cpp:273]     Train net output #0: loss = 2.71811 (* 1 = 2.71811 loss)
I0822 22:43:22.461393 31324 sgd_solver.cpp:790] Iteration 23520, lr = 0.01
I0822 22:43:30.724100 31324 solver.cpp:254] Iteration 23540 (2.42053 iter/s, 8.26266s/20 iters), loss = 2.51598
I0822 22:43:30.724218 31324 solver.cpp:273]     Train net output #0: loss = 2.51598 (* 1 = 2.51598 loss)
I0822 22:43:30.724232 31324 sgd_solver.cpp:790] Iteration 23540, lr = 0.01
I0822 22:43:39.692713 31324 solver.cpp:254] Iteration 23560 (2.23004 iter/s, 8.96844s/20 iters), loss = 2.54018
I0822 22:43:39.692778 31324 solver.cpp:273]     Train net output #0: loss = 2.54018 (* 1 = 2.54018 loss)
I0822 22:43:39.692791 31324 sgd_solver.cpp:790] Iteration 23560, lr = 0.01
I0822 22:43:49.267289 31324 solver.cpp:254] Iteration 23580 (2.08889 iter/s, 9.57446s/20 iters), loss = 2.31747
I0822 22:43:49.267354 31324 solver.cpp:273]     Train net output #0: loss = 2.31747 (* 1 = 2.31747 loss)
I0822 22:43:49.267367 31324 sgd_solver.cpp:790] Iteration 23580, lr = 0.01
*** Aborted at 1534992231 (unix time) try "date -d @1534992231" if you are using GNU date ***
PC: @     0x7f4f82967360 __pthread_cond_wait
*** SIGTERM (@0x3ee00007cc5) received by PID 31324 (TID 0x7f4fa31aeb00) from PID 31941; stack trace: ***
    @     0x7f4fa0a0f4b0 (unknown)
    @     0x7f4f82967360 __pthread_cond_wait
    @     0x7f4fa2a3f727 caffe::BlockingQueue<>::pop()
    @     0x7f4fa2aab195 caffe::BasePrefetchingDataLayer<>::Forward_gpu()
    @     0x7f4fa288fd91 caffe::Net<>::ForwardFromTo()
    @     0x7f4fa288fe97 caffe::Net<>::Forward()
    @     0x7f4fa28e11b0 caffe::Solver<>::Step()
    @     0x7f4fa28e1d9a caffe::Solver<>::Solve()
    @           0x40ac93 train()
    @           0x4076b8 main
    @     0x7f4fa09fa830 __libc_start_main
    @           0x408159 _start
    @                0x0 (unknown)
Terminated
